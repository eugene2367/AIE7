{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Movie Reviews Retriever Evaluation with Enhanced RAG Chain\n",
        "\n",
        "This notebook evaluates different retriever methods using the complete enhanced RAG chain from the movie_reviews_rag_system.ipynb, allowing us to test how different retrievers perform with the full agentic pipeline.\n",
        "\n",
        "### Objectives:\n",
        "1. Set up the complete enhanced RAG chain with multi-tool agents\n",
        "2. Create a \"golden dataset\" using RAGAS Synthetic Data Generation from movie reviews\n",
        "3. Evaluate 6 different retrievers within the enhanced agent pipeline\n",
        "4. Compare performance, cost, and latency of the complete system\n",
        "5. Provide recommendations for movie review retrieval in production\n",
        "\n",
        "### Data Sources:\n",
        "- **Rotten Tomatoes Movies**: Movie metadata with titles, ratings, genres, directors, runtime, release dates\n",
        "- **Rotten Tomatoes Reviews**: Professional critic reviews with scores, sentiment, publications, and detailed text\n",
        "\n",
        "### Retrievers to Evaluate:\n",
        "- Naive Retrieval (Embedding-based)\n",
        "- BM25 Retriever\n",
        "- Multi-Query Retriever\n",
        "- Parent-Document Retriever\n",
        "- Contextual Compression (Reranking)\n",
        "- Ensemble Retriever\n",
        "\n",
        "### Enhanced RAG Features:\n",
        "- Multi-tool agent with specialized movie analysis tools\n",
        "- External search capabilities\n",
        "- LangSmith tracing and monitoring\n",
        "- Advanced analytics and trend analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 1: Setup and Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”‘ Setting up API Keys\n",
            "========================================\n",
            "âœ… OpenAI API key already set\n",
            "âœ… Cohere API key already set\n",
            "âœ… SerpAPI API key already set\n",
            "âœ… Tavily API key already set\n",
            "âœ… LangSmith API key already set\n",
            "\n",
            "ğŸ¯ API Key Setup Complete!\n",
            "âœ… Ready for enhanced movie review retriever evaluation!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import getpass\n",
        "import warnings\n",
        "import numpy as np\n",
        "from typing import List, Dict, Any, Optional\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "from uuid import uuid4\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Apply nest_asyncio for Jupyter compatibility\n",
        "nest_asyncio.apply()\n",
        "\n",
        "print(\"ğŸ”‘ Setting up API Keys\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# OpenAI API Key (required)\n",
        "if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"ğŸ¤– Enter your OpenAI API Key: \")\n",
        "    print(\"âœ… OpenAI API key set\")\n",
        "else:\n",
        "    print(\"âœ… OpenAI API key already set\")\n",
        "\n",
        "# Cohere API Key (required for reranking)\n",
        "if not os.getenv(\"COHERE_API_KEY\"):\n",
        "    os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"ğŸ”„ Enter your Cohere API Key: \")\n",
        "    print(\"âœ… Cohere API key set\")\n",
        "else:\n",
        "    print(\"âœ… Cohere API key already set\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Serapi API Key (recommended for external search)\n",
        "if not os.getenv(\"SERPAPI_API_KEY\"):\n",
        "    serapi_key = getpass.getpass(\"ğŸ” Enter your Serapi API Key (or press Enter to skip): \")\n",
        "    if serapi_key.strip():\n",
        "        os.environ[\"SERPAPI_API_KEY\"] = serapi_key\n",
        "        print(\"âœ… SerpAPI API key set\")\n",
        "    else:\n",
        "        print(\"âš ï¸ SerpAPI API key skipped - external search will be limited\")\n",
        "else:\n",
        "    print(\"âœ… SerpAPI API key already set\")\n",
        "\n",
        "\n",
        "\n",
        "# Tavily API Key (recommended for external search)\n",
        "if not os.getenv(\"TAVILY_API_KEY\"):\n",
        "    tavily_key = getpass.getpass(\"ğŸ” Enter your Tavily API Key (or press Enter to skip): \")\n",
        "    if tavily_key.strip():\n",
        "        os.environ[\"TAVILY_API_KEY\"] = tavily_key\n",
        "        print(\"âœ… Tavily API key set\")\n",
        "    else:\n",
        "        print(\"âš ï¸ Tavily API key skipped - external search will be limited\")\n",
        "else:\n",
        "    print(\"âœ… Tavily API key already set\")\n",
        "\n",
        "# LangSmith API Key (optional for monitoring)\n",
        "if not os.getenv(\"LANGSMITH_API_KEY\"):\n",
        "    langsmith_key = getpass.getpass(\"ğŸ“Š Enter your LangSmith API Key (or press Enter to skip): \")\n",
        "    if langsmith_key.strip():\n",
        "        os.environ[\"LANGSMITH_API_KEY\"] = langsmith_key\n",
        "        os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "        os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "        os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "        os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "        print(\"âœ… LangSmith API key set and tracing enabled\")\n",
        "    else:\n",
        "        os.environ[\"LANGSMITH_TRACING\"] = \"false\"\n",
        "        os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
        "        print(\"âš ï¸ LangSmith skipped - no monitoring/tracing\")\n",
        "else:\n",
        "    print(\"âœ… LangSmith API key already set\")\n",
        "\n",
        "print(\"\\nğŸ¯ API Key Setup Complete!\")\n",
        "print(\"âœ… Ready for enhanced movie review retriever evaluation!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 2: Load and Prepare Movie Reviews Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ… Loading Rotten Tomatoes movie review datasets...\n",
            "Loading Rotten Tomatoes movies metadata...\n",
            "  Trying encoding: utf-8\n",
            "  âœ… Success with utf-8\n",
            "Movies dataset: 143258 movies\n",
            "Columns: ['id', 'title', 'audienceScore', 'tomatoMeter', 'rating', 'ratingContents', 'releaseDateTheaters', 'releaseDateStreaming', 'runtimeMinutes', 'genre', 'originalLanguage', 'director', 'writer', 'boxOffice', 'distributor', 'soundMix']\n",
            "\n",
            "Loading Rotten Tomatoes reviews...\n",
            "  Trying encoding: utf-8\n",
            "  âœ… Success with utf-8\n",
            "Reviews dataset: 1444963 reviews\n",
            "Columns: ['id', 'reviewId', 'creationDate', 'criticName', 'isTopCritic', 'originalScore', 'reviewState', 'publicatioName', 'reviewText', 'scoreSentiment', 'reviewUrl']\n",
            "\n",
            "ğŸ¬ Sample movies metadata:\n",
            "                   id                title  audienceScore  tomatoMeter rating  \\\n",
            "0  space-zombie-bingo  Space Zombie Bingo!           50.0          NaN    NaN   \n",
            "1     the_green_grass      The Green Grass            NaN          NaN    NaN   \n",
            "2           love_lies           Love, Lies           43.0          NaN    NaN   \n",
            "\n",
            "  ratingContents releaseDateTheaters releaseDateStreaming  runtimeMinutes  \\\n",
            "0            NaN                 NaN           2018-08-25            75.0   \n",
            "1            NaN                 NaN           2020-02-11           114.0   \n",
            "2            NaN                 NaN                  NaN           120.0   \n",
            "\n",
            "                    genre originalLanguage                       director  \\\n",
            "0  Comedy, Horror, Sci-fi          English                  George Ormrod   \n",
            "1                   Drama          English                Tiffany Edwards   \n",
            "2                   Drama           Korean  Park Heung-Sik,Heung-Sik Park   \n",
            "\n",
            "                                   writer boxOffice distributor soundMix  \n",
            "0              George Ormrod,John Sabotta       NaN         NaN      NaN  \n",
            "1                         Tiffany Edwards       NaN         NaN      NaN  \n",
            "2  Ha Young-Joon,Jeon Yun-su,Song Hye-jin       NaN         NaN      NaN  \n",
            "\n",
            "ğŸ“ Sample reviews:\n",
            "                                  id  reviewId creationDate       criticName  \\\n",
            "0                            beavers   1145982   2003-05-23  Ivan M. Lincoln   \n",
            "1                         blood_mask   1636744   2007-06-02    The Foywonder   \n",
            "2  city_hunter_shinjuku_private_eyes   2590987   2019-05-28     Reuben Baron   \n",
            "\n",
            "   isTopCritic originalScore reviewState                 publicatioName  \\\n",
            "0        False         3.5/4       fresh  Deseret News (Salt Lake City)   \n",
            "1        False           1/5      rotten                  Dread Central   \n",
            "2        False           NaN       fresh                            CBR   \n",
            "\n",
            "                                          reviewText scoreSentiment  \\\n",
            "0  Timed to be just long enough for most youngste...       POSITIVE   \n",
            "1  It doesn't matter if a movie costs 300 million...       NEGATIVE   \n",
            "2  The choreography is so precise and lifelike at...       POSITIVE   \n",
            "\n",
            "                                           reviewUrl  \n",
            "0  http://www.deseretnews.com/article/700003233/B...  \n",
            "1  http://www.dreadcentral.com/index.php?name=Rev...  \n",
            "2  https://www.cbr.com/city-hunter-shinjuku-priva...  \n",
            "\n",
            "ğŸ“Š Dataset Statistics:\n",
            "â€¢ Total movies: 143,258\n",
            "â€¢ Total reviews: 1,444,963\n",
            "â€¢ Average reviews per movie: 10.1\n",
            "â€¢ Unique movie IDs in reviews: 69,263\n",
            "â€¢ Movies with reviews: 69,263 / 143,258\n",
            "\n",
            "ğŸ† Review State Distribution:\n",
            "reviewState\n",
            "fresh     963799\n",
            "rotten    481164\n",
            "Name: count, dtype: int64\n",
            "\n",
            "â­ Score Sentiment Distribution:\n",
            "scoreSentiment\n",
            "POSITIVE    963799\n",
            "NEGATIVE    481164\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Load the Rotten Tomatoes datasets\n",
        "print(\"ğŸ… Loading Rotten Tomatoes movie review datasets...\")\n",
        "\n",
        "# Robust CSV loading function with error handling\n",
        "def load_csv_robust(filepath):\n",
        "    \"\"\"Load CSV with robust error handling for malformed data\"\"\"\n",
        "    encodings = ['utf-8', 'latin1', 'cp1252', 'iso-8859-1']\n",
        "    \n",
        "    for encoding in encodings:\n",
        "        try:\n",
        "            print(f\"  Trying encoding: {encoding}\")\n",
        "            # Try with error handling for malformed lines\n",
        "            df = pd.read_csv(\n",
        "                filepath, \n",
        "                encoding=encoding,\n",
        "                on_bad_lines='skip',  # Skip bad lines instead of failing\n",
        "                engine='python',      # Use Python engine for better error handling\n",
        "                quoting=1,           # Quote all fields\n",
        "                skipinitialspace=True\n",
        "            )\n",
        "            print(f\"  âœ… Success with {encoding}\")\n",
        "            return df\n",
        "        except UnicodeDecodeError:\n",
        "            print(f\"  âŒ Failed with {encoding}\")\n",
        "            continue\n",
        "        except Exception as e:\n",
        "            print(f\"  âŒ Failed with {encoding}: {str(e)}\")\n",
        "            continue\n",
        "    \n",
        "    # If all encodings fail, try with minimal options\n",
        "    print(\"  Trying with basic fallback...\")\n",
        "    try:\n",
        "        df = pd.read_csv(filepath, encoding='latin1', on_bad_lines='skip', engine='python')\n",
        "        print(\"  âœ… Success with fallback method\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Could not read {filepath}: {str(e)}\")\n",
        "\n",
        "# Load Rotten Tomatoes movies metadata\n",
        "print(\"Loading Rotten Tomatoes movies metadata...\")\n",
        "movies_df = load_csv_robust(\"data/rotten_tomatoes_movies.csv\")\n",
        "print(f\"Movies dataset: {len(movies_df)} movies\")\n",
        "print(f\"Columns: {list(movies_df.columns)}\")\n",
        "\n",
        "# Load Rotten Tomatoes reviews\n",
        "print(\"\\nLoading Rotten Tomatoes reviews...\")\n",
        "reviews_df = load_csv_robust(\"data/rotten_tomatoes_movie_reviews.csv\")\n",
        "print(f\"Reviews dataset: {len(reviews_df)} reviews\")\n",
        "print(f\"Columns: {list(reviews_df.columns)}\")\n",
        "\n",
        "# Display sample data\n",
        "print(\"\\nğŸ¬ Sample movies metadata:\")\n",
        "print(movies_df.head(3))\n",
        "\n",
        "print(\"\\nğŸ“ Sample reviews:\")\n",
        "print(reviews_df.head(3))\n",
        "\n",
        "# Basic statistics\n",
        "print(f\"\\nğŸ“Š Dataset Statistics:\")\n",
        "print(f\"â€¢ Total movies: {len(movies_df):,}\")\n",
        "print(f\"â€¢ Total reviews: {len(reviews_df):,}\")\n",
        "print(f\"â€¢ Average reviews per movie: {len(reviews_df)/len(movies_df):.1f}\")\n",
        "print(f\"â€¢ Unique movie IDs in reviews: {reviews_df['id'].nunique():,}\")\n",
        "print(f\"â€¢ Movies with reviews: {reviews_df['id'].nunique():,} / {len(movies_df):,}\")\n",
        "\n",
        "# Check review distribution\n",
        "print(f\"\\nğŸ† Review State Distribution:\")\n",
        "if 'reviewState' in reviews_df.columns:\n",
        "    print(reviews_df['reviewState'].value_counts())\n",
        "\n",
        "print(f\"\\nâ­ Score Sentiment Distribution:\")\n",
        "if 'scoreSentiment' in reviews_df.columns:\n",
        "    print(reviews_df['scoreSentiment'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”— Merging movies metadata with reviews...\n",
            "âœ… Cleaned reviews dataset: 1364909 reviews\n",
            "âœ… Merged dataset: 1388546 reviews with movie metadata\n",
            "âœ… Reviews with movie titles: 1383051 / 1388546\n",
            "âš ï¸ 5495 reviews missing movie titles (will use movie ID)\n",
            "\n",
            "ğŸ¬ Sample merged data:\n",
            "  title_clean criticName_clean  \\\n",
            "0     Beavers  Ivan M. Lincoln   \n",
            "1  Blood Mask    The Foywonder   \n",
            "\n",
            "                                    reviewText_clean rating  genre_clean  \n",
            "0  Timed to be just long enough for most youngste...    NaN  Documentary  \n",
            "1  It doesn't matter if a movie costs 300 million...    NaN               \n"
          ]
        }
      ],
      "source": [
        "# Data cleaning and preprocessing for Rotten Tomatoes data\n",
        "def clean_text(text):\n",
        "    \"\"\"Clean and normalize text data\"\"\"\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    \n",
        "    # Convert to string and clean\n",
        "    text = str(text).strip()\n",
        "    \n",
        "    # Remove special characters and normalize\n",
        "    import re\n",
        "    text = re.sub(r'[\\x00-\\x1f\\x7f-\\x9f]', '', text)  # Remove control characters\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Normalize whitespace\n",
        "    \n",
        "    return text.strip()\n",
        "\n",
        "# Clean movies data\n",
        "movies_df['title_clean'] = movies_df['title'].apply(clean_text)\n",
        "movies_df['genre_clean'] = movies_df['genre'].apply(clean_text)\n",
        "movies_df['director_clean'] = movies_df['director'].apply(clean_text)\n",
        "\n",
        "# Clean reviews data\n",
        "reviews_df['reviewText_clean'] = reviews_df['reviewText'].apply(clean_text)\n",
        "reviews_df['criticName_clean'] = reviews_df['criticName'].apply(clean_text)\n",
        "reviews_df['publicatioName_clean'] = reviews_df['publicatioName'].apply(clean_text)\n",
        "\n",
        "# Remove rows with empty review text\n",
        "reviews_df = reviews_df[reviews_df['reviewText_clean'].str.len() > 20].copy()\n",
        "\n",
        "# Merge movies and reviews for complete information\n",
        "print(\"ğŸ”— Merging movies metadata with reviews...\")\n",
        "merged_df = reviews_df.merge(movies_df, on='id', how='left')\n",
        "\n",
        "print(f\"âœ… Cleaned reviews dataset: {len(reviews_df)} reviews\")\n",
        "print(f\"âœ… Merged dataset: {len(merged_df)} reviews with movie metadata\")\n",
        "print(f\"âœ… Reviews with movie titles: {merged_df['title'].notna().sum()} / {len(merged_df)}\")\n",
        "\n",
        "# Handle missing titles\n",
        "missing_titles = merged_df['title'].isna().sum()\n",
        "if missing_titles > 0:\n",
        "    print(f\"âš ï¸ {missing_titles} reviews missing movie titles (will use movie ID)\")\n",
        "    merged_df['title_clean'] = merged_df['title_clean'].fillna(merged_df['id'])\n",
        "\n",
        "print(f\"\\nğŸ¬ Sample merged data:\")\n",
        "sample_cols = ['title_clean', 'criticName_clean', 'reviewText_clean', 'rating', 'genre_clean']\n",
        "available_cols = [col for col in sample_cols if col in merged_df.columns]\n",
        "print(merged_df[available_cols].head(2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ… Creating movie documents from Rotten Tomatoes data...\n",
            "ğŸ” Filtering movies with at least 5 reviews...\n",
            "âœ… Filtered dataset: 1324508 reviews from 31456 movies (min 5 reviews each)\n",
            "ğŸ“Š Review count distribution:\n",
            "   count: 31456.0\n",
            "   mean: 42.1\n",
            "   std: 65.0\n",
            "   min: 5.0\n",
            "   25%: 8.0\n",
            "   50%: 16.0\n",
            "   75%: 45.0\n",
            "   max: 1896.0\n",
            "ğŸ¬ Grouping reviews by movie...\n",
            "âœ… Created 100 movie documents from 100 movies\n",
            "âœ… Created 100 total review documents\n",
            "   - Source: Rotten Tomatoes\n",
            "   - Reviews with movie metadata included\n",
            "\\nğŸ“„ Sample document:\n",
            "Movie: Parasite\\nGenre: Comedy, Mystery & thriller, Drama\\nDirector: Bong Joon Ho\\nRating: R\\nRelease Date: 2019-11-01\\nAudience Score: 90.0%\\nTomato Meter: 99.0%\\nRuntime: 132.0 minutes\\nTotal Reviews: 1896\\n\\nReviews:\\n\\n--- Review 492485 ---\\nCritic: Patricia Puentes (CNET)\\nScore: nan\\nSentiment...\n",
            "\\nğŸ·ï¸ Sample metadata:\n",
            "  source: rotten_tomatoes\n",
            "  movie_id: parasite_2019\n",
            "  movie_title: Parasite\n",
            "  genre: Comedy, Mystery & thriller, Drama\n",
            "  director: Bong Joon Ho\n",
            "  rating: R\n",
            "  audience_score: 90.0\n",
            "  tomato_meter: 99.0\n",
            "\\nğŸ“Š Document Statistics:\n",
            "â€¢ Unique movies: 100\n",
            "â€¢ Average content length: 9936 characters\n"
          ]
        }
      ],
      "source": [
        "# Helper function to filter movies by review count\n",
        "def filter_movies_by_review_count(df, min_reviews=5):\n",
        "    \"\"\"Filter movies to only include those with at least min_reviews reviews\"\"\"\n",
        "    print(f\"ğŸ” Filtering movies with at least {min_reviews} reviews...\")\n",
        "    \n",
        "    # Count reviews per movie\n",
        "    review_counts = df.groupby('id').size().reset_index(name='review_count')\n",
        "    \n",
        "    # Filter movies that meet the minimum review count\n",
        "    qualified_movies = review_counts[review_counts['review_count'] >= min_reviews]\n",
        "    \n",
        "    # Filter the original dataframe to only include qualified movies\n",
        "    filtered_df = df[df['id'].isin(qualified_movies['id'])]\n",
        "    \n",
        "    print(f\"âœ… Filtered dataset: {len(filtered_df)} reviews from {len(qualified_movies)} movies (min {min_reviews} reviews each)\")\n",
        "    print(f\"ğŸ“Š Review count distribution:\")\n",
        "    review_distribution = qualified_movies['review_count'].describe()\n",
        "    for stat, value in review_distribution.items():\n",
        "        print(f\"   {stat}: {value:.1f}\")\n",
        "    \n",
        "    return filtered_df, qualified_movies\n",
        "\n",
        "# Create unified data structure for processing Rotten Tomatoes data (now groups by movie)\n",
        "def create_review_documents(df, max_movies=100, min_reviews=5):\n",
        "    \"\"\"Convert merged DataFrame to list of movie documents (grouped by movie)\"\"\"\n",
        "    documents = []\n",
        "    \n",
        "    # First filter by review count\n",
        "    filtered_df, qualified_movies = filter_movies_by_review_count(df, min_reviews)\n",
        "    \n",
        "    # Group by movie ID to collect all reviews for each movie\n",
        "    print(\"ğŸ¬ Grouping reviews by movie...\")\n",
        "    movie_groups = filtered_df.groupby('id')\n",
        "    \n",
        "    # Sort movies by review count (descending) to prioritize movies with more reviews\n",
        "    movie_review_counts = qualified_movies.sort_values('review_count', ascending=False)\n",
        "    \n",
        "    # Limit the number of movies for performance\n",
        "    movie_count = 0\n",
        "    processed_movies = 0\n",
        "    \n",
        "    for movie_id in movie_review_counts['id']:\n",
        "        if movie_count >= max_movies:\n",
        "            break\n",
        "            \n",
        "        movie_reviews = movie_groups.get_group(movie_id)\n",
        "        processed_movies += 1\n",
        "        \n",
        "        # Get the first row for movie metadata (all rows have same movie info)\n",
        "        first_review = movie_reviews.iloc[0]\n",
        "        \n",
        "        # Create comprehensive metadata for the movie\n",
        "        metadata = {\n",
        "            'source': 'rotten_tomatoes',\n",
        "            'movie_id': movie_id,\n",
        "            'movie_title': first_review.get('title_clean', str(movie_id)),\n",
        "            'genre': first_review.get('genre_clean', ''),\n",
        "            'director': first_review.get('director_clean', ''),\n",
        "            'rating': first_review.get('rating', ''),\n",
        "            'audience_score': first_review.get('audienceScore', ''),\n",
        "            'tomato_meter': first_review.get('tomatoMeter', ''),\n",
        "            'release_date': first_review.get('releaseDateTheaters', ''),\n",
        "            'runtime': first_review.get('runtimeMinutes', ''),\n",
        "            'total_reviews': len(movie_reviews),\n",
        "            'review_count': len(movie_reviews)\n",
        "        }\n",
        "        \n",
        "        # Create rich content for embedding - start with movie info\n",
        "        content = f\"Movie: {first_review.get('title_clean', str(movie_id))}\\\\n\"\n",
        "        \n",
        "        # Add movie metadata\n",
        "        if first_review.get('genre_clean'):\n",
        "            content += f\"Genre: {first_review.get('genre_clean')}\\\\n\"\n",
        "        if first_review.get('director_clean'):\n",
        "            content += f\"Director: {first_review.get('director_clean')}\\\\n\"\n",
        "        if first_review.get('rating'):\n",
        "            content += f\"Rating: {first_review.get('rating')}\\\\n\"\n",
        "        if first_review.get('releaseDateTheaters'):\n",
        "            content += f\"Release Date: {first_review.get('releaseDateTheaters')}\\\\n\"\n",
        "        if first_review.get('audienceScore'):\n",
        "            content += f\"Audience Score: {first_review.get('audienceScore')}%\\\\n\"\n",
        "        if first_review.get('tomatoMeter'):\n",
        "            content += f\"Tomato Meter: {first_review.get('tomatoMeter')}%\\\\n\"\n",
        "        if first_review.get('runtimeMinutes'):\n",
        "            content += f\"Runtime: {first_review.get('runtimeMinutes')} minutes\\\\n\"\n",
        "        \n",
        "        # Add review count\n",
        "        content += f\"Total Reviews: {len(movie_reviews)}\\\\n\\\\n\"\n",
        "        \n",
        "        # Add all reviews for this movie (with character limits)\n",
        "        content += \"Reviews:\\\\n\"\n",
        "        review_count = 0\n",
        "        total_chars = len(content)  # Start with the content we've already added\n",
        "        max_chars_per_movie = 10000  # Limit total characters per movie (reduced from 20000)\n",
        "        \n",
        "        for idx, review in movie_reviews.iterrows():\n",
        "            # Check if we're approaching the character limit\n",
        "            if total_chars > max_chars_per_movie:\n",
        "                remaining_reviews = len(movie_reviews) - review_count\n",
        "                content += f\"\\\\n... [Additional {remaining_reviews} reviews truncated due to character limit]\\\\n\"\n",
        "                break\n",
        "                \n",
        "            # Calculate how many characters this review will add\n",
        "            critic_name = review.get('criticName_clean', 'Anonymous')\n",
        "            publication = review.get('publicatioName_clean', 'Unknown')\n",
        "            review_text = review.get('reviewText_clean', '')\n",
        "            \n",
        "            # Estimate characters this review will add\n",
        "            review_header = f\"\\\\n--- Review {idx + 1} ---\\\\n\"\n",
        "            critic_line = f\"Critic: {critic_name}\"\n",
        "            if publication != 'Unknown':\n",
        "                critic_line += f\" ({publication})\"\n",
        "            critic_line += \"\\\\n\"\n",
        "            \n",
        "            score_lines = \"\"\n",
        "            if review.get('originalScore'):\n",
        "                score_lines += f\"Score: {review.get('originalScore')}\\\\n\"\n",
        "            if review.get('scoreSentiment'):\n",
        "                score_lines += f\"Sentiment: {review.get('scoreSentiment')}\\\\n\"\n",
        "            if review.get('reviewState'):\n",
        "                score_lines += f\"Status: {review.get('reviewState')}\\\\n\"\n",
        "            \n",
        "            # Truncate review text if needed (reduced from 500 to 250 chars)\n",
        "            if review_text and len(review_text) > 250:\n",
        "                review_text = review_text[:250] + \"...\"\n",
        "            \n",
        "            review_content = f\"Review: {review_text}\\\\n\" if review_text else \"\"\n",
        "            \n",
        "            # Calculate total characters for this review\n",
        "            review_chars = len(review_header) + len(critic_line) + len(score_lines) + len(review_content)\n",
        "            \n",
        "            # Check if adding this review would exceed the limit\n",
        "            if total_chars + review_chars > max_chars_per_movie:\n",
        "                remaining_reviews = len(movie_reviews) - review_count\n",
        "                content += f\"\\\\n... [Additional {remaining_reviews} reviews truncated due to character limit]\\\\n\"\n",
        "                break\n",
        "            \n",
        "            # Add the review content\n",
        "            content += review_header\n",
        "            content += critic_line\n",
        "            content += score_lines\n",
        "            content += review_content\n",
        "            \n",
        "            review_count += 1\n",
        "            total_chars += review_chars\n",
        "        \n",
        "        documents.append({\n",
        "            'content': content,\n",
        "            'metadata': metadata\n",
        "        })\n",
        "        \n",
        "        movie_count += 1\n",
        "    \n",
        "    print(f\"âœ… Created {len(documents)} movie documents from {movie_count} movies\")\n",
        "    return documents\n",
        "\n",
        "# Create documents from merged Rotten Tomatoes data\n",
        "print(\"ğŸ… Creating movie documents from Rotten Tomatoes data...\")\n",
        "all_documents = create_review_documents(merged_df, max_movies=100, min_reviews=5)\n",
        "\n",
        "print(f\"âœ… Created {len(all_documents)} total review documents\")\n",
        "print(f\"   - Source: Rotten Tomatoes\")\n",
        "print(f\"   - Reviews with movie metadata included\")\n",
        "\n",
        "# Show sample document\n",
        "print(\"\\\\nğŸ“„ Sample document:\")\n",
        "print(all_documents[0]['content'][:300] + \"...\")\n",
        "\n",
        "# Show metadata sample\n",
        "print(\"\\\\nğŸ·ï¸ Sample metadata:\")\n",
        "sample_metadata = all_documents[0]['metadata']\n",
        "for key, value in list(sample_metadata.items())[:8]:  # Show first 8 metadata fields\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "# Basic statistics\n",
        "print(f\"\\\\nğŸ“Š Document Statistics:\")\n",
        "unique_movies = len(set([doc['metadata']['movie_title'] for doc in all_documents]))\n",
        "#unique_critics = len(set([doc['metadata']['criticName'] for doc in all_documents]))\n",
        "print(f\"â€¢ Unique movies: {unique_movies}\")\n",
        "#print(f\"â€¢ Unique critics: {unique_critics}\")\n",
        "print(f\"â€¢ Average content length: {np.mean([len(doc['content']) for doc in all_documents]):.0f} characters\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 3: Setup Basic RAG Components\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”ª Using each movie as a separate chunk...\n",
            "âœ… Created 100 chunks from 100 movies\n",
            "   Each movie is treated as a separate chunk containing all its reviews for better semantic coherence\n",
            "ğŸ“ Maximum chunk length: 2841 tokens\n",
            "ğŸ“ Average chunk length: 2679 tokens\n",
            "ğŸ§  Initializing embedding model...\n",
            "âœ… Basic RAG components initialized!\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "from langchain_openai.embeddings import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import Qdrant\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langgraph.graph import START, StateGraph\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "# Token counting function\n",
        "def tiktoken_len(text):\n",
        "    tokens = tiktoken.encoding_for_model(\"gpt-4o\").encode(text)\n",
        "    return len(tokens)\n",
        "\n",
        "# Convert our documents to LangChain Document format - each movie is already a chunk\n",
        "print(\"ğŸ”ª Using each movie as a separate chunk...\")\n",
        "chunks = []\n",
        "for doc in all_documents:\n",
        "    langchain_doc = Document(\n",
        "        page_content=doc['content'],\n",
        "        metadata=doc['metadata']\n",
        "    )\n",
        "    chunks.append(langchain_doc)\n",
        "\n",
        "print(f\"âœ… Created {len(chunks)} chunks from {len(all_documents)} movies\")\n",
        "print(\"   Each movie is treated as a separate chunk containing all its reviews for better semantic coherence\")\n",
        "\n",
        "# Verify chunk sizes\n",
        "chunk_lengths = [tiktoken_len(chunk.page_content) for chunk in chunks]\n",
        "max_chunk_length = max(chunk_lengths)\n",
        "avg_chunk_length = sum(chunk_lengths) / len(chunk_lengths)\n",
        "print(f\"ğŸ“ Maximum chunk length: {max_chunk_length} tokens\")\n",
        "print(f\"ğŸ“ Average chunk length: {avg_chunk_length:.0f} tokens\")\n",
        "\n",
        "# Initialize embedding model\n",
        "print(\"ğŸ§  Initializing embedding model...\")\n",
        "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "# Initialize chat model\n",
        "chat_model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1)\n",
        "\n",
        "print(\"âœ… Basic RAG components initialized!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 4: Setup Enhanced Agent Tools and External Search\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”§ Setting up external search tools...\n",
            "âœ… Tavily search tool configured\n",
            "âœ… SerpAPI search tool configured\n",
            "ğŸ” Using Tavily for external search\n",
            "\\nğŸ§ª Testing Tavily search...\n",
            "âœ… Search test successful: Found 3 results\n"
          ]
        }
      ],
      "source": [
        "# External search tools setup\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_community.utilities import SerpAPIWrapper\n",
        "from langchain.tools import Tool\n",
        "from langchain_core.tools import tool\n",
        "import json\n",
        "\n",
        "# Setup external search tools\n",
        "print(\"ğŸ”§ Setting up external search tools...\")\n",
        "\n",
        "# Option 1: Tavily Search (recommended - often has free tier)\n",
        "try:\n",
        "    tavily_search = TavilySearchResults(\n",
        "        max_results=3,\n",
        "        search_depth=\"basic\",\n",
        "        include_answer=True,\n",
        "        include_raw_content=True\n",
        "    )\n",
        "    print(\"âœ… Tavily search tool configured\")\n",
        "    has_tavily = True\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Tavily not configured: {e}\")\n",
        "    has_tavily = False\n",
        "\n",
        "# Option 2: SerpAPI (Google Search) - backup option\n",
        "try:\n",
        "    search = SerpAPIWrapper()\n",
        "    serp_tool = Tool(\n",
        "        name=\"google_search\",\n",
        "        description=\"Search Google for current information about movies, actors, reviews, or box office data\",\n",
        "        func=search.run,\n",
        "    )\n",
        "    print(\"âœ… SerpAPI search tool configured\")\n",
        "    has_serp = True\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ SerpAPI not configured: {e}\")\n",
        "    has_serp = False\n",
        "\n",
        "# Create a fallback search function if no external APIs are configured\n",
        "def fallback_search(query: str) -> str:\n",
        "    \"\"\"Fallback search when no external APIs are available\"\"\"\n",
        "    return f\"External search not available. Query '{query}' would require external movie database access. Please configure Tavily API key (https://tavily.com/) or SerpAPI key (https://serpapi.com/) for enhanced search capabilities.\"\n",
        "\n",
        "# Choose which search tool to use\n",
        "if has_tavily:\n",
        "    external_search_tool = tavily_search\n",
        "    search_tool_name = \"Tavily\"\n",
        "elif has_serp:\n",
        "    external_search_tool = serp_tool\n",
        "    search_tool_name = \"SerpAPI\"\n",
        "else:\n",
        "    external_search_tool = Tool(\n",
        "        name=\"fallback_search\",\n",
        "        description=\"Fallback search tool when external APIs are not configured\",\n",
        "        func=fallback_search\n",
        "    )\n",
        "    search_tool_name = \"Fallback\"\n",
        "\n",
        "print(f\"ğŸ” Using {search_tool_name} for external search\")\n",
        "\n",
        "# Test the search tool\n",
        "print(f\"\\\\nğŸ§ª Testing {search_tool_name} search...\")\n",
        "try:\n",
        "    if has_tavily:\n",
        "        test_result = external_search_tool.invoke({\"query\": \"Inception movie reviews 2010\"})\n",
        "        print(f\"âœ… Search test successful: Found {len(test_result)} results\")\n",
        "    elif has_serp:\n",
        "        test_result = external_search_tool.run(\"Inception movie reviews 2010\")\n",
        "        print(f\"âœ… Search test successful: {test_result[:100]}...\")\n",
        "    else:\n",
        "        test_result = external_search_tool.run(\"Inception movie reviews 2010\")\n",
        "        print(f\"âš ï¸ Using fallback search: {test_result}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Search test failed: {e}\")\n",
        "    print(\"ğŸ’¡ You can continue without external search - the agent will use only embedded reviews\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ› ï¸ Creating specialized agent tools for Rotten Tomatoes data...\n",
            "âœ… Created search_movie_reviews tool\n"
          ]
        }
      ],
      "source": [
        "# Create specialized tools for Rotten Tomatoes movie analysis\n",
        "print(\"ğŸ› ï¸ Creating specialized agent tools for Rotten Tomatoes data...\")\n",
        "\n",
        "# We'll create a placeholder retriever that will be swapped out during evaluation\n",
        "# This will be replaced with different retrievers during testing\n",
        "def get_base_retriever():\n",
        "    \"\"\"Get the base retriever - this will be swapped during evaluation\"\"\"\n",
        "    # Create a default vectorstore for now\n",
        "    vectorstore = Qdrant.from_documents(\n",
        "        chunks,\n",
        "        embedding_model,\n",
        "        location=\":memory:\",\n",
        "        collection_name=\"MovieReviews\"\n",
        "    )\n",
        "    return vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
        "\n",
        "# Initialize base retriever\n",
        "base_retriever = get_base_retriever()\n",
        "\n",
        "# Create basic RAG chain components for tools\n",
        "HUMAN_TEMPLATE = \"\"\"\n",
        "You are a knowledgeable movie critic and analyst. You have access to a database of movie reviews from Rotten Tomatoes.\n",
        "\n",
        "Use the provided context to answer the user's question about movies, reviews, ratings, and trends. Only use the information provided in the context. If the context doesn't contain relevant information to answer the question, respond with \"I don't have enough information to answer that question based on the available reviews.\"\n",
        "\n",
        "When analyzing reviews, consider:\n",
        "- Professional critic perspectives and ratings\n",
        "- Review states (fresh/rotten) and sentiment analysis  \n",
        "- Tomatometer and audience score patterns\n",
        "- Publication sources and critic credentials\n",
        "- Movie metadata (genre, director, release date, runtime)\n",
        "\n",
        "CONTEXT:\n",
        "{context}\n",
        "\n",
        "QUESTION:\n",
        "{question}\n",
        "\n",
        "Provide a comprehensive and insightful answer based on the available review data.\n",
        "\"\"\"\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"human\", HUMAN_TEMPLATE)\n",
        "])\n",
        "\n",
        "# Define state structure for enhanced RAG\n",
        "class State(TypedDict):\n",
        "    question: str\n",
        "    context: List[Document]\n",
        "    response: str\n",
        "\n",
        "# Tool 1: Movie Review Search (our main RAG)\n",
        "@tool\n",
        "def search_movie_reviews(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Search through embedded movie reviews from Rotten Tomatoes.\n",
        "    Use this for questions about specific movies, ratings, or review content.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Use the current base_retriever (will be swapped during evaluation)\n",
        "        retrieved_docs = base_retriever.get_relevant_documents(query)\n",
        "        \n",
        "        # Generate response using RAG\n",
        "        generator_chain = chat_prompt | chat_model | StrOutputParser()\n",
        "        response = generator_chain.invoke({\n",
        "            \"question\": query, \n",
        "            \"context\": retrieved_docs\n",
        "        })\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        return f\"Error searching reviews: {str(e)}\"\n",
        "\n",
        "print(\"âœ… Created search_movie_reviews tool\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Created analyze_movie_statistics tool\n"
          ]
        }
      ],
      "source": [
        "# Tool 2: Movie Statistics Analysis\n",
        "@tool\n",
        "def analyze_movie_statistics(movie_name: str = \"\") -> str:\n",
        "    \"\"\"\n",
        "    Analyze statistics for a specific movie or provide general Rotten Tomatoes dataset statistics.\n",
        "    Returns ratings, review counts, critic information, and other numerical insights.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if movie_name:\n",
        "            # Search for specific movie in the merged dataset\n",
        "            movie_data = merged_df[\n",
        "                merged_df['title_clean'].str.contains(movie_name, case=False, na=False)\n",
        "            ]\n",
        "            \n",
        "            if movie_data.empty:\n",
        "                return f\"No statistics found for '{movie_name}' in the Rotten Tomatoes dataset.\"\n",
        "            \n",
        "            # Get movie information\n",
        "            movie_info = movie_data.iloc[0]  # Get first match for movie metadata\n",
        "            movie_reviews = movie_data  # All reviews for this movie\n",
        "            \n",
        "            stats = f\"Statistics for '{movie_info.get('title_clean', movie_name)}':\\\\n\"\n",
        "            stats += f\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\\\n\"\n",
        "            \n",
        "            # Movie metadata\n",
        "            if movie_info.get('genre_clean'):\n",
        "                stats += f\"ğŸ­ Genre: {movie_info['genre_clean']}\\\\n\"\n",
        "            if movie_info.get('director_clean'):\n",
        "                stats += f\"ğŸ¬ Director: {movie_info['director_clean']}\\\\n\"\n",
        "            if movie_info.get('rating'):\n",
        "                stats += f\"ğŸ·ï¸ Rating: {movie_info['rating']}\\\\n\"\n",
        "            if movie_info.get('runtimeMinutes'):\n",
        "                stats += f\"â±ï¸ Runtime: {movie_info['runtimeMinutes']} minutes\\\\n\"\n",
        "            if movie_info.get('releaseDateTheaters'):\n",
        "                stats += f\"ğŸ“… Release Date: {movie_info['releaseDateTheaters']}\\\\n\"\n",
        "            \n",
        "            # Scores\n",
        "            if pd.notna(movie_info.get('audienceScore')):\n",
        "                stats += f\"ğŸ‘¥ Audience Score: {movie_info['audienceScore']}%\\\\n\"\n",
        "            if pd.notna(movie_info.get('tomatoMeter')):\n",
        "                stats += f\"ğŸ… Tomatometer: {movie_info['tomatoMeter']}%\\\\n\"\n",
        "            \n",
        "            # Review statistics\n",
        "            stats += f\"\\\\nğŸ“Š Review Analysis:\\\\n\"\n",
        "            stats += f\"â€¢ Total Reviews: {len(movie_reviews)}\\\\n\"\n",
        "            \n",
        "            # Review state distribution\n",
        "            if 'reviewState' in movie_reviews.columns:\n",
        "                review_states = movie_reviews['reviewState'].value_counts()\n",
        "                for state, count in review_states.items():\n",
        "                    stats += f\"â€¢ {state.title()}: {count} reviews\\\\n\"\n",
        "            \n",
        "            # Sentiment distribution\n",
        "            if 'scoreSentiment' in movie_reviews.columns:\n",
        "                sentiments = movie_reviews['scoreSentiment'].value_counts()\n",
        "                stats += f\"\\\\nğŸ­ Sentiment Breakdown:\\\\n\"\n",
        "                for sentiment, count in sentiments.items():\n",
        "                    stats += f\"â€¢ {sentiment}: {count} reviews\\\\n\"\n",
        "            \n",
        "            # Top critics\n",
        "            top_critics = movie_reviews[movie_reviews['isTopCritic'] == True]\n",
        "            if len(top_critics) > 0:\n",
        "                stats += f\"â€¢ Top Critics: {len(top_critics)} reviews\\\\n\"\n",
        "            \n",
        "            return stats\n",
        "        else:\n",
        "            # General dataset statistics\n",
        "            stats = f\"ğŸ… Rotten Tomatoes Dataset Statistics:\\\\n\"\n",
        "            stats += f\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\\\n\"\n",
        "            stats += f\"ğŸ“Š Overview:\\\\n\"\n",
        "            stats += f\"â€¢ Total Movies: {len(movies_df):,}\\\\n\"\n",
        "            stats += f\"â€¢ Total Reviews: {len(reviews_df):,}\\\\n\"\n",
        "            stats += f\"â€¢ Reviews in Current Sample: {len(merged_df):,}\\\\n\"\n",
        "            stats += f\"â€¢ Average Reviews per Movie: {len(reviews_df)/len(movies_df):.1f}\\\\n\"\n",
        "            \n",
        "            # Genre distribution (top 5)\n",
        "            if 'genre_clean' in merged_df.columns:\n",
        "                top_genres = merged_df['genre_clean'].value_counts().head(5)\n",
        "                stats += f\"\\\\nğŸ­ Top Genres:\\\\n\"\n",
        "                for genre, count in top_genres.items():\n",
        "                    if pd.notna(genre):\n",
        "                        stats += f\"â€¢ {genre}: {count} reviews\\\\n\"\n",
        "            \n",
        "            # Review state distribution\n",
        "            if 'reviewState' in merged_df.columns:\n",
        "                review_states = merged_df['reviewState'].value_counts()\n",
        "                stats += f\"\\\\nğŸ† Review States:\\\\n\"\n",
        "                for state, count in review_states.items():\n",
        "                    stats += f\"â€¢ {state}: {count} reviews\\\\n\"\n",
        "            \n",
        "            # Top critics\n",
        "            top_critics_count = merged_df[merged_df['isTopCritic'] == True]\n",
        "            stats += f\"\\\\nâ­ Critics:\\\\n\"\n",
        "            stats += f\"â€¢ Top Critics: {len(top_critics_count):,} reviews\\\\n\"\n",
        "            stats += f\"â€¢ Regular Critics: {len(merged_df) - len(top_critics_count):,} reviews\\\\n\"\n",
        "            \n",
        "            return stats\n",
        "            \n",
        "    except Exception as e:\n",
        "        return f\"Error analyzing statistics: {str(e)}\"\n",
        "\n",
        "print(\"âœ… Created analyze_movie_statistics tool\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Created 4 specialized tools for Rotten Tomatoes:\n",
            "  - search_movie_reviews: Search through embedded movie reviews from Rotten Tomatoes.\n",
            "Use this for questions about specific movies, ratings, or review content.\n",
            "  - analyze_movie_statistics: Analyze statistics for a specific movie or provide general Rotten Tomatoes dataset statistics.\n",
            "Returns ratings, review counts, critic information, and other numerical insights.\n",
            "  - analyze_movie_ratings: Analyze ratings and review sentiment for a specific movie from Rotten Tomatoes.\n",
            "Shows audience score, tomatometer, critic consensus, and sentiment analysis.\n",
            "  - search_external_movie_info: Search external sites (IMDb, Metacritic, Letterboxd, Rotten Tomatoes, etc.)\n",
            "for reviews, ratings, or recent news about a movie.\n",
            "\\nâœ… All Rotten Tomatoes agent tools ready!\n"
          ]
        }
      ],
      "source": [
        "# Tool 3: Rating and Review Analysis Tool\n",
        "@tool\n",
        "def analyze_movie_ratings(movie_name: str) -> str:\n",
        "    \"\"\"\n",
        "    Analyze ratings and review sentiment for a specific movie from Rotten Tomatoes.\n",
        "    Shows audience score, tomatometer, critic consensus, and sentiment analysis.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        movie_data = merged_df[\n",
        "            merged_df['title_clean'].str.contains(movie_name, case=False, na=False)\n",
        "        ]\n",
        "        \n",
        "        if movie_data.empty:\n",
        "            return f\"No rating data found for '{movie_name}' in Rotten Tomatoes dataset.\"\n",
        "        \n",
        "        movie_info = movie_data.iloc[0]\n",
        "        \n",
        "        analysis = f\"ğŸ… Rotten Tomatoes Analysis for '{movie_info.get('title_clean', movie_name)}':\\\\n\"\n",
        "        analysis += f\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\\\n\"\n",
        "        \n",
        "        # Official scores\n",
        "        if pd.notna(movie_info.get('tomatoMeter')):\n",
        "            analysis += f\"ğŸ… Tomatometer: {movie_info['tomatoMeter']}% (Critics)\\\\n\"\n",
        "        if pd.notna(movie_info.get('audienceScore')):\n",
        "            analysis += f\"ğŸ¿ Audience Score: {movie_info['audienceScore']}%\\\\n\"\n",
        "        \n",
        "        # Review breakdown\n",
        "        fresh_reviews = movie_data[movie_data['reviewState'] == 'fresh']\n",
        "        rotten_reviews = movie_data[movie_data['reviewState'] == 'rotten']\n",
        "        \n",
        "        analysis += f\"\\\\nğŸ“Š Review Breakdown:\\\\n\"\n",
        "        analysis += f\"â€¢ Fresh Reviews: {len(fresh_reviews)}\\\\n\"\n",
        "        analysis += f\"â€¢ Rotten Reviews: {len(rotten_reviews)}\\\\n\"\n",
        "        if len(movie_data) > 0:\n",
        "            fresh_percentage = (len(fresh_reviews) / len(movie_data)) * 100\n",
        "            analysis += f\"â€¢ Fresh Percentage: {fresh_percentage:.1f}%\\\\n\"\n",
        "        \n",
        "        # Sentiment analysis\n",
        "        positive_reviews = movie_data[movie_data['scoreSentiment'] == 'POSITIVE']\n",
        "        negative_reviews = movie_data[movie_data['scoreSentiment'] == 'NEGATIVE']\n",
        "        \n",
        "        analysis += f\"\\\\nğŸ­ Sentiment Analysis:\\\\n\"\n",
        "        analysis += f\"â€¢ Positive: {len(positive_reviews)} reviews\\\\n\"\n",
        "        analysis += f\"â€¢ Negative: {len(negative_reviews)} reviews\\\\n\"\n",
        "        \n",
        "        # Top critics vs regular critics\n",
        "        top_critic_reviews = movie_data[movie_data['isTopCritic'] == True]\n",
        "        regular_reviews = movie_data[movie_data['isTopCritic'] == False]\n",
        "        \n",
        "        analysis += f\"\\\\nâ­ Critic Breakdown:\\\\n\"\n",
        "        analysis += f\"â€¢ Top Critics: {len(top_critic_reviews)} reviews\\\\n\"\n",
        "        analysis += f\"â€¢ Regular Critics: {len(regular_reviews)} reviews\\\\n\"\n",
        "        \n",
        "        return analysis\n",
        "        \n",
        "    except Exception as e:\n",
        "        return f\"Error analyzing ratings: {str(e)}\"\n",
        "\n",
        "# Tool 4: External Movie Search (when local data is insufficient)\n",
        "@tool\n",
        "def search_external_movie_info(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Search external sites (IMDb, Metacritic, Letterboxd, Rotten Tomatoes, etc.)\n",
        "    for reviews, ratings, or recent news about a movie.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Build a richer multi-site query\n",
        "        review_sites = [\n",
        "            \"Rotten Tomatoes\", \"IMDb\", \"Metacritic\", \"Letterboxd\",\n",
        "            \"Roger Ebert\", \"The Guardian film review\"\n",
        "        ]\n",
        "        joined_sites = \" OR \".join(f'\"{site}\"' for site in review_sites)\n",
        "        search_string = f'movie {query} reviews ratings {joined_sites}'\n",
        "\n",
        "        # Dispatch to whichever external search tool you have\n",
        "        if has_tavily:\n",
        "            result = external_search_tool.invoke({\"query\": search_string})\n",
        "            # Tavily returns a list of dicts â†’ format the first three nicely\n",
        "            snippets = []\n",
        "            for item in result[:3]:\n",
        "                if isinstance(item, dict):\n",
        "                    url     = item.get(\"url\", \"\")\n",
        "                    content = (item.get(\"content\", \"\") or \"\").strip()\n",
        "                    snippets.append(f\"Source: {url}\\\\n{content[:200]}â€¦\")\n",
        "            return \"\\\\n\\\\n\".join(snippets) if snippets else \"No results found.\"\n",
        "        \n",
        "        elif has_serp:\n",
        "            raw = external_search_tool.run(search_string)\n",
        "            return raw[:500] + \"â€¦\" if len(raw) > 500 else raw\n",
        "        \n",
        "        else:  # generic `.run` fallback\n",
        "            return external_search_tool.run(search_string)\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"External search error: {e}\"\n",
        "\n",
        "# Create the agent's toolbox for Rotten Tomatoes analysis\n",
        "agent_tools = [\n",
        "    search_movie_reviews,\n",
        "    analyze_movie_statistics, \n",
        "    analyze_movie_ratings,\n",
        "    search_external_movie_info\n",
        "]\n",
        "\n",
        "print(f\"âœ… Created {len(agent_tools)} specialized tools for Rotten Tomatoes:\")\n",
        "for tool in agent_tools:\n",
        "    print(f\"  - {tool.name}: {tool.description}\")\n",
        "\n",
        "print(\"\\\\nâœ… All Rotten Tomatoes agent tools ready!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 5: Setup Enhanced Agent with Tool Selection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¤– Building enhanced agent with tool selection...\n",
            "âœ… Enhanced agent nodes defined!\n"
          ]
        }
      ],
      "source": [
        "# Enhanced Agent State with Tool Selection\n",
        "from typing_extensions import TypedDict, Annotated\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[list[BaseMessage], add_messages]\n",
        "    question: str\n",
        "    tool_calls: list\n",
        "    final_answer: str\n",
        "\n",
        "# Enhanced Agent with tool selection capabilities\n",
        "print(\"ğŸ¤– Building enhanced agent with tool selection...\")\n",
        "\n",
        "# Create the agent prompt\n",
        "AGENT_PROMPT = \"\"\"You are an intelligent movie analysis agent with access to multiple specialized tools.\n",
        "\n",
        "Your tools:\n",
        "1. search_movie_reviews: Search embedded movie reviews from Rotten Tomatoes\n",
        "2. analyze_movie_statistics: Get numerical statistics about movies and datasets  \n",
        "3. analyze_movie_ratings: Analyze ratings and review sentiment for specific movies\n",
        "4. search_external_movie_info: Search external sources when local data is insufficient\n",
        "\n",
        "Guidelines:\n",
        "- Start with local review data (search_movie_reviews) for most questions\n",
        "- Use statistics tools for numerical analysis\n",
        "- Use rating analysis for detailed movie performance breakdown\n",
        "- Only use external search when local data is clearly insufficient\n",
        "- Always explain your reasoning and cite sources\n",
        "- Provide comprehensive, insightful answers\n",
        "\n",
        "Current question: {question}\n",
        "\"\"\"\n",
        "\n",
        "# Create enhanced chat model with tool binding\n",
        "agent_model = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\", \n",
        "    temperature=0.1,\n",
        "    max_tokens=1000\n",
        ").bind_tools(agent_tools)\n",
        "\n",
        "def agent_reasoning_node(state: AgentState) -> AgentState:\n",
        "    \"\"\"Agent reasoning and tool selection\"\"\"\n",
        "    question = state[\"question\"]\n",
        "    messages = state.get(\"messages\", [])\n",
        "    \n",
        "    # Create the prompt with current question\n",
        "    prompt_message = HumanMessage(content=AGENT_PROMPT.format(question=question))\n",
        "    \n",
        "    # Get agent response with potential tool calls\n",
        "    response = agent_model.invoke([prompt_message] + messages)\n",
        "    \n",
        "    return {\n",
        "        \"messages\": [response],\n",
        "        \"tool_calls\": response.tool_calls if hasattr(response, 'tool_calls') and response.tool_calls else []\n",
        "    }\n",
        "\n",
        "def tool_execution_node(state: AgentState) -> AgentState:\n",
        "    \"\"\"Execute selected tools\"\"\"\n",
        "    tool_calls = state.get(\"tool_calls\", [])\n",
        "    messages = []\n",
        "    \n",
        "    for tool_call in tool_calls:\n",
        "        tool_name = tool_call[\"name\"]\n",
        "        tool_args = tool_call[\"args\"]\n",
        "        \n",
        "        # Find and execute the tool\n",
        "        for tool in agent_tools:\n",
        "            if tool.name == tool_name:\n",
        "                try:\n",
        "                    result = tool.invoke(tool_args)\n",
        "                    # Create tool message\n",
        "                    tool_message = ToolMessage(\n",
        "                        content=str(result),\n",
        "                        tool_call_id=tool_call[\"id\"]\n",
        "                    )\n",
        "                    messages.append(tool_message)\n",
        "                except Exception as e:\n",
        "                    error_message = ToolMessage(\n",
        "                        content=f\"Error executing {tool_name}: {str(e)}\",\n",
        "                        tool_call_id=tool_call[\"id\"]\n",
        "                    )\n",
        "                    messages.append(error_message)\n",
        "                break\n",
        "    \n",
        "    return {\"messages\": messages}\n",
        "\n",
        "def final_response_node(state: AgentState) -> AgentState:\n",
        "    \"\"\"Generate final response based on tool results\"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "    question = state[\"question\"]\n",
        "    \n",
        "    # Create final prompt\n",
        "    final_prompt = f\"\"\"\n",
        "    Based on the tool results above, provide a comprehensive answer to the question: {question}\n",
        "    \n",
        "    Make sure to:\n",
        "    - Synthesize information from multiple sources\n",
        "    - Cite specific data points and sources\n",
        "    - Provide insights beyond just raw data\n",
        "    - Be conversational but informative\n",
        "    \"\"\"\n",
        "    \n",
        "    final_response = chat_model.invoke(messages + [HumanMessage(content=final_prompt)])\n",
        "    \n",
        "    return {\n",
        "        \"final_answer\": final_response.content,\n",
        "        \"messages\": [final_response]\n",
        "    }\n",
        "\n",
        "print(\"âœ… Enhanced agent nodes defined!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”— Building agent workflow...\n",
            "âœ… Enhanced agent with tool selection ready!\n",
            "ğŸ¯ LangSmith project: Movie-Reviews-Enhanced-RAG-7de23b06\n",
            "ğŸš€ Enhanced agent ready for complex movie analysis!\n",
            "âœ… LangSmith tracing configured for evaluation!\n"
          ]
        }
      ],
      "source": [
        "# Build the enhanced agent graph\n",
        "print(\"ğŸ”— Building agent workflow...\")\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "# Create agent graph\n",
        "agent_graph = StateGraph(AgentState)\n",
        "\n",
        "# Add nodes\n",
        "agent_graph.add_node(\"agent\", agent_reasoning_node)\n",
        "agent_graph.add_node(\"tools\", ToolNode(agent_tools))\n",
        "agent_graph.add_node(\"final_response\", final_response_node)\n",
        "\n",
        "# Add edges\n",
        "agent_graph.add_edge(START, \"agent\")\n",
        "\n",
        "# Conditional edge: if agent makes tool calls, go to tools; otherwise go to final response\n",
        "def should_continue(state: AgentState) -> str:\n",
        "    tool_calls = state.get(\"tool_calls\", [])\n",
        "    if tool_calls:\n",
        "        return \"tools\"\n",
        "    else:\n",
        "        return \"final_response\"\n",
        "\n",
        "agent_graph.add_conditional_edges(\"agent\", should_continue)\n",
        "agent_graph.add_edge(\"tools\", \"final_response\")\n",
        "agent_graph.add_edge(\"final_response\", END)\n",
        "\n",
        "# Compile the enhanced agent\n",
        "enhanced_agent = agent_graph.compile()\n",
        "\n",
        "print(\"âœ… Enhanced agent with tool selection ready!\")\n",
        "\n",
        "# Generate unique project ID for this session\n",
        "unique_id = uuid4().hex[:8]\n",
        "project_name = f\"Movie-Reviews-Enhanced-RAG-{unique_id}\"\n",
        "\n",
        "# Configure LangSmith if available\n",
        "if os.getenv(\"LANGSMITH_API_KEY\"):\n",
        "    os.environ[\"LANGSMITH_PROJECT\"] = project_name\n",
        "    print(f\"ğŸ¯ LangSmith project: {project_name}\")\n",
        "\n",
        "# Create a query function for the enhanced agent with tracing\n",
        "def query_enhanced_agent_with_tracing(question: str, run_name: str = None) -> Dict[str, Any]:\n",
        "    \"\"\"Query the enhanced agent with LangSmith tracing\"\"\"\n",
        "    \n",
        "    # Generate run name if not provided\n",
        "    if not run_name:\n",
        "        run_name = f\"movie_query_{int(time.time())}\"\n",
        "    \n",
        "    # Add tags for better organization\n",
        "    tags = [\"movie-reviews\", \"rag-agent\", \"multi-tool\"]\n",
        "    \n",
        "    try:\n",
        "        # Execute with tracing metadata\n",
        "        start_time = time.time()\n",
        "        \n",
        "        result = enhanced_agent.invoke(\n",
        "            {\n",
        "                \"question\": question,\n",
        "                \"messages\": [],\n",
        "                \"tool_calls\": [],\n",
        "                \"final_answer\": \"\"\n",
        "            },\n",
        "            config={\n",
        "                \"tags\": tags,\n",
        "                \"metadata\": {\n",
        "                    \"query_type\": \"movie_analysis\",\n",
        "                    \"session_id\": unique_id,\n",
        "                    \"run_name\": run_name\n",
        "                }\n",
        "            }\n",
        "        )\n",
        "        \n",
        "        end_time = time.time()\n",
        "        execution_time = end_time - start_time\n",
        "        \n",
        "        return {\n",
        "            \"question\": question,\n",
        "            \"answer\": result.get(\"final_answer\", \"No answer generated\"),\n",
        "            \"tool_calls_made\": len(result.get(\"tool_calls\", [])),\n",
        "            \"execution_time\": execution_time,\n",
        "            \"run_name\": run_name,\n",
        "            \"success\": True\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"question\": question,\n",
        "            \"answer\": f\"Error: {str(e)}\",\n",
        "            \"tool_calls_made\": 0,\n",
        "            \"execution_time\": 0,\n",
        "            \"run_name\": run_name,\n",
        "            \"success\": False\n",
        "        }\n",
        "\n",
        "print(\"ğŸš€ Enhanced agent ready for complex movie analysis!\")\n",
        "print(\"âœ… LangSmith tracing configured for evaluation!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 6: Set Up Different Retrievers for Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting up different retrievers for evaluation...\n",
            "âœ… 1. Naive retriever ready\n",
            "âœ… 2. BM25 retriever ready\n",
            "âœ… 3. Multi-query retriever ready\n",
            "âœ… 4. Parent document retriever ready\n",
            "âœ… 5. Contextual compression retriever ready\n",
            "âœ… 6. Ensemble retriever ready\n",
            "\n",
            "âœ… All 6 retrievers ready for evaluation!\n",
            "  - Naive\n",
            "  - BM25\n",
            "  - Multi-Query\n",
            "  - Parent Document\n",
            "  - Contextual Compression\n",
            "  - Ensemble\n"
          ]
        }
      ],
      "source": [
        "# Import retriever components\n",
        "from langchain_community.vectorstores import Qdrant\n",
        "from langchain_community.retrievers import BM25Retriever\n",
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "from langchain.retrievers import ParentDocumentRetriever, EnsembleRetriever\n",
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain_cohere import CohereRerank\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_qdrant import QdrantVectorStore\n",
        "from qdrant_client import QdrantClient, models\n",
        "\n",
        "print(\"Setting up different retrievers for evaluation...\")\n",
        "\n",
        "# 1. Naive Retriever (Embedding-based)\n",
        "def create_naive_retriever():\n",
        "    vectorstore = Qdrant.from_documents(\n",
        "        chunks,\n",
        "        embedding_model,\n",
        "        location=\":memory:\",\n",
        "        collection_name=\"MovieReviews_Naive\"\n",
        "    )\n",
        "    return vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "naive_retriever = create_naive_retriever()\n",
        "print(\"âœ… 1. Naive retriever ready\")\n",
        "\n",
        "# 2. BM25 Retriever (Keyword-based)\n",
        "def create_bm25_retriever():\n",
        "    bm25 = BM25Retriever.from_documents(chunks)\n",
        "    bm25.k = 3\n",
        "    return bm25\n",
        "\n",
        "bm25_retriever = create_bm25_retriever()\n",
        "print(\"âœ… 2. BM25 retriever ready\")\n",
        "\n",
        "# 3. Multi-Query Retriever\n",
        "def create_multi_query_retriever():\n",
        "    base_retriever = create_naive_retriever()\n",
        "    return MultiQueryRetriever.from_llm(\n",
        "        retriever=base_retriever, \n",
        "        llm=chat_model\n",
        "    )\n",
        "\n",
        "multi_query_retriever = create_multi_query_retriever()\n",
        "print(\"âœ… 3. Multi-query retriever ready\")\n",
        "\n",
        "# 4. Parent Document Retriever\n",
        "def create_parent_document_retriever():\n",
        "    # Create smaller chunks for parent document retrieval\n",
        "    child_splitter = RecursiveCharacterTextSplitter(chunk_size=400)\n",
        "    \n",
        "    # Create new QdrantClient and collection for parent docs\n",
        "    client = QdrantClient(location=\":memory:\")\n",
        "    client.create_collection(\n",
        "        collection_name=\"movie_reviews_parent_docs\",\n",
        "        vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE)\n",
        "    )\n",
        "    \n",
        "    parent_document_vectorstore = QdrantVectorStore(\n",
        "        collection_name=\"movie_reviews_parent_docs\", \n",
        "        embedding=embedding_model, \n",
        "        client=client\n",
        "    )\n",
        "    \n",
        "    store = InMemoryStore()\n",
        "    parent_retriever = ParentDocumentRetriever(\n",
        "        vectorstore=parent_document_vectorstore,\n",
        "        docstore=store,\n",
        "        child_splitter=child_splitter,\n",
        "    )\n",
        "    \n",
        "    parent_retriever.add_documents(chunks, ids=None)\n",
        "    return parent_retriever\n",
        "\n",
        "parent_document_retriever = create_parent_document_retriever()\n",
        "print(\"âœ… 4. Parent document retriever ready\")\n",
        "\n",
        "# 5. Contextual Compression Retriever (with Cohere reranking)\n",
        "def create_compression_retriever():\n",
        "    base_retriever = create_naive_retriever()\n",
        "    compressor = CohereRerank(model=\"rerank-v3.5\")\n",
        "    return ContextualCompressionRetriever(\n",
        "        base_compressor=compressor, \n",
        "        base_retriever=base_retriever\n",
        "    )\n",
        "\n",
        "compression_retriever = create_compression_retriever()\n",
        "print(\"âœ… 5. Contextual compression retriever ready\")\n",
        "\n",
        "# 6. Ensemble Retriever (combines multiple approaches)\n",
        "def create_ensemble_retriever():\n",
        "    # Use fresh instances to avoid conflicts\n",
        "    naive = create_naive_retriever()\n",
        "    bm25 = create_bm25_retriever()\n",
        "    compression = create_compression_retriever()\n",
        "    \n",
        "    retrievers = [bm25, naive, compression]\n",
        "    weights = [0.4, 0.4, 0.2]  # Slightly favor BM25 and naive\n",
        "    \n",
        "    return EnsembleRetriever(\n",
        "        retrievers=retrievers, \n",
        "        weights=weights\n",
        "    )\n",
        "\n",
        "ensemble_retriever = create_ensemble_retriever()\n",
        "print(\"âœ… 6. Ensemble retriever ready\")\n",
        "\n",
        "# Store all retrievers for evaluation\n",
        "retrievers_to_evaluate = [\n",
        "    (\"Naive\", naive_retriever),\n",
        "    (\"BM25\", bm25_retriever),\n",
        "    (\"Multi-Query\", multi_query_retriever),\n",
        "    (\"Parent Document\", parent_document_retriever),\n",
        "    (\"Contextual Compression\", compression_retriever),\n",
        "    (\"Ensemble\", ensemble_retriever)\n",
        "]\n",
        "\n",
        "print(f\"\\nâœ… All {len(retrievers_to_evaluate)} retrievers ready for evaluation!\")\n",
        "for name, _ in retrievers_to_evaluate:\n",
        "    print(f\"  - {name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 7: Create Golden Dataset using RAGAS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¯ Generating Golden Test Set for Movie Reviews using RAGAS...\n",
            "======================================================================\n",
            "âœ… RAGAS models initialized\n",
            "ğŸ“„ Preparing documents for test set generation...\n",
            "   Selected 50 review documents for question generation\n",
            "âš™ï¸ Creating RAGAS test set generator...\n",
            "ğŸ”¬ Generating 10 movie review questions (this may take a few minutes)...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75c0bd3f177b4c34bcb1f158041b7d52",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying HeadlinesExtractor:   0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "440ab231f34f483f9b49641d4543e67c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying HeadlineSplitter:   0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b0af91164cf40c988fb1ccf0daf4f26",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying SummaryExtractor:   0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3e36bb0dea747e58a807e3e399ad49d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying CustomNodeFilter:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f69bd1bfd150400fba49765b28ec259b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/244 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a07cf84c5a924ad59dfde527754905ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "53756532d67c4b26a323f84d2024f1c6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e64bc16471d4ad29c406a1958d2fdd1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "446469164d7d45d7886099a1a33cc43d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Samples:   0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Synthetic test set generated successfully!\n",
            "\n",
            "ğŸ“Š Generated 12 synthetic test cases\n",
            "\n",
            "ğŸ“ Generated Movie Review Questions:\n",
            "--------------------------------------------------\n",
            "Q1: Who is Patricia Puentes and what did she say about Parasite?\n",
            "Expected: Patricia Puentes is a critic from CNET who provided a positive review of the film Parasite, stating ...\n",
            "--------------------------------------------------\n",
            "Q2: What insights does Catherine Springer from CathsFilmForum.com provide about the film Parasite?\n",
            "Expected: Catherine Springer from CathsFilmForum.com describes Parasite as visually stunning, thematically res...\n",
            "--------------------------------------------------\n",
            "Q3: What are the sentiments expressed by Eric Webb in his reviews of the film?\n",
            "Expected: Eric Webb, writing for the Austin American-Statesman, expressed a positive sentiment in his reviews ...\n",
            "--------------------------------------------------\n",
            "Q4: What did Mike Massie think about the disaster film 2012?\n",
            "Expected: Mike Massie gave the film 2012 a score of 5/10 and described it as a film where Roland Emmerich has ...\n",
            "--------------------------------------------------\n",
            "Q5: What are the contrasting opinions on 'Solo: A Star Wars Story' regarding its contribution to the Star Wars franchise and its overall entertainment value?\n",
            "Expected: The reviews for 'Solo: A Star Wars Story' present contrasting opinions. Some critics, like Keith Gar...\n",
            "--------------------------------------------------\n",
            "\n",
            "âœ… Ready to evaluate 12 questions with enhanced agent\n",
            "\n",
            "âœ… Golden test set ready with 12 questions\n",
            "ğŸ¯ Ready for comprehensive retriever evaluation with enhanced agent!\n"
          ]
        }
      ],
      "source": [
        "# # RAGAS setup for movie reviews\n",
        "# from ragas.llms import LangchainLLMWrapper\n",
        "# from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "# from ragas.testset import TestsetGenerator\n",
        "\n",
        "# print(\"ğŸ¯ Generating Golden Test Set for Movie Reviews using RAGAS...\")\n",
        "# print(\"=\" * 70)\n",
        "\n",
        "# # Initialize models for RAGAS\n",
        "# generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7))\n",
        "# generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings(model=\"text-embedding-3-small\"))\n",
        "\n",
        "# print(\"âœ… RAGAS models initialized\")\n",
        "\n",
        "# # Prepare documents for test set generation\n",
        "# print(\"ğŸ“„ Preparing documents for test set generation...\")\n",
        "\n",
        "# # Use diverse subset of movie reviews for better question generation\n",
        "# # Focus on diverse movies, critics, and sentiments\n",
        "# testset_docs = chunks[:50]  # Use first 50 documents for cost efficiency\n",
        "\n",
        "# print(f\"   Selected {len(testset_docs)} review documents for question generation\")\n",
        "\n",
        "# # Create test set generator\n",
        "# print(\"âš™ï¸ Creating RAGAS test set generator...\")\n",
        "# generator = TestsetGenerator(\n",
        "#     llm=generator_llm,\n",
        "#     embedding_model=generator_embeddings\n",
        "# )\n",
        "\n",
        "# # Generate synthetic test set\n",
        "# TESTSET_SIZE = 10  # Generate enough questions for robust evaluation\n",
        "# print(f\"ğŸ”¬ Generating {TESTSET_SIZE} movie review questions (this may take a few minutes)...\")\n",
        "\n",
        "# try:\n",
        "#     golden_dataset = generator.generate_with_langchain_docs(\n",
        "#         documents=testset_docs,\n",
        "#         testset_size=TESTSET_SIZE\n",
        "#     )\n",
        "    \n",
        "#     print(\"âœ… Synthetic test set generated successfully!\")\n",
        "    \n",
        "#     # Convert to DataFrame and display\n",
        "#     synthetic_df = golden_dataset.to_pandas()\n",
        "#     print(f\"\\nğŸ“Š Generated {len(synthetic_df)} synthetic test cases\")\n",
        "    \n",
        "#     # Show sample questions\n",
        "#     print(\"\\nğŸ“ Generated Movie Review Questions:\")\n",
        "#     print(\"-\" * 50)\n",
        "    \n",
        "#     # Find the correct question column\n",
        "#     if 'question' in synthetic_df.columns:\n",
        "#         question_col = 'question'\n",
        "#     elif 'user_input' in synthetic_df.columns:\n",
        "#         question_col = 'user_input'\n",
        "#     else:\n",
        "#         question_col = synthetic_df.columns[0]\n",
        "#         print(f\"Using column '{question_col}' as questions\")\n",
        "    \n",
        "#     for i, row in synthetic_df.head(5).iterrows():\n",
        "#         print(f\"Q{i+1}: {row[question_col]}\")\n",
        "#         if 'reference' in row and pd.notna(row['reference']):\n",
        "#             print(f\"Expected: {row['reference'][:100]}...\")\n",
        "#         print(\"-\" * 50)\n",
        "    \n",
        "#     # Store for evaluation\n",
        "#     questions_for_evaluation = synthetic_df[question_col].tolist()\n",
        "#     print(f\"\\nâœ… Ready to evaluate {len(questions_for_evaluation)} questions with enhanced agent\")\n",
        "# finally:\n",
        "#     print(f\"\\nâœ… Golden test set ready with {len(questions_for_evaluation)} questions\")\n",
        "#     print(\"ğŸ¯ Ready for comprehensive retriever evaluation with enhanced agent!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¯ Generating Golden Test Set using RAGAS...\n",
            "======================================================================\n",
            "âœ… RAGAS imports successful\n",
            "ğŸ“„ Preparing documents for test set generation...\n",
            "   âœ  50 review docs ready (each â‰¥ 120 tokens) + 1 guidelines doc\n",
            "   Selected 50 review docs (+1 guidelines doc)\n",
            "ğŸ¤– Setting up RAGAS generator models...\n",
            "âš™ï¸ Creating RAGAS test set generator...\n",
            "ğŸ”¬ Generating 10 general/comparative questions from 50 docs (this may take a few minutes)...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b9a6d58019834518a45621c81e455524",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying HeadlinesExtractor:   0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a185aff327541cc8d0b02a13abaa03f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying HeadlineSplitter:   0%|          | 0/51 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "unable to apply transformation: 'headlines' property not found in this node\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89561fe2f8bf43d08c21b7596e529ce8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying SummaryExtractor:   0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39f60fcaf8014fd59d5fa209ab9201b5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying CustomNodeFilter:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8df19f637f04814b6025f63f7a6ce6a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "321cc5644ade483e8d3cfcecfbe5fb1c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89496585521c403d9d3106bc2aca291a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f8eb798322fa409e993c84e10b58ec21",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3412a05d0ee43daa3d458f6e790aec9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Samples:   0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Synthetic test set generated successfully!\n",
            "\n",
            "ğŸ“Š Generated 12 synthetic test cases\n",
            "âš ï¸ Some questions looked too review-specific; keeping the rest.\n",
            "\n",
            "ğŸ“ Generated Questions (general/comparative):\n",
            "--------------------------------------------------\n",
            "Q2: What was Matt Brunson's overall sentiment regarding Deadpool 2?\n",
            "Expected Answer: Matt Brunson from Film Frenzy gave Deadpool 2 a score of 3/4 and expressed a positive sentiment, sta...\n",
            "--------------------------------------------------\n",
            "Q5: What positive sentiments do critics express about the nostalgia and emotional impact of Star Wars: The Force Awakens?\n",
            "Expected Answer: Critics express a range of positive sentiments about Star Wars: The Force Awakens, highlighting its ...\n",
            "--------------------------------------------------\n",
            "Q6: What are the audience and critic sentiments towards Star Wars: The Force Awakens, and how does it compare to the original trilogy in terms of storytelling and nostalgia?\n",
            "Expected Answer: The audience sentiment towards Star Wars: The Force Awakens is largely positive, with an audience sc...\n",
            "--------------------------------------------------\n",
            "Q7: What is the audience score for Captain America: Civil War and how does it compare to the audience score of Avengers: Endgame?\n",
            "Expected Answer: The audience score for Captain America: Civil War is 89.0%, while the audience score for Avengers: E...\n",
            "--------------------------------------------------\n",
            "Q8: What was the release date of Avengers: Endgame and how did critics respond to its emotional impact and character development?\n",
            "Expected Answer: Avengers: Endgame was released on April 26, 2019. Critics responded positively to its emotional impa...\n",
            "--------------------------------------------------\n",
            "Q9: What are the sentiments expressed by Eleanor Ringel Cater in her reviews of both 'Rain Man' and 'Our Kind of Traitor', and how do they reflect her perspective on storytelling in films?\n",
            "Expected Answer: In her review of 'Rain Man', Eleanor Ringel Cater expresses a positive sentiment, noting that Tom Cr...\n",
            "--------------------------------------------------\n",
            "Q10: What are the critical sentiments expressed about Alfonso CuarÃ³n's film Roma, and how do they reflect its themes of social inequality and personal storytelling?\n",
            "Expected Answer: Critics have expressed a range of sentiments about Alfonso CuarÃ³n's film Roma, highlighting its deep...\n",
            "--------------------------------------------------\n",
            "Q11: How does the audience reception of 'The Force Awakens' compare to the critical acclaim it received, particularly in terms of emotional impact and nostalgia as highlighted by reviews from 'The Cinematic Reel'?\n",
            "Expected Answer: The audience reception of 'The Force Awakens' is notably high, with an audience score of 90.0% and a...\n",
            "--------------------------------------------------\n",
            "\n",
            "âœ… Golden test set ready with 8 questions\n",
            "ğŸ¯ Ready for comprehensive RAGAS evaluation!\n",
            "\n",
            "ğŸ” Key Improvements in this version:\n",
            "  â€¢ General/comparative questions instead of reviewer-specific\n",
            "  â€¢ Better document preparation with minimum token requirements\n",
            "  â€¢ Grouped reviews by movie for better context\n",
            "  â€¢ Post-filtering to remove overly specific questions\n",
            "  â€¢ Configurable parameters for fine-tuning\n"
          ]
        }
      ],
      "source": [
        "# ğŸ¯ IMPROVED RAGAS: Generating a general/comparative Golden Test Set\n",
        "print(\"ğŸ¯ Generating Golden Test Set using RAGAS...\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# -----------------------------\n",
        "# Config knobs\n",
        "# -----------------------------\n",
        "MAX_TITLES            = 50       # widen unique title coverage\n",
        "PER_TITLE_REVIEWS     = 20        # cap reviews per title to keep breadth\n",
        "GEN_DOCS_LIMIT        = 50     # how many docs to feed into generator\n",
        "TESTSET_SIZE          = 10       # number of questions to generate\n",
        "RAND_SEED             = 42\n",
        "\n",
        "# Guidance: general, movie-level questions (not single-review)\n",
        "GENERATION_GUIDELINES = \"\"\"\n",
        "You are generating questions for evaluating a movie QA system.\n",
        "The corpus consists of people's reviews of movies (subjective opinions from critics/audiences).\n",
        "\n",
        "Generate questions that:\n",
        "- Are GENERAL about movies or comparisons/similarities across movies, directors, genres, time periods, or sentiments.\n",
        "- Do NOT ask about a single specific reviewer's wording, a single outlet, or a quote-level detail.\n",
        "- Encourage retrieval across multiple documents (e.g., \"Compare audience vs critic sentiment for X and Y\", \"Which genres show higher variance in sentiment?\", \"Do Nolan films receive more 'fresh' ratings than Villeneuve films?\", etc.)\n",
        "- Can be answered from aggregated patterns in reviews (scores, sentiments, themes), not from a single snippet.\n",
        "- Ask about reccomendations based on movie x they like. i.e. \"What movies are similar to The Dark Knight?\"\n",
        "\n",
        "Avoid:\n",
        "- \"What did [reviewer/outlet] say about <movie>?\"\n",
        "- \"Quote the line where...\"\n",
        "- Any question that hinges on one review's phrasing.\n",
        "\"\"\"\n",
        "\n",
        "# -----------------------------\n",
        "# Helper: prepare a larger, diverse document sample\n",
        "# -----------------------------\n",
        "MIN_TOKENS_PER_DOC = 120     # anything < 100 triggers RAGAS's error\n",
        "\n",
        "def token_len(text: str) -> int:\n",
        "    return len(text.split())\n",
        "\n",
        "def prepare_documents_for_ragas() -> list:\n",
        "    \"\"\"\n",
        "    Build Documents that are guaranteed to meet the min-token rule.\n",
        "    Strategy:\n",
        "      â€¢ Pick a broad set of review rows (as before)      â†’ breadth\n",
        "      â€¢ Concatenate rows from the same movie until >= N  â†’ length\n",
        "    \"\"\"\n",
        "    from langchain_core.documents import Document\n",
        "    import random\n",
        "    random.seed(RAND_SEED)\n",
        "\n",
        "    # 1ï¸âƒ£  Group rows by movie title\n",
        "    by_title = {}\n",
        "    for row in all_documents:\n",
        "        title = row.get(\"metadata\", {}).get(\"movie_title\") or \"UNKNOWN_TITLE\"\n",
        "        by_title.setdefault(title, []).append(row)\n",
        "\n",
        "    # 2ï¸âƒ£  Shuffle titles for randomness and pick a subset for breadth\n",
        "    chosen_titles = random.sample(list(by_title), k=min(MAX_TITLES, len(by_title)))\n",
        "\n",
        "    docs = []\n",
        "\n",
        "    # 3ï¸âƒ£  For each title, concatenate reviews until the merged block is long enough\n",
        "    for title in chosen_titles:\n",
        "        # Sort so we get a mix of sentiments & critics in the concat\n",
        "        random.shuffle(by_title[title])\n",
        "\n",
        "        buffer = []\n",
        "        running_text = \"\"\n",
        "        running_meta = {}\n",
        "\n",
        "        for rev in by_title[title]:\n",
        "            running_text += rev[\"content\"].strip() + \"\\n\\n\"\n",
        "            # Merge metadata (keep first non-None values)\n",
        "            for k, v in rev.get(\"metadata\", {}).items():\n",
        "                running_meta.setdefault(k, v)\n",
        "\n",
        "            if token_len(running_text) >= MIN_TOKENS_PER_DOC:\n",
        "                # âœ… This block is long enough â€“ push it as a Document\n",
        "                docs.append(\n",
        "                    Document(\n",
        "                        page_content=running_text.strip(),\n",
        "                        metadata=running_meta | {\"merged_reviews\": len(buffer) + 1}\n",
        "                    )\n",
        "                )\n",
        "                # reset for next chunk of the same title\n",
        "                buffer.clear()\n",
        "                running_text = \"\"\n",
        "                running_meta = {}\n",
        "\n",
        "            else:\n",
        "                buffer.append(rev)\n",
        "\n",
        "        # If leftovers are still < MIN_TOKENS, append them to previous doc or skip\n",
        "        if running_text:\n",
        "            if docs and token_len(running_text) < MIN_TOKENS_PER_DOC:\n",
        "                docs[-1].page_content += \"\\n\\n\" + running_text.strip()\n",
        "                docs[-1].metadata[\"merged_reviews\"] += len(buffer)\n",
        "            else:\n",
        "                docs.append(\n",
        "                    Document(\n",
        "                        page_content=running_text.strip(),\n",
        "                        metadata=running_meta | {\"merged_reviews\": len(buffer)}\n",
        "                    )\n",
        "                )\n",
        "\n",
        "        # Stop once we hit our global limit\n",
        "        if len(docs) >= GEN_DOCS_LIMIT:\n",
        "            break\n",
        "\n",
        "    # 4ï¸âƒ£  Clip to limit & prepend the generation-guidelines doc\n",
        "    docs = [Document(GENERATION_GUIDELINES.strip(), metadata={\"role\": \"generation_guidelines\"})] + \\\n",
        "           docs[:GEN_DOCS_LIMIT]\n",
        "\n",
        "    print(f\"   âœ  {len(docs)-1} review docs ready (each â‰¥ {MIN_TOKENS_PER_DOC} tokens) \"\n",
        "          f\"+ 1 guidelines doc\")\n",
        "    return docs\n",
        "\n",
        "\n",
        "try:\n",
        "    from ragas.llms import LangchainLLMWrapper\n",
        "    from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "    from ragas.testset import TestsetGenerator\n",
        "\n",
        "    print(\"âœ… RAGAS imports successful\")\n",
        "\n",
        "    # Prepare documents for synthetic generation\n",
        "    print(\"ğŸ“„ Preparing documents for test set generation...\")\n",
        "    rag_docs = prepare_documents_for_ragas()\n",
        "    # Subtract 1 because the first doc is the guidelines doc\n",
        "    print(f\"   Selected {len(rag_docs)-1} review docs (+1 guidelines doc)\")\n",
        "\n",
        "    # Set up RAGAS generator models\n",
        "    print(\"ğŸ¤– Setting up RAGAS generator models...\")\n",
        "    generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7))\n",
        "    generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings(model=\"text-embedding-3-small\"))\n",
        "\n",
        "    # Create test set generator\n",
        "    print(\"âš™ï¸ Creating RAGAS test set generator...\")\n",
        "    generator = TestsetGenerator(\n",
        "        llm=generator_llm,\n",
        "        embedding_model=generator_embeddings\n",
        "    )\n",
        "\n",
        "    # Generate synthetic test set\n",
        "    print(f\"ğŸ”¬ Generating {TESTSET_SIZE} general/comparative questions \"\n",
        "          f\"from {min(len(rag_docs), GEN_DOCS_LIMIT)} docs (this may take a few minutes)...\")\n",
        "\n",
        "    synthetic_dataset = generator.generate_with_langchain_docs(\n",
        "        documents=rag_docs,        # includes the guidelines doc + diverse reviews\n",
        "        testset_size=TESTSET_SIZE, # âœ… 10 questions\n",
        "    )\n",
        "\n",
        "    print(\"âœ… Synthetic test set generated successfully!\")\n",
        "\n",
        "    # Convert to DataFrame and display\n",
        "    synthetic_df = synthetic_dataset.to_pandas()\n",
        "    print(f\"\\nğŸ“Š Generated {len(synthetic_df)} synthetic test cases\")\n",
        "\n",
        "    # Optional: light post-filter to nudge away from single-review phrasing\n",
        "    def looks_too_review_specific(q: str) -> bool:\n",
        "        ql = q.lower()\n",
        "        triggers = [\n",
        "            \"what did\", \"what does\", \"according to this review\", \"quote\", \"in the following review\",\n",
        "            \"the reviewer\", \"this critic\", \"as stated above\"\n",
        "        ]\n",
        "        return any(t in ql for t in triggers)\n",
        "\n",
        "    filtered_df = synthetic_df[~synthetic_df[\"user_input\"].apply(looks_too_review_specific)]\n",
        "    if len(filtered_df) < TESTSET_SIZE:\n",
        "        print(\"âš ï¸ Some questions looked too review-specific; keeping the rest.\")\n",
        "    synthetic_df = filtered_df.head(TESTSET_SIZE)\n",
        "\n",
        "    # Show sample questions\n",
        "    print(\"\\nğŸ“ Generated Questions (general/comparative):\")\n",
        "    print(\"-\" * 50)\n",
        "    for i, row in synthetic_df.head(10).iterrows():\n",
        "        print(f\"Q{i+1}: {row['user_input']}\")\n",
        "        ref = row.get(\"reference\", \"\")\n",
        "        if isinstance(ref, str) and ref.strip():\n",
        "            print(f\"Expected Answer: {ref[:100]}...\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    # Store for evaluation\n",
        "    golden_test_set = synthetic_dataset\n",
        "    \n",
        "    # Update questions_for_evaluation for the rest of the notebook\n",
        "    questions_for_evaluation = synthetic_df[\"user_input\"].tolist()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error in RAGAS setup: {e}\")\n",
        "    print(\"ğŸ’¡ You can continue without RAGAS - the agent will use only embedded reviews\")\n",
        "    questions_for_evaluation = []\n",
        "\n",
        "print(f\"\\nâœ… Golden test set ready with {len(synthetic_df)} questions\")\n",
        "print(\"ğŸ¯ Ready for comprehensive RAGAS evaluation!\")\n",
        "print(\"\\nğŸ” Key Improvements in this version:\")\n",
        "print(\"  â€¢ General/comparative questions instead of reviewer-specific\")\n",
        "print(\"  â€¢ Better document preparation with minimum token requirements\")\n",
        "print(\"  â€¢ Grouped reviews by movie for better context\")\n",
        "print(\"  â€¢ Post-filtering to remove overly specific questions\")\n",
        "print(\"  â€¢ Configurable parameters for fine-tuning\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "synthetic_df = golden_test_set.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>reference_contexts</th>\n",
              "      <th>reference</th>\n",
              "      <th>synthesizer_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What did Nicholas Oon think about the sequel t...</td>\n",
              "      <td>[Audience Score: 85.0%\\nTomato Meter: 84.0%\\nR...</td>\n",
              "      <td>Nicholas Oon from Maximum Hype (YouTube) rated...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What was Matt Brunson's overall sentiment rega...</td>\n",
              "      <td>[Movie: Deadpool 2\\n Genre: Action, Adventure,...</td>\n",
              "      <td>Matt Brunson from Film Frenzy gave Deadpool 2 ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What did Christine Champagne from Out Magazene...</td>\n",
              "      <td>[Audience Score: 86.0%\\nTomato Meter: 94.0%\\nR...</td>\n",
              "      <td>Christine Champagne from Out Magazine describe...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What did Keith H. Brown from Eye for Film say ...</td>\n",
              "      <td>[Movie: American Splendor\\n Genre: Biography, ...</td>\n",
              "      <td>Keith H. Brown from Eye for Film gave the movi...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What positive sentiments do critics express ab...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nReviews: 445\\n\\nReviews:\\n\\n--- Re...</td>\n",
              "      <td>Critics express a range of positive sentiments...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>What are the audience and critic sentiments to...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nReviews: 445\\n\\nReviews:\\n\\n--- Re...</td>\n",
              "      <td>The audience sentiment towards Star Wars: The ...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>What is the audience score for Captain America...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nRelease Date: 2019-04-26\\nAudience...</td>\n",
              "      <td>The audience score for Captain America: Civil ...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What was the release date of Avengers: Endgame...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nRelease Date: 2019-04-26\\nAudience...</td>\n",
              "      <td>Avengers: Endgame was released on April 26, 20...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What are the sentiments expressed by Eleanor R...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nAudience Score: 90.0%\\nTomato Mete...</td>\n",
              "      <td>In her review of 'Rain Man', Eleanor Ringel Ca...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>What are the critical sentiments expressed abo...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nMovie: Roma\\n Genre: Drama\\n Direc...</td>\n",
              "      <td>Critics have expressed a range of sentiments a...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>How does the audience reception of 'The Force ...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nReviews: 445\\n\\nReviews:\\n\\n--- Re...</td>\n",
              "      <td>The audience reception of 'The Force Awakens' ...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>What did Jason Best say about the film State o...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nAudience Score: 73.0%\\nTomato Mete...</td>\n",
              "      <td>Jason Best described State of Play as an enthr...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           user_input  \\\n",
              "0   What did Nicholas Oon think about the sequel t...   \n",
              "1   What was Matt Brunson's overall sentiment rega...   \n",
              "2   What did Christine Champagne from Out Magazene...   \n",
              "3   What did Keith H. Brown from Eye for Film say ...   \n",
              "4   What positive sentiments do critics express ab...   \n",
              "5   What are the audience and critic sentiments to...   \n",
              "6   What is the audience score for Captain America...   \n",
              "7   What was the release date of Avengers: Endgame...   \n",
              "8   What are the sentiments expressed by Eleanor R...   \n",
              "9   What are the critical sentiments expressed abo...   \n",
              "10  How does the audience reception of 'The Force ...   \n",
              "11  What did Jason Best say about the film State o...   \n",
              "\n",
              "                                   reference_contexts  \\\n",
              "0   [Audience Score: 85.0%\\nTomato Meter: 84.0%\\nR...   \n",
              "1   [Movie: Deadpool 2\\n Genre: Action, Adventure,...   \n",
              "2   [Audience Score: 86.0%\\nTomato Meter: 94.0%\\nR...   \n",
              "3   [Movie: American Splendor\\n Genre: Biography, ...   \n",
              "4   [<1-hop>\\n\\nReviews: 445\\n\\nReviews:\\n\\n--- Re...   \n",
              "5   [<1-hop>\\n\\nReviews: 445\\n\\nReviews:\\n\\n--- Re...   \n",
              "6   [<1-hop>\\n\\nRelease Date: 2019-04-26\\nAudience...   \n",
              "7   [<1-hop>\\n\\nRelease Date: 2019-04-26\\nAudience...   \n",
              "8   [<1-hop>\\n\\nAudience Score: 90.0%\\nTomato Mete...   \n",
              "9   [<1-hop>\\n\\nMovie: Roma\\n Genre: Drama\\n Direc...   \n",
              "10  [<1-hop>\\n\\nReviews: 445\\n\\nReviews:\\n\\n--- Re...   \n",
              "11  [<1-hop>\\n\\nAudience Score: 73.0%\\nTomato Mete...   \n",
              "\n",
              "                                            reference  \\\n",
              "0   Nicholas Oon from Maximum Hype (YouTube) rated...   \n",
              "1   Matt Brunson from Film Frenzy gave Deadpool 2 ...   \n",
              "2   Christine Champagne from Out Magazine describe...   \n",
              "3   Keith H. Brown from Eye for Film gave the movi...   \n",
              "4   Critics express a range of positive sentiments...   \n",
              "5   The audience sentiment towards Star Wars: The ...   \n",
              "6   The audience score for Captain America: Civil ...   \n",
              "7   Avengers: Endgame was released on April 26, 20...   \n",
              "8   In her review of 'Rain Man', Eleanor Ringel Ca...   \n",
              "9   Critics have expressed a range of sentiments a...   \n",
              "10  The audience reception of 'The Force Awakens' ...   \n",
              "11  Jason Best described State of Play as an enthr...   \n",
              "\n",
              "                        synthesizer_name  \n",
              "0   single_hop_specifc_query_synthesizer  \n",
              "1   single_hop_specifc_query_synthesizer  \n",
              "2   single_hop_specifc_query_synthesizer  \n",
              "3   single_hop_specifc_query_synthesizer  \n",
              "4   multi_hop_abstract_query_synthesizer  \n",
              "5   multi_hop_abstract_query_synthesizer  \n",
              "6   multi_hop_abstract_query_synthesizer  \n",
              "7   multi_hop_abstract_query_synthesizer  \n",
              "8   multi_hop_specific_query_synthesizer  \n",
              "9   multi_hop_specific_query_synthesizer  \n",
              "10  multi_hop_specific_query_synthesizer  \n",
              "11  multi_hop_specific_query_synthesizer  "
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "synthetic_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 8: Enhanced Agent Evaluation with Retriever Swapping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Enhanced agent evaluation functions ready!\n",
            "ğŸ”„ Ready to swap retrievers and test the complete enhanced pipeline!\n"
          ]
        }
      ],
      "source": [
        "# Function to swap retriever in the enhanced agent and evaluate\n",
        "def evaluate_enhanced_agent_with_retriever(retriever_name: str, retriever, questions: List[str]):\n",
        "    \"\"\"\n",
        "    Evaluate the enhanced agent with a specific retriever.\n",
        "    This swaps out the base_retriever used in the search_movie_reviews tool.\n",
        "    \"\"\"\n",
        "    print(f\"\\nğŸ” Evaluating Enhanced Agent with {retriever_name} Retriever...\")\n",
        "    print(\"-\" * 60)\n",
        "    \n",
        "    # Global reference to swap the retriever\n",
        "    global base_retriever\n",
        "    original_retriever = base_retriever\n",
        "    \n",
        "    try:\n",
        "        # Swap in the new retriever\n",
        "        base_retriever = retriever\n",
        "        \n",
        "        start_time = time.time()\n",
        "        successful_queries = 0\n",
        "        total_tool_calls = 0\n",
        "        results = []\n",
        "        \n",
        "        for i, question in enumerate(questions):\n",
        "            print(f\"Processing question {i+1}/{len(questions)}: {question[:50]}...\")\n",
        "            \n",
        "            try:\n",
        "                # Query the enhanced agent with the swapped retriever\n",
        "                result = query_enhanced_agent_with_tracing(\n",
        "                    question, \n",
        "                    run_name=f\"{retriever_name.lower().replace(' ', '_')}_q{i+1}\"\n",
        "                )\n",
        "                \n",
        "                if result['success']:\n",
        "                    successful_queries += 1\n",
        "                    total_tool_calls += result['tool_calls_made']\n",
        "                    results.append({\n",
        "                        'question': question,\n",
        "                        'answer': result['answer'],\n",
        "                        'tool_calls': result['tool_calls_made'],\n",
        "                        'execution_time': result['execution_time'],\n",
        "                        'success': True\n",
        "                    })\n",
        "                else:\n",
        "                    print(f\"   âŒ Failed: {result['answer']}\")\n",
        "                    results.append({\n",
        "                        'question': question,\n",
        "                        'answer': result['answer'],\n",
        "                        'tool_calls': 0,\n",
        "                        'execution_time': 0,\n",
        "                        'success': False\n",
        "                    })\n",
        "                    \n",
        "            except Exception as e:\n",
        "                print(f\"   âŒ Error: {str(e)}\")\n",
        "                results.append({\n",
        "                    'question': question,\n",
        "                    'answer': f\"Error: {str(e)}\",\n",
        "                    'tool_calls': 0,\n",
        "                    'execution_time': 0,\n",
        "                    'success': False\n",
        "                })\n",
        "        \n",
        "        end_time = time.time()\n",
        "        total_time = end_time - start_time\n",
        "        \n",
        "        # Calculate metrics\n",
        "        success_rate = successful_queries / len(questions) if questions else 0\n",
        "        avg_tool_calls = total_tool_calls / len(questions) if questions else 0\n",
        "        avg_execution_time = total_time / len(questions) if questions else 0\n",
        "        \n",
        "        evaluation_result = {\n",
        "            'retriever_name': retriever_name,\n",
        "            'success_rate': success_rate,\n",
        "            'avg_tool_calls': avg_tool_calls,\n",
        "            'total_time': total_time,\n",
        "            'avg_execution_time': avg_execution_time,\n",
        "            'successful_queries': successful_queries,\n",
        "            'total_queries': len(questions),\n",
        "            'results': results\n",
        "        }\n",
        "        \n",
        "        print(f\"âœ… {retriever_name} Evaluation Complete:\")\n",
        "        print(f\"   Success Rate: {success_rate:.2%}\")\n",
        "        print(f\"   Avg Tool Calls: {avg_tool_calls:.1f}\")\n",
        "        print(f\"   Total Time: {total_time:.2f}s\")\n",
        "        print(f\"   Avg Time per Query: {avg_execution_time:.2f}s\")\n",
        "        \n",
        "        return evaluation_result\n",
        "        \n",
        "    finally:\n",
        "        # Always restore the original retriever\n",
        "        base_retriever = original_retriever\n",
        "\n",
        "# Function to estimate costs for enhanced agent evaluation\n",
        "def estimate_enhanced_agent_cost(retriever_name: str, num_queries: int) -> float:\n",
        "    \"\"\"Estimate API costs for enhanced agent with different retrievers\"\"\"\n",
        "    \n",
        "    # Base costs per query (including agent reasoning + tool calls)\n",
        "    base_costs = {\n",
        "        'Naive': 0.008,  # OpenAI embeddings + LLM calls + tool execution\n",
        "        'BM25': 0.006,   # No embeddings, but more tool calls due to lower accuracy\n",
        "        'Multi-Query': 0.015,  # Multiple LLM calls + embeddings + retries\n",
        "        'Parent Document': 0.010,  # Embeddings + LLM + larger context\n",
        "        'Contextual Compression': 0.025,  # Cohere rerank + embeddings + LLM\n",
        "        'Ensemble': 0.035,  # All of the above combined + coordination overhead\n",
        "    }\n",
        "    \n",
        "    return base_costs.get(retriever_name, 0.012) * num_queries\n",
        "\n",
        "print(\"âœ… Enhanced agent evaluation functions ready!\")\n",
        "print(\"ğŸ”„ Ready to swap retrievers and test the complete enhanced pipeline!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 9: Run Complete Enhanced Agent Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ Starting Comprehensive Enhanced Agent Evaluation\n",
            "================================================================================\n",
            "ğŸ“Š Testing 6 retrievers on 12 questions\n",
            "ğŸ¤– Each question will go through the complete enhanced agent pipeline\n",
            "================================================================================\n",
            "\n",
            "ğŸ” Evaluating Enhanced Agent with Naive Retriever...\n",
            "------------------------------------------------------------\n",
            "Processing question 1/12: What are the key highlights of the documentary 'Be...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/f1/cmsz4dgn2y194hgy1n_pldjc0000gn/T/ipykernel_67907/4270994735.py:61: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  retrieved_docs = base_retriever.get_relevant_documents(query)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing question 2/12: What is the overall sentiment of the review for Bl...\n",
            "Processing question 3/12: How does the choreography in 'City Hunter: Shinjuk...\n",
            "Processing question 4/12: What are the main criticisms of the film City Hunt...\n",
            "Processing question 5/12: What are the contrasting sentiments expressed in t...\n",
            "Processing question 6/12: What are the critical perspectives on Alan J. Paku...\n",
            "Processing question 7/12: What are the contrasting reviews of The DUFF in te...\n",
            "Processing question 8/12: Who directed the movie Klute and what is notable a...\n",
            "Processing question 9/12: How does John DeFore's review of 'More Than Honey'...\n",
            "Processing question 10/12: In what ways does Richard Dutcher's film 'Falling'...\n",
            "Processing question 11/12: In what ways does the film 'Miss and the Doctors' ...\n",
            "Processing question 12/12: What are the critical reviews of the movie '10 Ter...\n",
            "âœ… Naive Evaluation Complete:\n",
            "   Success Rate: 100.00%\n",
            "   Avg Tool Calls: 1.4\n",
            "   Total Time: 247.74s\n",
            "   Avg Time per Query: 20.65s\n",
            "â±ï¸ Pausing briefly before next retriever...\n",
            "\n",
            "ğŸ” Evaluating Enhanced Agent with BM25 Retriever...\n",
            "------------------------------------------------------------\n",
            "Processing question 1/12: What are the key highlights of the documentary 'Be...\n",
            "Processing question 2/12: What is the overall sentiment of the review for Bl...\n",
            "Processing question 3/12: How does the choreography in 'City Hunter: Shinjuk...\n",
            "Processing question 4/12: What are the main criticisms of the film City Hunt...\n",
            "Processing question 5/12: What are the contrasting sentiments expressed in t...\n",
            "Processing question 6/12: What are the critical perspectives on Alan J. Paku...\n",
            "Processing question 7/12: What are the contrasting reviews of The DUFF in te...\n",
            "Processing question 8/12: Who directed the movie Klute and what is notable a...\n",
            "Processing question 9/12: How does John DeFore's review of 'More Than Honey'...\n",
            "Processing question 10/12: In what ways does Richard Dutcher's film 'Falling'...\n",
            "Processing question 11/12: In what ways does the film 'Miss and the Doctors' ...\n",
            "Processing question 12/12: What are the critical reviews of the movie '10 Ter...\n",
            "âœ… BM25 Evaluation Complete:\n",
            "   Success Rate: 100.00%\n",
            "   Avg Tool Calls: 1.4\n",
            "   Total Time: 212.07s\n",
            "   Avg Time per Query: 17.67s\n",
            "â±ï¸ Pausing briefly before next retriever...\n",
            "\n",
            "ğŸ” Evaluating Enhanced Agent with Multi-Query Retriever...\n",
            "------------------------------------------------------------\n",
            "Processing question 1/12: What are the key highlights of the documentary 'Be...\n",
            "Processing question 2/12: What is the overall sentiment of the review for Bl...\n",
            "Processing question 3/12: How does the choreography in 'City Hunter: Shinjuk...\n",
            "Processing question 4/12: What are the main criticisms of the film City Hunt...\n",
            "Processing question 5/12: What are the contrasting sentiments expressed in t...\n",
            "Processing question 6/12: What are the critical perspectives on Alan J. Paku...\n",
            "Processing question 7/12: What are the contrasting reviews of The DUFF in te...\n",
            "Processing question 8/12: Who directed the movie Klute and what is notable a...\n",
            "Processing question 9/12: How does John DeFore's review of 'More Than Honey'...\n",
            "Processing question 10/12: In what ways does Richard Dutcher's film 'Falling'...\n",
            "Processing question 11/12: In what ways does the film 'Miss and the Doctors' ...\n",
            "Processing question 12/12: What are the critical reviews of the movie '10 Ter...\n",
            "âœ… Multi-Query Evaluation Complete:\n",
            "   Success Rate: 100.00%\n",
            "   Avg Tool Calls: 1.4\n",
            "   Total Time: 263.26s\n",
            "   Avg Time per Query: 21.94s\n",
            "â±ï¸ Pausing briefly before next retriever...\n",
            "\n",
            "ğŸ” Evaluating Enhanced Agent with Parent Document Retriever...\n",
            "------------------------------------------------------------\n",
            "Processing question 1/12: What are the key highlights of the documentary 'Be...\n",
            "Processing question 2/12: What is the overall sentiment of the review for Bl...\n",
            "Processing question 3/12: How does the choreography in 'City Hunter: Shinjuk...\n",
            "Processing question 4/12: What are the main criticisms of the film City Hunt...\n",
            "Processing question 5/12: What are the contrasting sentiments expressed in t...\n",
            "Processing question 6/12: What are the critical perspectives on Alan J. Paku...\n",
            "Processing question 7/12: What are the contrasting reviews of The DUFF in te...\n",
            "Processing question 8/12: Who directed the movie Klute and what is notable a...\n",
            "Processing question 9/12: How does John DeFore's review of 'More Than Honey'...\n",
            "Processing question 10/12: In what ways does Richard Dutcher's film 'Falling'...\n",
            "Processing question 11/12: In what ways does the film 'Miss and the Doctors' ...\n",
            "Processing question 12/12: What are the critical reviews of the movie '10 Ter...\n",
            "âœ… Parent Document Evaluation Complete:\n",
            "   Success Rate: 100.00%\n",
            "   Avg Tool Calls: 1.4\n",
            "   Total Time: 230.95s\n",
            "   Avg Time per Query: 19.25s\n",
            "â±ï¸ Pausing briefly before next retriever...\n",
            "\n",
            "ğŸ” Evaluating Enhanced Agent with Contextual Compression Retriever...\n",
            "------------------------------------------------------------\n",
            "Processing question 1/12: What are the key highlights of the documentary 'Be...\n",
            "Processing question 2/12: What is the overall sentiment of the review for Bl...\n",
            "Processing question 3/12: How does the choreography in 'City Hunter: Shinjuk...\n",
            "Processing question 4/12: What are the main criticisms of the film City Hunt...\n",
            "Processing question 5/12: What are the contrasting sentiments expressed in t...\n",
            "Processing question 6/12: What are the critical perspectives on Alan J. Paku...\n",
            "Processing question 7/12: What are the contrasting reviews of The DUFF in te...\n",
            "Processing question 8/12: Who directed the movie Klute and what is notable a...\n",
            "Processing question 9/12: How does John DeFore's review of 'More Than Honey'...\n",
            "Processing question 10/12: In what ways does Richard Dutcher's film 'Falling'...\n",
            "Processing question 11/12: In what ways does the film 'Miss and the Doctors' ...\n",
            "Processing question 12/12: What are the critical reviews of the movie '10 Ter...\n",
            "âœ… Contextual Compression Evaluation Complete:\n",
            "   Success Rate: 100.00%\n",
            "   Avg Tool Calls: 1.4\n",
            "   Total Time: 227.75s\n",
            "   Avg Time per Query: 18.98s\n",
            "â±ï¸ Pausing briefly before next retriever...\n",
            "\n",
            "ğŸ” Evaluating Enhanced Agent with Ensemble Retriever...\n",
            "------------------------------------------------------------\n",
            "Processing question 1/12: What are the key highlights of the documentary 'Be...\n",
            "Processing question 2/12: What is the overall sentiment of the review for Bl...\n",
            "Processing question 3/12: How does the choreography in 'City Hunter: Shinjuk...\n",
            "Processing question 4/12: What are the main criticisms of the film City Hunt...\n",
            "Processing question 5/12: What are the contrasting sentiments expressed in t...\n",
            "Processing question 6/12: What are the critical perspectives on Alan J. Paku...\n",
            "Processing question 7/12: What are the contrasting reviews of The DUFF in te...\n",
            "Processing question 8/12: Who directed the movie Klute and what is notable a...\n",
            "Processing question 9/12: How does John DeFore's review of 'More Than Honey'...\n",
            "Processing question 10/12: In what ways does Richard Dutcher's film 'Falling'...\n",
            "Processing question 11/12: In what ways does the film 'Miss and the Doctors' ...\n",
            "Processing question 12/12: What are the critical reviews of the movie '10 Ter...\n",
            "âœ… Ensemble Evaluation Complete:\n",
            "   Success Rate: 100.00%\n",
            "   Avg Tool Calls: 1.4\n",
            "   Total Time: 264.12s\n",
            "   Avg Time per Query: 22.01s\n",
            "â±ï¸ Pausing briefly before next retriever...\n",
            "\\nâœ… All Enhanced Agent Evaluations Complete!\n",
            "ğŸ“ˆ Evaluated 6 retrievers with enhanced agent pipeline\n",
            "\\nğŸ“Š Enhanced Agent Retriever Evaluation Results:\n",
            "================================================================================\n",
            "             Retriever  Success Rate  Avg Tool Calls  Total Time (s)  Avg Time/Query (s)  Estimated Cost ($)\n",
            "                 Naive           1.0           1.417         247.744              20.645               0.096\n",
            "                  BM25           1.0           1.417         212.074              17.673               0.072\n",
            "           Multi-Query           1.0           1.417         263.260              21.938               0.180\n",
            "       Parent Document           1.0           1.417         230.953              19.246               0.120\n",
            "Contextual Compression           1.0           1.417         227.745              18.979               0.300\n",
            "              Ensemble           1.0           1.417         264.118              22.010               0.420\n",
            "\\nğŸ† ENHANCED AGENT PERFORMANCE WINNERS:\n",
            "==================================================\n",
            "âš¡ Fastest: BM25 (212.07s total)\n",
            "ğŸ’° Most Cost-Effective: BM25 ($0.072)\n",
            "ğŸ¯ Most Reliable: Naive (100.0% success)\n",
            "ğŸ”§ Most Efficient: Naive (1.4 avg tools)\n",
            "ğŸŒŸ Best Overall: BM25 (Score: 3.809)\n",
            "\\nğŸ¬ Enhanced Agent Movie Review Evaluation Complete!\n",
            "â° Completed at: 2025-08-04 09:33:39\n"
          ]
        }
      ],
      "source": [
        "# Run comprehensive evaluation of enhanced agent with all retrievers\n",
        "print(\"ğŸš€ Starting Comprehensive Enhanced Agent Evaluation\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"ğŸ“Š Testing {len(retrievers_to_evaluate)} retrievers on {len(questions_for_evaluation)} questions\")\n",
        "print(f\"ğŸ¤– Each question will go through the complete enhanced agent pipeline\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Store all evaluation results\n",
        "all_evaluation_results = []\n",
        "\n",
        "# Evaluate each retriever with the enhanced agent\n",
        "for retriever_name, retriever in retrievers_to_evaluate:\n",
        "    try:\n",
        "        # Run evaluation with this retriever\n",
        "        result = evaluate_enhanced_agent_with_retriever(\n",
        "            retriever_name, \n",
        "            retriever, \n",
        "            questions_for_evaluation\n",
        "        )\n",
        "        \n",
        "        # Add cost estimation\n",
        "        result['estimated_cost'] = estimate_enhanced_agent_cost(\n",
        "            retriever_name, \n",
        "            len(questions_for_evaluation)\n",
        "        )\n",
        "        \n",
        "        all_evaluation_results.append(result)\n",
        "        \n",
        "        # Add a brief pause between evaluations to avoid rate limits\n",
        "        print(f\"â±ï¸ Pausing briefly before next retriever...\")\n",
        "        time.sleep(2)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Failed to evaluate {retriever_name}: {str(e)}\")\n",
        "        # Add placeholder result for failed evaluation\n",
        "        all_evaluation_results.append({\n",
        "            'retriever_name': retriever_name,\n",
        "            'success_rate': 0.0,\n",
        "            'avg_tool_calls': 0.0,\n",
        "            'total_time': 0.0,\n",
        "            'avg_execution_time': 0.0,\n",
        "            'successful_queries': 0,\n",
        "            'total_queries': len(questions_for_evaluation),\n",
        "            'estimated_cost': 0.0,\n",
        "            'results': []\n",
        "        })\n",
        "\n",
        "print(\"\\\\nâœ… All Enhanced Agent Evaluations Complete!\")\n",
        "print(f\"ğŸ“ˆ Evaluated {len(all_evaluation_results)} retrievers with enhanced agent pipeline\")\n",
        "\n",
        "# Create results DataFrame for analysis\n",
        "results_df = pd.DataFrame([\n",
        "    {\n",
        "        'Retriever': result['retriever_name'],\n",
        "        'Success Rate': result['success_rate'],\n",
        "        'Avg Tool Calls': result['avg_tool_calls'],\n",
        "        'Total Time (s)': result['total_time'],\n",
        "        'Avg Time/Query (s)': result['avg_execution_time'],\n",
        "        'Estimated Cost ($)': result['estimated_cost']\n",
        "    }\n",
        "    for result in all_evaluation_results\n",
        "])\n",
        "\n",
        "# Display comprehensive results\n",
        "print(\"\\\\nğŸ“Š Enhanced Agent Retriever Evaluation Results:\")\n",
        "print(\"=\" * 80)\n",
        "print(results_df.round(3).to_string(index=False))\n",
        "\n",
        "# Find best performers\n",
        "successful_results = results_df[results_df['Success Rate'] > 0.5]\n",
        "\n",
        "if len(successful_results) > 0:\n",
        "    fastest = successful_results.loc[successful_results['Total Time (s)'].idxmin()]\n",
        "    cheapest = successful_results.loc[successful_results['Estimated Cost ($)'].idxmin()]\n",
        "    most_reliable = successful_results.loc[successful_results['Success Rate'].idxmax()]\n",
        "    most_efficient = successful_results.loc[successful_results['Avg Tool Calls'].idxmin()]\n",
        "    \n",
        "    print(\"\\\\nğŸ† ENHANCED AGENT PERFORMANCE WINNERS:\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"âš¡ Fastest: {fastest['Retriever']} ({fastest['Total Time (s)']:.2f}s total)\")\n",
        "    print(f\"ğŸ’° Most Cost-Effective: {cheapest['Retriever']} (${cheapest['Estimated Cost ($)']:.3f})\")\n",
        "    print(f\"ğŸ¯ Most Reliable: {most_reliable['Retriever']} ({most_reliable['Success Rate']:.1%} success)\")\n",
        "    print(f\"ğŸ”§ Most Efficient: {most_efficient['Retriever']} ({most_efficient['Avg Tool Calls']:.1f} avg tools)\")\n",
        "    \n",
        "    # Calculate combined score for overall best\n",
        "    successful_results = successful_results.copy()\n",
        "    successful_results['Combined Score'] = (\n",
        "        0.3 * successful_results['Success Rate'] + \n",
        "        0.25 * (1 / (successful_results['Total Time (s)'] + 1)) + \n",
        "        0.25 * (1 / (successful_results['Estimated Cost ($)'] + 0.001)) +\n",
        "        0.2 * (1 / (successful_results['Avg Tool Calls'] + 1))\n",
        "    )\n",
        "    \n",
        "    best_overall = successful_results.loc[successful_results['Combined Score'].idxmax()]\n",
        "    print(f\"ğŸŒŸ Best Overall: {best_overall['Retriever']} (Score: {best_overall['Combined Score']:.3f})\")\n",
        "    \n",
        "else:\n",
        "    print(\"\\\\nâš ï¸ No retrievers achieved >50% success rate. Check system configuration.\")\n",
        "\n",
        "print(f\"\\\\nğŸ¬ Enhanced Agent Movie Review Evaluation Complete!\")\n",
        "print(f\"â° Completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 11: LangSmith Advanced Evaluation Setup (QA Accuracy, Helpfulness, Relevance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”¬ Setting up LangSmith Advanced Evaluation...\n",
            "âœ… LangSmith detected - setting up advanced evaluation\n",
            "ğŸ“Š LangSmith dataset: movie-reviews-retriever-evalfinal-7de23b06\n",
            "ğŸ“ Using RAGAS-generated reference answers from synthetic_df...\n",
            "ğŸ“Š Available columns in synthetic_df: ['user_input', 'reference_contexts', 'reference', 'synthesizer_name']\n",
            "âœ… Using 10 RAGAS question-reference pairs for LangSmith evaluation\n",
            "âœ… Created LangSmith dataset with 10 examples\n",
            "ğŸ¯ LangSmith evaluation setup complete!\n",
            "ğŸ”§ LangSmith evaluation: ENABLED\n"
          ]
        }
      ],
      "source": [
        "# Setup LangSmith evaluation dataset and configuration\n",
        "print(\"ğŸ”¬ Setting up LangSmith Advanced Evaluation...\")\n",
        "\n",
        "# Check if LangSmith is available\n",
        "USE_LANGSMITH = bool(os.getenv(\"LANGSMITH_API_KEY\"))\n",
        "\n",
        "if USE_LANGSMITH:\n",
        "    print(\"âœ… LangSmith detected - setting up advanced evaluation\")\n",
        "    \n",
        "    try:\n",
        "        from langsmith import Client\n",
        "        from langsmith.evaluation import LangChainStringEvaluator, evaluate\n",
        "        from langchain.prompts import ChatPromptTemplate\n",
        "        from langchain.schema import StrOutputParser\n",
        "        from operator import itemgetter\n",
        "        \n",
        "        # Initialize LangSmith client\n",
        "        langsmith_client = Client()\n",
        "        \n",
        "        # Create dataset name for this evaluation\n",
        "        LANGSMITH_DATASET_NAME = f\"movie-reviews-retriever-evalfinal-{unique_id}\"\n",
        "        print(f\"ğŸ“Š LangSmith dataset: {LANGSMITH_DATASET_NAME}\")\n",
        "        \n",
        "        # Create dataset from our evaluation questions using RAGAS reference answers\n",
        "        dataset_inputs = []\n",
        "        dataset_outputs = []\n",
        "        \n",
        "        # Use the synthetic_df that was created by RAGAS (contains both questions and references)\n",
        "        num_questions = min(10, len(synthetic_df))  # Use subset for LangSmith eval\n",
        "        \n",
        "        print(f\"ğŸ“ Using RAGAS-generated reference answers from synthetic_df...\")\n",
        "        print(f\"ğŸ“Š Available columns in synthetic_df: {list(synthetic_df.columns)}\")\n",
        "        \n",
        "        # Find the correct reference column\n",
        "        if 'reference' in synthetic_df.columns:\n",
        "            reference_col = 'reference'\n",
        "        elif 'expected_output' in synthetic_df.columns:\n",
        "            reference_col = 'expected_output'\n",
        "        elif 'answer' in synthetic_df.columns:\n",
        "            reference_col = 'answer'\n",
        "        else:\n",
        "            reference_col = synthetic_df.columns[-1]  # Use last column as fallback\n",
        "            print(f\"âš ï¸ Using column '{reference_col}' as reference answers\")\n",
        "        \n",
        "        # Find the question column (already determined in RAGAS step)\n",
        "        if 'question' in synthetic_df.columns:\n",
        "            question_col = 'question'\n",
        "        elif 'user_input' in synthetic_df.columns:\n",
        "            question_col = 'user_input'\n",
        "        else:\n",
        "            question_col = synthetic_df.columns[0]\n",
        "        \n",
        "        for i in range(num_questions):\n",
        "            row = synthetic_df.iloc[i]\n",
        "            question = row[question_col]\n",
        "            reference = row[reference_col]\n",
        "            \n",
        "            dataset_inputs.append({\"question\": question})\n",
        "            dataset_outputs.append({\"answer\": reference})\n",
        "        \n",
        "        print(f\"âœ… Using {len(dataset_inputs)} RAGAS question-reference pairs for LangSmith evaluation\")\n",
        "        \n",
        "        # Create the dataset in LangSmith\n",
        "        try:\n",
        "            dataset = langsmith_client.create_dataset(\n",
        "                dataset_name=LANGSMITH_DATASET_NAME,\n",
        "                description=\"Movie review questions for retriever evaluation with RAGAS-generated references\"\n",
        "            )\n",
        "            \n",
        "            # Add examples to dataset\n",
        "            for inputs, outputs in zip(dataset_inputs, dataset_outputs):\n",
        "                langsmith_client.create_example(\n",
        "                    dataset_id=dataset.id,\n",
        "                    inputs=inputs,\n",
        "                    outputs=outputs\n",
        "                )\n",
        "            \n",
        "            print(f\"âœ… Created LangSmith dataset with {len(dataset_inputs)} examples\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            if \"already exists\" in str(e).lower():\n",
        "                print(f\"ğŸ“‹ Dataset {LANGSMITH_DATASET_NAME} already exists - using existing dataset\")\n",
        "            else:\n",
        "                print(f\"âš ï¸ Dataset creation issue: {e}\")\n",
        "                # Continue with evaluation anyway\n",
        "        \n",
        "        print(\"ğŸ¯ LangSmith evaluation setup complete!\")\n",
        "        \n",
        "    except ImportError as e:\n",
        "        print(f\"âŒ LangSmith libraries not available: {e}\")\n",
        "        print(\"ğŸ’¡ Install with: pip install langsmith\")\n",
        "        USE_LANGSMITH = False\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ LangSmith setup issue: {e}\")\n",
        "        USE_LANGSMITH = False\n",
        "\n",
        "else:\n",
        "    print(\"âš ï¸ LangSmith not configured - skipping advanced evaluation\")\n",
        "    print(\"ğŸ’¡ Set LANGSMITH_API_KEY environment variable to enable advanced metrics\")\n",
        "\n",
        "print(f\"ğŸ”§ LangSmith evaluation: {'ENABLED' if USE_LANGSMITH else 'DISABLED'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 12: LangSmith Advanced Evaluation Run Evaluation Using AGENTIC RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ”¬ Running LangSmith evaluation with ENHANCED AGENT for ALL retrievers...\n",
            "ğŸ¤– This tests the complete agentic pipeline with multi-tool selection\n",
            "ğŸ“Š Evaluating 6 retrievers with ENHANCED AGENT...\n",
            "ğŸ” Evaluators: QA Accuracy, Movie Helpfulness, Movie Relevance\n",
            "ğŸ¤– Testing: Complete agentic pipeline with tool selection and reasoning\n",
            "\n",
            "ğŸ” Evaluating Naive retriever with Enhanced Agent...\n",
            "View the evaluation results for experiment: 'enhanced_agent_naive-b02acd5f' at:\n",
            "https://smith.langchain.com/o/a8b64252-5f0f-4f35-a048-c004586e098a/datasets/571b3b25-acd2-44c8-8012-6015f838d6c9/compare?selectedSessions=bf8b540c-a127-49c8-ad4e-f75c85ea5ac5\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f7bf4c57b7534a19b24f4d47c692c1c5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/f1/cmsz4dgn2y194hgy1n_pldjc0000gn/T/ipykernel_87547/4270994735.py:61: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  retrieved_docs = base_retriever.get_relevant_documents(query)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 95\u001b[39m\n\u001b[32m     92\u001b[39m         base_retriever = original_retriever\n\u001b[32m     94\u001b[39m \u001b[38;5;66;03m# Run LangSmith evaluation with our enhanced agent wrapper\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m experiment_results = \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m    \u001b[49m\u001b[43menhanced_agent_wrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mLANGSMITH_DATASET_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m        \u001b[49m\u001b[43mqa_evaluator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmovie_helpfulness_evaluator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmovie_relevance_evaluator\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mretriever_type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mevaluation_run\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43menhanced_agent_retrievers\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mevaluators\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mqa_helpfulness_relevance\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdomain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmovie_reviews\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mevaluation_mode\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43menhanced_agent_pipeline\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43magent_features\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmulti_tool_selection_external_search_analytics\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    110\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43menhanced_agent_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m_\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m-\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m_\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    112\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâœ… \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m enhanced agent evaluation completed successfully\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    116\u001b[39m \u001b[38;5;66;03m# Add rate limiting delay between retrievers\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langsmith/evaluation/_runner.py:423\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(target, data, evaluators, summary_evaluators, metadata, experiment_prefix, description, max_concurrency, num_repetitions, client, blocking, experiment, upload_results, error_handling, **kwargs)\u001b[39m\n\u001b[32m    421\u001b[39m     _warn_once(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mupload_results\u001b[39m\u001b[33m'\u001b[39m\u001b[33m parameter is in beta.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    422\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRunning evaluation over target system \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOptional\u001b[49m\u001b[43m[\u001b[49m\u001b[43mSequence\u001b[49m\u001b[43m[\u001b[49m\u001b[43mEVALUATOR_T\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m    \u001b[49m\u001b[43msummary_evaluators\u001b[49m\u001b[43m=\u001b[49m\u001b[43msummary_evaluators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_concurrency\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_concurrency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m    \u001b[49m\u001b[43mblocking\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m    \u001b[49m\u001b[43mupload_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupload_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_handling\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langsmith/evaluation/_runner.py:1101\u001b[39m, in \u001b[36m_evaluate\u001b[39m\u001b[34m(target, data, evaluators, summary_evaluators, metadata, experiment_prefix, description, max_concurrency, num_repetitions, client, blocking, experiment, upload_results, error_handling)\u001b[39m\n\u001b[32m   1099\u001b[39m     manager = manager.with_summary_evaluators(summary_evaluators)\n\u001b[32m   1100\u001b[39m \u001b[38;5;66;03m# Start consuming the results.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1101\u001b[39m results = \u001b[43mExperimentResults\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocking\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langsmith/evaluation/_runner.py:580\u001b[39m, in \u001b[36mExperimentResults.__init__\u001b[39m\u001b[34m(self, experiment_manager, blocking)\u001b[39m\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    579\u001b[39m     \u001b[38;5;28mself\u001b[39m._thread = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m580\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langsmith/evaluation/_runner.py:605\u001b[39m, in \u001b[36mExperimentResults._process_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    603\u001b[39m tqdm = _load_tqdm()\n\u001b[32m    604\u001b[39m results = \u001b[38;5;28mself\u001b[39m._manager.get_results()\n\u001b[32m--> \u001b[39m\u001b[32m605\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_results\u001b[49m\u001b[43m.\u001b[49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/tqdm/notebook.py:250\u001b[39m, in \u001b[36mtqdm_notebook.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    249\u001b[39m     it = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__iter__\u001b[39m()\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# return super(tqdm...) will not catch exception\u001b[39;49;00m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langsmith/evaluation/_runner.py:1522\u001b[39m, in \u001b[36m_ExperimentManager.get_results\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1520\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_results\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterable[ExperimentResultRow]:\n\u001b[32m   1521\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the traces, evaluation results, and associated examples.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1522\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluation_results\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m   1523\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mruns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluation_results\u001b[49m\n\u001b[32m   1524\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1525\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mExperimentResultRow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1526\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1527\u001b[39m \u001b[43m            \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1528\u001b[39m \u001b[43m            \u001b[49m\u001b[43mevaluation_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluation_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1529\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langsmith/evaluation/_runner.py:1502\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   1497\u001b[39m \u001b[38;5;66;03m# Split the generator into three so the manager\u001b[39;00m\n\u001b[32m   1498\u001b[39m \u001b[38;5;66;03m# can consume each value individually.\u001b[39;00m\n\u001b[32m   1499\u001b[39m r1, r2, r3 = itertools.tee(experiment_results, \u001b[32m3\u001b[39m)\n\u001b[32m   1500\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._copy(\n\u001b[32m   1501\u001b[39m     (result[\u001b[33m\"\u001b[39m\u001b[33mexample\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m r1),\n\u001b[32m-> \u001b[39m\u001b[32m1502\u001b[39m     runs=\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr2\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1503\u001b[39m     evaluation_results=(result[\u001b[33m\"\u001b[39m\u001b[33mevaluation_results\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m r3),\n\u001b[32m   1504\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langsmith/evaluation/_runner.py:1691\u001b[39m, in \u001b[36m_ExperimentManager._score\u001b[39m\u001b[34m(self, evaluators, max_concurrency)\u001b[39m\n\u001b[32m   1689\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m max_concurrency == \u001b[32m0\u001b[39m:\n\u001b[32m   1690\u001b[39m     context = copy_context()\n\u001b[32m-> \u001b[39m\u001b[32m1691\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcurrent_results\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_evaluators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m            \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcurrent_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1696\u001b[39m \u001b[43m            \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1697\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1698\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langsmith/evaluation/_runner.py:1522\u001b[39m, in \u001b[36m_ExperimentManager.get_results\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1520\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_results\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterable[ExperimentResultRow]:\n\u001b[32m   1521\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the traces, evaluation results, and associated examples.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1522\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluation_results\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m   1523\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mruns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluation_results\u001b[49m\n\u001b[32m   1524\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1525\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mExperimentResultRow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1526\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1527\u001b[39m \u001b[43m            \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1528\u001b[39m \u001b[43m            \u001b[49m\u001b[43mevaluation_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluation_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1529\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langsmith/evaluation/_runner.py:1477\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   1469\u001b[39m _experiment_results = context.run(\n\u001b[32m   1470\u001b[39m     \u001b[38;5;28mself\u001b[39m._predict,\n\u001b[32m   1471\u001b[39m     target,\n\u001b[32m   1472\u001b[39m     max_concurrency=max_concurrency,\n\u001b[32m   1473\u001b[39m     include_attachments=_target_include_attachments(target),\n\u001b[32m   1474\u001b[39m )\n\u001b[32m   1475\u001b[39m r1, r2 = itertools.tee(_experiment_results, \u001b[32m2\u001b[39m)\n\u001b[32m   1476\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._copy(\n\u001b[32m-> \u001b[39m\u001b[32m1477\u001b[39m     (pred[\u001b[33m\"\u001b[39m\u001b[33mexample\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m r1), runs=\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1478\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langsmith/evaluation/_runner.py:1558\u001b[39m, in \u001b[36m_ExperimentManager._predict\u001b[39m\u001b[34m(self, target, max_concurrency, include_attachments)\u001b[39m\n\u001b[32m   1556\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m max_concurrency == \u001b[32m0\u001b[39m:\n\u001b[32m   1557\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.examples:\n\u001b[32m-> \u001b[39m\u001b[32m1558\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1559\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1560\u001b[39m \u001b[43m            \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1561\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1562\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1563\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_upload_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1565\u001b[39m \u001b[43m            \u001b[49m\u001b[43minclude_attachments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1566\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_error_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1567\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1569\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1570\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ls_utils.ContextThreadPoolExecutor(max_concurrency) \u001b[38;5;28;01mas\u001b[39;00m executor:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langsmith/evaluation/_runner.py:1924\u001b[39m, in \u001b[36m_forward\u001b[39m\u001b[34m(fn, example, experiment_name, metadata, client, upload_results, include_attachments, error_handling)\u001b[39m\n\u001b[32m   1922\u001b[39m arg_names = _get_target_args(fn)\n\u001b[32m   1923\u001b[39m args = [\u001b[38;5;28mgetattr\u001b[39m(example, argn) \u001b[38;5;28;01mfor\u001b[39;00m argn \u001b[38;5;129;01min\u001b[39;00m arg_names]\n\u001b[32m-> \u001b[39m\u001b[32m1924\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlangsmith_extra\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlangsmith_extra\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[38;5;66;03m# Reset attachment readers if attachments were used.\u001b[39;00m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m include_attachments \u001b[38;5;129;01mand\u001b[39;00m example.attachments \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 79\u001b[39m, in \u001b[36menhanced_agent_wrapper\u001b[39m\u001b[34m(inputs)\u001b[39m\n\u001b[32m     76\u001b[39m base_retriever = retriever\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# Use our enhanced agent function\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m result = \u001b[43mquery_enhanced_agent_with_tracing\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlangsmith_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m_\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m-\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m_\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     82\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[38;5;66;03m# Return the answer (LangSmith expects this format)\u001b[39;00m\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result.get(\u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mNo answer generated\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 59\u001b[39m, in \u001b[36mquery_enhanced_agent_with_tracing\u001b[39m\u001b[34m(question, run_name)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     56\u001b[39m     \u001b[38;5;66;03m# Execute with tracing metadata\u001b[39;00m\n\u001b[32m     57\u001b[39m     start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     result = \u001b[43menhanced_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfinal_answer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     65\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery_type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmovie_analysis\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msession_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43munique_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_name\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     end_time = time.time()\n\u001b[32m     77\u001b[39m     execution_time = end_time - start_time\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langgraph/pregel/main.py:3019\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, **kwargs)\u001b[39m\n\u001b[32m   3016\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3017\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3019\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3020\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3021\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3022\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3023\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3024\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3025\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3026\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3027\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3028\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3029\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3030\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3031\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3032\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3033\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langgraph/pregel/main.py:2651\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2649\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2650\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2651\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2653\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2654\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2655\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2656\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2657\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2658\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2659\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2660\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2661\u001b[39m loop.after_tick()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langgraph/pregel/_runner.py:162\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    160\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langgraph/pregel/_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:646\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    644\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    645\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m646\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    648\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:390\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    388\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    392\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 104\u001b[39m, in \u001b[36mfinal_response_node\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;66;03m# Create final prompt\u001b[39;00m\n\u001b[32m     94\u001b[39m final_prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[33mBased on the tool results above, provide a comprehensive answer to the question: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m     96\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    101\u001b[39m \u001b[33m- Be conversational but informative\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[33m\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m final_response = \u001b[43mchat_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfinal_prompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    107\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfinal_answer\u001b[39m\u001b[33m\"\u001b[39m: final_response.content,\n\u001b[32m    108\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [final_response]\n\u001b[32m    109\u001b[39m }\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:395\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    385\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    390\u001b[39m     **kwargs: Any,\n\u001b[32m    391\u001b[39m ) -> BaseMessage:\n\u001b[32m    392\u001b[39m     config = ensure_config(config)\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    394\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    405\u001b[39m     ).message\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:980\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    971\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    972\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    973\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    977\u001b[39m     **kwargs: Any,\n\u001b[32m    978\u001b[39m ) -> LLMResult:\n\u001b[32m    979\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m980\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:799\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    796\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    797\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    798\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m799\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    803\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    804\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    805\u001b[39m         )\n\u001b[32m    806\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    807\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1045\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1043\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1044\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1045\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1046\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1047\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1048\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1049\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1131\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1129\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n\u001b[32m   1130\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1131\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response, generation_info)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:1131\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1086\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1087\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1088\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1128\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   1129\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1130\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1131\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1136\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1137\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1138\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1139\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1140\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1141\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1142\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1143\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1144\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1145\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1146\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1147\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/openai/_base_client.py:1256\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1242\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1243\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1244\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1251\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1252\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1253\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1254\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1255\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1256\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/openai/_base_client.py:979\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    977\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    978\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    985\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.11-macos-aarch64-none/lib/python3.12/ssl.py:1232\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1228\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1229\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1230\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1231\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1232\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1233\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1234\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.11-macos-aarch64-none/lib/python3.12/ssl.py:1105\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1103\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1107\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "\n",
        "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness, ResponseRelevancy, ContextEntityRecall, NoiseSensitivity\n",
        "\n",
        "# Run LangSmith Advanced Evaluation with ENHANCED AGENT (not simple RAG)\n",
        "if USE_LANGSMITH:\n",
        "    print(\"\\nğŸ”¬ Running LangSmith evaluation with ENHANCED AGENT for ALL retrievers...\")\n",
        "    print(\"ğŸ¤– This tests the complete agentic pipeline with multi-tool selection\")\n",
        "    \n",
        "    try:\n",
        "        # Movie-specific evaluators (same as before)\n",
        "        eval_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "        qa_evaluator = LangChainStringEvaluator(\"qa\", config={\"llm\": eval_llm})\n",
        "        \n",
        "        # Movie review helpfulness evaluator\n",
        "        movie_helpfulness_evaluator = LangChainStringEvaluator(\n",
        "            \"labeled_criteria\",\n",
        "            config={\n",
        "                \"criteria\": {\n",
        "                    \"helpfulness\": (\n",
        "                        \"Is this submission helpful for someone looking for movie information,\"\n",
        "                        \" taking into account the correct reference answer about movies/reviews?\"\n",
        "                    )\n",
        "                },\n",
        "                \"llm\": eval_llm\n",
        "            },\n",
        "            prepare_data=lambda run, example: {\n",
        "                \"prediction\": run.outputs[\"output\"],\n",
        "                \"reference\": example.outputs[\"answer\"],\n",
        "                \"input\": example.inputs[\"question\"],\n",
        "            }\n",
        "        )\n",
        "        \n",
        "        # Movie review relevance evaluator\n",
        "        movie_relevance_evaluator = LangChainStringEvaluator(\n",
        "            \"criteria\",\n",
        "            config={\n",
        "                \"criteria\": {\n",
        "                    \"relevance\": \"Is this response relevant to the movie/review question? Does it provide useful movie information?\",\n",
        "                },\n",
        "                \"llm\": eval_llm\n",
        "            }\n",
        "        )\n",
        "        \n",
        "        # Define all retrievers to evaluate (using the same ones from our main evaluation)\n",
        "        all_retrievers_to_evaluate = [\n",
        "            (naive_retriever, \"Naive\"),\n",
        "            (bm25_retriever, \"BM25\"),\n",
        "            (multi_query_retriever, \"Multi-Query\"),\n",
        "            (parent_document_retriever, \"Parent-Document\"),\n",
        "            (compression_retriever, \"Contextual-Compression\"),\n",
        "            (ensemble_retriever, \"Ensemble\")\n",
        "        ]\n",
        "        \n",
        "        print(f\"ğŸ“Š Evaluating {len(all_retrievers_to_evaluate)} retrievers with ENHANCED AGENT...\")\n",
        "        print(\"ğŸ” Evaluators: QA Accuracy, Movie Helpfulness, Movie Relevance\")\n",
        "        print(\"ğŸ¤– Testing: Complete agentic pipeline with tool selection and reasoning\")\n",
        "        \n",
        "        # Evaluate each retriever with the ENHANCED AGENT\n",
        "        for retriever, name in all_retrievers_to_evaluate:\n",
        "            print(f\"\\nğŸ” Evaluating {name} retriever with Enhanced Agent...\")\n",
        "            \n",
        "            try:\n",
        "                # Create a wrapper function for LangSmith that uses our enhanced agent\n",
        "                def enhanced_agent_wrapper(inputs):\n",
        "                    \"\"\"\n",
        "                    Wrapper function that LangSmith can call to evaluate our enhanced agent.\n",
        "                    This swaps the retriever and runs the complete agentic pipeline.\n",
        "                    \"\"\"\n",
        "                    question = inputs[\"question\"]\n",
        "                    \n",
        "                    # Temporarily swap the retriever\n",
        "                    global base_retriever\n",
        "                    original_retriever = base_retriever\n",
        "                    \n",
        "                    try:\n",
        "                        # Swap in the current retriever being evaluated\n",
        "                        base_retriever = retriever\n",
        "                        \n",
        "                        # Use our enhanced agent function\n",
        "                        result = query_enhanced_agent_with_tracing(\n",
        "                            question, \n",
        "                            run_name=f\"langsmith_{name.lower().replace(' ', '_').replace('-', '_')}\"\n",
        "                        )\n",
        "                        \n",
        "                        # Return the answer (LangSmith expects this format)\n",
        "                        return result.get(\"answer\", \"No answer generated\")\n",
        "                        \n",
        "                    except Exception as e:\n",
        "                        return f\"Enhanced agent error: {str(e)}\"\n",
        "                    \n",
        "                    finally:\n",
        "                        # Always restore original retriever\n",
        "                        base_retriever = original_retriever\n",
        "                \n",
        "                # Run LangSmith evaluation with our enhanced agent wrapper\n",
        "                experiment_results = evaluate(\n",
        "                    enhanced_agent_wrapper,\n",
        "                    data=LANGSMITH_DATASET_NAME,\n",
        "                    evaluators=[\n",
        "                        qa_evaluator,\n",
        "                        movie_helpfulness_evaluator,\n",
        "                        movie_relevance_evaluator\n",
        "                    ],\n",
        "                    metadata={\n",
        "                        \"retriever_type\": name, \n",
        "                        \"evaluation_run\": \"enhanced_agent_retrievers\",\n",
        "                        \"evaluators\": \"qa_helpfulness_relevance\",\n",
        "                        \"domain\": \"movie_reviews\",\n",
        "                        \"evaluation_mode\": \"enhanced_agent_pipeline\",\n",
        "                        \"agent_features\": \"multi_tool_selection_external_search_analytics\"\n",
        "                    },\n",
        "                    experiment_prefix=f\"enhanced_agent_{name.lower().replace(' ', '_').replace('-', '_')}\"\n",
        "                )\n",
        "                \n",
        "                print(f\"âœ… {name} enhanced agent evaluation completed successfully\")\n",
        "                \n",
        "                # Add rate limiting delay between retrievers\n",
        "                print(f\"â±ï¸ Pausing briefly before next retriever...\")\n",
        "                time.sleep(3)  # 3 second delay between retrievers\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"âŒ {name} enhanced agent evaluation failed: {e}\")\n",
        "                continue\n",
        "        \n",
        "        print(\"\\nğŸ¯ All enhanced agent retriever evaluations completed!\")\n",
        "        print(\"ğŸ“Š Check LangSmith dashboard for detailed comparison results!\")\n",
        "        print(\"ğŸ” Each retriever tested with: Complete Enhanced Agent Pipeline\")\n",
        "        print(\"ğŸ¤– Includes: Multi-tool selection, external search, analytics, reasoning\")\n",
        "        print(f\"ğŸŒ LangSmith Project: {project_name}\")\n",
        "        print(f\"ğŸ“‹ Dataset: {LANGSMITH_DATASET_NAME}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Enhanced Agent LangSmith evaluation failed: {e}\")\n",
        "        print(\"ğŸ’¡ Check your LangSmith API key and network connection\")\n",
        "        \n",
        "else:\n",
        "    print(\"\\nâš ï¸ Skipping Enhanced Agent LangSmith evaluation (not configured)\")\n",
        "    print(\"ğŸ’¡ Configure LangSmith API key to enable:\")\n",
        "    print(\"   - Enhanced Agent QA Accuracy scoring\")\n",
        "    print(\"   - Enhanced Agent Movie helpfulness analysis\") \n",
        "    print(\"   - Enhanced Agent Content relevance evaluation\")\n",
        "    print(\"   - Enhanced Agent Tool usage analytics\")\n",
        "    print(\"   - Detailed agentic pipeline performance comparisons\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 13: LangSmith Advanced Evaluation Run Evaluation Basic RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ”¬ Running LangSmith evaluation for ALL movie review retrievers...\n",
            "ğŸ“Š Evaluating 6 movie review retrievers with LangSmith...\n",
            "ğŸ” Evaluators: QA Accuracy, Movie Helpfulness, Movie Relevance\n",
            "ğŸ“‹ This evaluation tests retrievers directly (not through enhanced agent)\n",
            "\n",
            "ğŸ” Evaluating Naive retriever on movie reviews...\n",
            "View the evaluation results for experiment: 'movie_retriever_naive-ac3fd236' at:\n",
            "https://smith.langchain.com/o/a8b64252-5f0f-4f35-a048-c004586e098a/datasets/2d89c42c-0b26-429c-82c5-e11a2ec88e53/compare?selectedSessions=1cd0d506-8e96-478b-9c7c-bf0cddb739de\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3741f8153c5f4cba90a4ddf4d3c0da7f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Naive movie review evaluation completed successfully\n",
            "â±ï¸ Pausing briefly before next retriever...\n",
            "\n",
            "ğŸ” Evaluating BM25 retriever on movie reviews...\n",
            "View the evaluation results for experiment: 'movie_retriever_bm25-871d04be' at:\n",
            "https://smith.langchain.com/o/a8b64252-5f0f-4f35-a048-c004586e098a/datasets/2d89c42c-0b26-429c-82c5-e11a2ec88e53/compare?selectedSessions=97fa8ff8-96c6-4a43-ad8f-16ebbd467e59\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6c7b161cedf43edacb8ac777b643c27",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… BM25 movie review evaluation completed successfully\n",
            "â±ï¸ Pausing briefly before next retriever...\n",
            "\n",
            "ğŸ” Evaluating Multi-Query retriever on movie reviews...\n",
            "View the evaluation results for experiment: 'movie_retriever_multi_query-9ab2d4e4' at:\n",
            "https://smith.langchain.com/o/a8b64252-5f0f-4f35-a048-c004586e098a/datasets/2d89c42c-0b26-429c-82c5-e11a2ec88e53/compare?selectedSessions=36e9f2de-38aa-4b00-8419-1256d17ea5ad\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a12a626854846e8a0b18d1ffa1a2d0a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Multi-Query movie review evaluation completed successfully\n",
            "â±ï¸ Pausing briefly before next retriever...\n",
            "\n",
            "ğŸ” Evaluating Parent-Document retriever on movie reviews...\n",
            "View the evaluation results for experiment: 'movie_retriever_parent_document-d0a54e61' at:\n",
            "https://smith.langchain.com/o/a8b64252-5f0f-4f35-a048-c004586e098a/datasets/2d89c42c-0b26-429c-82c5-e11a2ec88e53/compare?selectedSessions=5d6ad0b6-ddd2-49a9-94f0-4c0aa29a7eef\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d8bfa130e5d444ab342a9d5535f32c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Parent-Document movie review evaluation completed successfully\n",
            "â±ï¸ Pausing briefly before next retriever...\n",
            "\n",
            "ğŸ” Evaluating Contextual-Compression retriever on movie reviews...\n",
            "View the evaluation results for experiment: 'movie_retriever_contextual_compression-e3873fe3' at:\n",
            "https://smith.langchain.com/o/a8b64252-5f0f-4f35-a048-c004586e098a/datasets/2d89c42c-0b26-429c-82c5-e11a2ec88e53/compare?selectedSessions=a869713e-662c-4330-afc9-677f74a0334a\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f01c42e2c2948a09c191a2c7b57e26b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Contextual-Compression movie review evaluation completed successfully\n",
            "â±ï¸ Pausing briefly before next retriever...\n",
            "\n",
            "ğŸ” Evaluating Ensemble retriever on movie reviews...\n",
            "View the evaluation results for experiment: 'movie_retriever_ensemble-1a5e3f73' at:\n",
            "https://smith.langchain.com/o/a8b64252-5f0f-4f35-a048-c004586e098a/datasets/2d89c42c-0b26-429c-82c5-e11a2ec88e53/compare?selectedSessions=4e314c41-7427-4d23-a1ca-718d68adf17f\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44d802b70bef4865bbf333ba28b3c66d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Ensemble movie review evaluation completed successfully\n",
            "â±ï¸ Pausing briefly before next retriever...\n",
            "\n",
            "ğŸ¯ All movie review retriever evaluations completed!\n",
            "ğŸ“Š Check LangSmith dashboard for detailed comparison results!\n",
            "ğŸ” Each retriever has been evaluated for: QA Accuracy, Movie Helpfulness, Movie Relevance\n",
            "ğŸŒ LangSmith Project: Movie-Reviews-Enhanced-RAG-31693300\n",
            "ğŸ“‹ Dataset: movie-reviews-retriever-eval1-31693300\n"
          ]
        }
      ],
      "source": [
        "# Run LangSmith Advanced Evaluation for ALL Retrievers\n",
        "if USE_LANGSMITH:\n",
        "    print(\"\\nğŸ”¬ Running LangSmith evaluation for ALL movie review retrievers...\")\n",
        "    \n",
        "    try:\n",
        "        # Create RAG chain for movie review evaluation\n",
        "        MOVIE_RAG_PROMPT = \"\"\"Given the provided movie review context and question, answer the question based only on the context.\n",
        "If you cannot answer based on the context, say \"I don't know\".\n",
        "\n",
        "Focus on:\n",
        "- Movie titles, directors, genres, and release information\n",
        "- Critic opinions, scores, and sentiments\n",
        "- Review publication sources and dates\n",
        "- Rotten Tomatoes ratings (Tomatometer and Audience Score)\n",
        "\n",
        "Context: {context}\n",
        "Question: {question}\"\"\"\n",
        "        \n",
        "        rag_prompt = ChatPromptTemplate.from_template(MOVIE_RAG_PROMPT)\n",
        "        eval_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "        \n",
        "        # Movie-specific evaluators\n",
        "        qa_evaluator = LangChainStringEvaluator(\"qa\", config={\"llm\": eval_llm})\n",
        "        \n",
        "        # Movie review helpfulness evaluator\n",
        "        movie_helpfulness_evaluator = LangChainStringEvaluator(\n",
        "            \"labeled_criteria\",\n",
        "            config={\n",
        "                \"criteria\": {\n",
        "                    \"helpfulness\": (\n",
        "                        \"Is this submission helpful for someone looking for movie information,\"\n",
        "                        \" taking into account the correct reference answer about movies/reviews?\"\n",
        "                    )\n",
        "                },\n",
        "                \"llm\": eval_llm\n",
        "            },\n",
        "            prepare_data=lambda run, example: {\n",
        "                \"prediction\": run.outputs[\"output\"],\n",
        "                \"reference\": example.outputs[\"answer\"],\n",
        "                \"input\": example.inputs[\"question\"],\n",
        "            }\n",
        "        )\n",
        "        \n",
        "        # Movie review relevance evaluator\n",
        "        movie_relevance_evaluator = LangChainStringEvaluator(\n",
        "            \"criteria\",\n",
        "            config={\n",
        "                \"criteria\": {\n",
        "                    \"relevance\": \"Is this response relevant to the movie/review question? Does it provide useful movie information?\",\n",
        "                },\n",
        "                \"llm\": eval_llm\n",
        "            }\n",
        "        )\n",
        "        \n",
        "        # Define all retrievers to evaluate (using the same ones from our main evaluation)\n",
        "        all_retrievers_to_evaluate = [\n",
        "            (naive_retriever, \"Naive\"),\n",
        "            (bm25_retriever, \"BM25\"),\n",
        "            (multi_query_retriever, \"Multi-Query\"),\n",
        "            (parent_document_retriever, \"Parent-Document\"),\n",
        "            (compression_retriever, \"Contextual-Compression\"),\n",
        "            (ensemble_retriever, \"Ensemble\")\n",
        "        ]\n",
        "        \n",
        "        print(f\"ğŸ“Š Evaluating {len(all_retrievers_to_evaluate)} movie review retrievers with LangSmith...\")\n",
        "        print(\"ğŸ” Evaluators: QA Accuracy, Movie Helpfulness, Movie Relevance\")\n",
        "        print(\"ğŸ“‹ This evaluation tests retrievers directly (not through enhanced agent)\")\n",
        "        \n",
        "        # Evaluate each retriever\n",
        "        for retriever, name in all_retrievers_to_evaluate:\n",
        "            print(f\"\\nğŸ” Evaluating {name} retriever on movie reviews...\")\n",
        "            \n",
        "            try:\n",
        "                # Create RAG chain for this retriever\n",
        "                rag_chain = (\n",
        "                    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
        "                    | rag_prompt | eval_llm | StrOutputParser()\n",
        "                )\n",
        "                \n",
        "                # Run evaluation for this retriever\n",
        "                experiment_results = evaluate(\n",
        "                    rag_chain.invoke,\n",
        "                    data=LANGSMITH_DATASET_NAME,\n",
        "                    evaluators=[\n",
        "                        qa_evaluator,\n",
        "                        movie_helpfulness_evaluator,\n",
        "                        movie_relevance_evaluator\n",
        "                    ],\n",
        "                    metadata={\n",
        "                        \"retriever_type\": name, \n",
        "                        \"evaluation_run\": \"movie_review_retrievers\",\n",
        "                        \"evaluators\": \"qa_helpfulness_relevance\",\n",
        "                        \"domain\": \"movie_reviews\",\n",
        "                        \"evaluation_mode\": \"direct_retriever\"\n",
        "                    },\n",
        "                    experiment_prefix=f\"movie_retriever_{name.lower().replace(' ', '_').replace('-', '_')}\"\n",
        "                )\n",
        "                \n",
        "                print(f\"âœ… {name} movie review evaluation completed successfully\")\n",
        "                \n",
        "                # Add rate limiting delay between retrievers\n",
        "                print(f\"â±ï¸ Pausing briefly before next retriever...\")\n",
        "                time.sleep(3)  # 3 second delay between retrievers\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"âŒ {name} evaluation failed: {e}\")\n",
        "                continue\n",
        "        \n",
        "        print(\"\\nğŸ¯ All movie review retriever evaluations completed!\")\n",
        "        print(\"ğŸ“Š Check LangSmith dashboard for detailed comparison results!\")\n",
        "        print(\"ğŸ” Each retriever has been evaluated for: QA Accuracy, Movie Helpfulness, Movie Relevance\")\n",
        "        print(f\"ğŸŒ LangSmith Project: {project_name}\")\n",
        "        print(f\"ğŸ“‹ Dataset: {LANGSMITH_DATASET_NAME}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ LangSmith evaluation failed: {e}\")\n",
        "        print(\"ğŸ’¡ Check your LangSmith API key and network connection\")\n",
        "        \n",
        "else:\n",
        "    print(\"\\nâš ï¸ Skipping LangSmith evaluation (not configured)\")\n",
        "    print(\"ğŸ’¡ Configure LangSmith API key to enable:\")\n",
        "    print(\"   - QA Accuracy scoring\")\n",
        "    print(\"   - Movie helpfulness analysis\") \n",
        "    print(\"   - Content relevance evaluation\")\n",
        "    print(\"   - Detailed performance comparisons\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Evaluation Summary: Two Complementary Approaches\n",
        "\n",
        "This notebook provides **two complementary evaluation approaches** for your movie review RAG system:\n",
        "\n",
        "### ğŸ¤– **Enhanced Agent Evaluation** (Steps 8-10)\n",
        "- **What**: Tests retrievers within your complete enhanced agent pipeline\n",
        "- **Includes**: Multi-tool selection, external search, statistical analysis, and LangSmith tracing\n",
        "- **Metrics**: Success rate, tool usage, timing, cost estimation\n",
        "- **Purpose**: Real-world performance evaluation of your production system\n",
        "- **Output**: Production recommendations by use case (speed vs accuracy vs cost)\n",
        "\n",
        "### ğŸ”¬ **LangSmith Advanced Evaluation** (Step 11)\n",
        "- **What**: Tests retrievers directly with standardized LangSmith metrics\n",
        "- **Includes**: QA Accuracy, Helpfulness, and Relevance scoring\n",
        "- **Metrics**: Scientific evaluation scores for retriever comparison\n",
        "- **Purpose**: Detailed retriever analysis with industry-standard metrics\n",
        "- **Output**: Dashboard analytics and comparative scoring\n",
        "\n",
        "### ğŸ’¡ **Why Both Matter**:\n",
        "- **Enhanced Agent**: Shows how retrievers perform in your actual use case with all tools\n",
        "- **LangSmith**: Provides standardized metrics for scientific comparison\n",
        "- **Together**: Complete picture of retriever performance for optimal selection\n",
        "\n",
        "### ğŸ¯ **Next Steps**:\n",
        "1. **Run the notebook** to get both enhanced agent and LangSmith evaluations\n",
        "2. **Use Enhanced Agent results** for production deployment decisions  \n",
        "3. **Use LangSmith metrics** for detailed retriever analysis and optimization\n",
        "4. **Compare RAGAS references** with actual retriever outputs in LangSmith dashboard\n",
        "5. **Monitor both** in production for continuous improvement\n",
        "\n",
        "### ğŸ”§ **Key Fix Applied**:\n",
        "- âœ… **RAGAS Reference Integration**: LangSmith now uses actual RAGAS-generated reference answers instead of generic ones\n",
        "- âœ… **Proper Question-Answer Mapping**: Each evaluation question has its corresponding RAGAS reference\n",
        "- âœ… **Better Evaluation Quality**: More accurate helpfulness and relevance scoring\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ› ISOLATED RAGAS DEBUG - Testing with single example...\n",
            "================================================================================\n",
            "âœ… RAGAS imports successful\n",
            "ğŸ¯ Testing with SINGLE example outside LangSmith context\n",
            "\n",
            "ğŸ“‹ TEST DATA:\n",
            "   Question: What did Slant Magazine say about the movie Stay Cool and how does it reflect on the film's quality?\n",
            "   Reference: Slant Magazine's critic Adam Keleman described Stay Cool as thoroughly a family affair but felt it w...\n",
            "\n",
            "ğŸ” RETRIEVAL:\n",
            "   Retrieved 5 docs, using first 2\n",
            "   Context[0]: Movie: Stay Cool\\nGenre: Comedy\\nDirector: Michael Polish\\nRating: PG-13\\nRelease Date: nan\\nCritic:...\n",
            "   Context[1]: Movie: Stay Cool\\nGenre: Comedy\\nDirector: Michael Polish\\nRating: PG-13\\nRelease Date: nan\\nCritic:...\n",
            "\n",
            "ğŸ¤– RAG RESPONSE GENERATION:\n",
            "   Generated response: Slant Magazine, through critic Adam Keleman, described \"Stay Cool\" as feeling rushed and merely an homage to films like \"Pretty in Pink\" or \"Some Kind...\n",
            "\n",
            "ğŸ“Š RAGAS DATA STRUCTURE:\n",
            "   user_input: <class 'str'> - 'What did Slant Magazine say about the movie Stay C...'\n",
            "   response: <class 'str'> - 'Slant Magazine, through critic Adam Keleman, descr...'\n",
            "   retrieved_contexts: <class 'list'> - 2 items\n",
            "   reference: <class 'str'> - 'Slant Magazine's critic Adam Keleman described Sta...'\n",
            "\n",
            "ğŸ”¬ CREATING RAGAS DATASET:\n",
            "   Dataset created successfully!\n",
            "   Dataset type: <class 'ragas.dataset_schema.EvaluationDataset'>\n",
            "   Dataset length: 1\n",
            "\n",
            "âš¡ RUNNING RAGAS EVALUATION:\n",
            "   Metric: Faithfulness\n",
            "   LLM: client=<openai.resources.chat.completions.completions.Completions object at 0x1750db200> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x17588f740> root_client=<openai.OpenAI object at 0x17588f8c0> root_async_client=<openai.AsyncOpenAI object at 0x17588c0e0> model_name='gpt-4o-mini' temperature=1e-08 model_kwargs={} openai_api_key=SecretStr('**********') request_timeout=180 n=1\n",
            "   Embeddings: client=<openai.resources.embeddings.Embeddings object at 0x17588e150> async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x10593c770> model='text-embedding-3-small' dimensions=None deployment='text-embedding-ada-002' openai_api_version=None openai_api_base=None openai_api_type=None openai_proxy=None embedding_ctx_length=8191 openai_api_key=SecretStr('**********') openai_organization=None allowed_special=None disallowed_special=None chunk_size=1000 max_retries=2 request_timeout=180 headers=None tiktoken_enabled=True tiktoken_model_name=None show_progress_bar=False model_kwargs={} skip_empty=False default_headers=None default_query=None retry_min_seconds=4 retry_max_seconds=20 http_client=None http_async_client=None check_embedding_ctx_length=True\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "692c5611db01404db484d4618ac1ccd8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… RAGAS evaluation completed successfully!\n",
            "   Result type: <class 'ragas.dataset_schema.EvaluationResult'>\n",
            "   Result DataFrame shape: (1, 5)\n",
            "   Result DataFrame columns: ['user_input', 'retrieved_contexts', 'response', 'reference', 'faithfulness']\n",
            "   Faithfulness score: 0.7142857142857143\n",
            "\n",
            "ğŸ› ISOLATED DEBUG COMPLETE!\n",
            "ğŸ’¡ This test shows exactly where the RAGAS error occurs\n",
            "ğŸ’¡ If this fails, the issue is in RAGAS itself, not LangSmith integration\n"
          ]
        }
      ],
      "source": [
        "# # ğŸ› ISOLATED RAGAS DEBUG - Single Row Test (No LangSmith)\n",
        "\n",
        "# print(\"ğŸ› ISOLATED RAGAS DEBUG - Testing with single example...\")\n",
        "# print(\"=\" * 80)\n",
        "\n",
        "# try:\n",
        "#     from ragas import evaluate as ragas_evaluate, EvaluationDataset\n",
        "#     from ragas.metrics import faithfulness\n",
        "#     import os\n",
        "    \n",
        "#     # Disable RAGAS tracking\n",
        "#     os.environ['RAGAS_DO_NOT_TRACK'] = 'true'\n",
        "    \n",
        "#     print(\"âœ… RAGAS imports successful\")\n",
        "#     print(\"ğŸ¯ Testing with SINGLE example outside LangSmith context\")\n",
        "    \n",
        "#     # 1. Get one example from the dataset\n",
        "#     if 'synthetic_df' in locals() and len(synthetic_df) > 0:\n",
        "#         test_row = synthetic_df.iloc[0]\n",
        "#         test_question = test_row['user_input']\n",
        "#         test_reference = test_row['reference']\n",
        "        \n",
        "#         print(f\"\\nğŸ“‹ TEST DATA:\")\n",
        "#         print(f\"   Question: {test_question}\")\n",
        "#         print(f\"   Reference: {test_reference[:100]}...\")\n",
        "        \n",
        "#         # 2. Use naive retriever to get contexts\n",
        "#         print(f\"\\nğŸ” RETRIEVAL:\")\n",
        "#         retrieved_docs = naive_retriever.invoke(test_question)\n",
        "#         contexts = [doc.page_content for doc in retrieved_docs[:2]]\n",
        "        \n",
        "#         print(f\"   Retrieved {len(retrieved_docs)} docs, using first 2\")\n",
        "#         for i, ctx in enumerate(contexts):\n",
        "#             print(f\"   Context[{i}]: {ctx[:100]}...\")\n",
        "        \n",
        "#         # 3. Generate response using our RAG pipeline\n",
        "#         print(f\"\\nğŸ¤– RAG RESPONSE GENERATION:\")\n",
        "#         context_str = \"\\n\\n\".join(contexts)\n",
        "#         rag_prompt = f\"\"\"Given the movie review context, answer the question based only on the context.\n",
        "\n",
        "# Context: {context_str}\n",
        "# Question: {test_question}\"\"\"\n",
        "        \n",
        "#         test_response = chat_model.invoke(rag_prompt).content\n",
        "#         print(f\"   Generated response: {test_response[:150]}...\")\n",
        "        \n",
        "#         # 4. Create RAGAS evaluation data\n",
        "#         print(f\"\\nğŸ“Š RAGAS DATA STRUCTURE:\")\n",
        "#         eval_data = [{\n",
        "#             'user_input': test_question,\n",
        "#             'response': test_response,\n",
        "#             'retrieved_contexts': contexts,\n",
        "#             'reference': test_reference\n",
        "#         }]\n",
        "        \n",
        "#         print(f\"   user_input: {type(eval_data[0]['user_input'])} - '{eval_data[0]['user_input'][:50]}...'\")\n",
        "#         print(f\"   response: {type(eval_data[0]['response'])} - '{eval_data[0]['response'][:50]}...'\")\n",
        "#         print(f\"   retrieved_contexts: {type(eval_data[0]['retrieved_contexts'])} - {len(eval_data[0]['retrieved_contexts'])} items\")\n",
        "#         print(f\"   reference: {type(eval_data[0]['reference'])} - '{eval_data[0]['reference'][:50]}...'\")\n",
        "        \n",
        "#         # 5. Create RAGAS dataset\n",
        "#         print(f\"\\nğŸ”¬ CREATING RAGAS DATASET:\")\n",
        "#         ragas_dataset = EvaluationDataset.from_list(eval_data)\n",
        "#         print(f\"   Dataset created successfully!\")\n",
        "#         print(f\"   Dataset type: {type(ragas_dataset)}\")\n",
        "#         print(f\"   Dataset length: {len(ragas_dataset) if hasattr(ragas_dataset, '__len__') else 'Unknown'}\")\n",
        "        \n",
        "#         # 6. Run RAGAS evaluation (THIS IS WHERE THE ERROR LIKELY OCCURS)\n",
        "#         print(f\"\\nâš¡ RUNNING RAGAS EVALUATION:\")\n",
        "#         print(f\"   Metric: Faithfulness\")\n",
        "#         print(f\"   LLM: {chat_model}\")\n",
        "#         print(f\"   Embeddings: {embedding_model}\")\n",
        "        \n",
        "#         # Try with minimal parameters first\n",
        "#         try:\n",
        "#             result = ragas_evaluate(\n",
        "#                 dataset=ragas_dataset,\n",
        "#                 metrics=[faithfulness],\n",
        "#                 llm=chat_model,\n",
        "#                 embeddings=embedding_model\n",
        "#             )\n",
        "            \n",
        "#             print(f\"âœ… RAGAS evaluation completed successfully!\")\n",
        "#             print(f\"   Result type: {type(result)}\")\n",
        "            \n",
        "#             # Try to extract the score\n",
        "#             try:\n",
        "#                 result_df = result.to_pandas()\n",
        "#                 print(f\"   Result DataFrame shape: {result_df.shape}\")\n",
        "#                 print(f\"   Result DataFrame columns: {list(result_df.columns)}\")\n",
        "                \n",
        "#                 if 'faithfulness' in result_df.columns:\n",
        "#                     score = result_df['faithfulness'].iloc[0]\n",
        "#                     print(f\"   Faithfulness score: {score}\")\n",
        "#                 else:\n",
        "#                     print(f\"   âŒ 'faithfulness' column not found\")\n",
        "                    \n",
        "#             except Exception as score_error:\n",
        "#                 print(f\"   âŒ Error extracting score: {score_error}\")\n",
        "                \n",
        "#         except Exception as ragas_error:\n",
        "#             print(f\"âŒ RAGAS EVALUATION FAILED:\")\n",
        "#             print(f\"   Error: {ragas_error}\")\n",
        "#             print(f\"   Error type: {type(ragas_error)}\")\n",
        "            \n",
        "#             # Print full traceback for debugging\n",
        "#             import traceback\n",
        "#             print(f\"\\nğŸ” FULL TRACEBACK:\")\n",
        "#             traceback.print_exc()\n",
        "        \n",
        "#     else:\n",
        "#         print(\"âŒ No synthetic_df found - run RAGAS dataset generation first\")\n",
        "    \n",
        "#     # Clean up\n",
        "#     if 'RAGAS_DO_NOT_TRACK' in os.environ:\n",
        "#         del os.environ['RAGAS_DO_NOT_TRACK']\n",
        "        \n",
        "# except ImportError as e:\n",
        "#     print(f\"âŒ Import error: {e}\")\n",
        "# except Exception as e:\n",
        "#     print(f\"âŒ Unexpected error: {e}\")\n",
        "#     import traceback\n",
        "#     traceback.print_exc()\n",
        "\n",
        "# print(f\"\\nğŸ› ISOLATED DEBUG COMPLETE!\")\n",
        "# print(f\"ğŸ’¡ This test shows exactly where the RAGAS error occurs\")\n",
        "# print(f\"ğŸ’¡ If this fails, the issue is in RAGAS itself, not LangSmith integration\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”§ RAGAS WORKAROUND - Pre-computing scores outside LangSmith context...\n",
            "================================================================================\n",
            "âœ… RAGAS and LangSmith imports successful\n",
            "ğŸ”§ WORKAROUND: Pre-computing RAGAS scores outside LangSmith context\n",
            "ğŸ’¡ Issue: RAGAS tracing conflicts when running inside LangSmith evaluators\n",
            "\n",
            "ğŸ“Š Step 1: Pre-computing RAGAS scores for all dataset questions...\n",
            "   Found 12 questions in synthetic dataset\n",
            "\n",
            "ğŸ” Pre-computing RAGAS scores for Naive retriever...\n",
            "   Processing question 1/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eecc4d93837f4faebc4928a41a4ab009",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef78b5446a684b20968a4ad6fcb89996",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72bccb4c77154973b56f1d79aef0fd27",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed10d72aefd14b60b9a52ddad4d458cd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 2/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8208447025534274889aa636cdcd383f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5fd307c6e6ca405db0aba44d70e4d57c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0940d666657c445ab4fd29f7377a1fa5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ce82c3521bf4b97b0600b53ad91337b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 3/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8530325919564db589ac86930ad1ef44",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a9c10b106394476fb44d44dae3502117",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56283ae4ca97481fa6fa1e3b0c0ed10d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a28741338c54bd591ca376d7970e032",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 4/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a00153c81d63487a9b2fd0ea16ad3d4a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc4d32260f9e4f2198bcdaf20d751a2b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a586582a4454413282e9adc2560e3b3d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "399837f9f3ef45268801d689d9fb753d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 5/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5d5123f00014b8d8b16786d211cf6bc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74229200794a44ed90bf05df96b3797e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a495d6f7acf24896bc04389471583fd0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "32be66d13a2d4a9d84aec31de1d14d58",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 6/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cfbc70638be04fa0953bf2d4a401dde3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1c19a9ef78b4f6c82f4f19f4e6bb5db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e17a9c851bd145909f4915afe055d05d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a023bdae82974ec4b4237a7d62925041",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 7/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2d0b31fabe349888a885eb2d5ca5d41",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80c5a7c86a324a30a1827fc311a218df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2f4e002b2564e80a150c9bfc6d4f122",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84ad234ce5c0452a8f88f268f25eca56",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 8/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec13b5261dc046e390407fa3dd845173",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "34494fb2f1434e55977e83f00dbaa739",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e46ed425d6e54c70bc8e9282178819ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea775b8de92c4e8ca2ef275d8e5f13ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 9/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cdfcc64631ea4efa9c4351086fd52f61",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2eb6498e08e4abf82ad48cafe52a3cb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a66f85b37ee24dc184cb205f7e8735b3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ad1cd56d0df4b4ca484e08d608a342a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 10/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54336b460fcc4752ad5095ae7da611ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f7f56108f42455c8ea4d960cf551021",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f7a2d36a3e40446ab24296c397cc8387",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "46b0bd70ed3544d6804352e9bd24a439",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 11/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "881a3097421a498fa4082b55c8ee46cf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63c7c2b8b1a945e493364c165438f32d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5a968e2e3ab4ce1908701f4869775b4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be0846efa409432bb7a5ad9aa47e8b7c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 12/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88536e04e1a6468e94afdcc22e349cd6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d0b52f22e6b94383bbfa9e3c643adf13",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9635e542002d4d10a0cc089f6ed94057",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca31a07c406f46d6890b0b3eb3aaa4e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… Naive average scores: {'faithfulness': 0.9090909090909092, 'answer_relevancy': 0.6541499491567708, 'context_precision': 0.6249999999458333, 'context_recall': 0.5416666666666666}\n",
            "\n",
            "ğŸ” Pre-computing RAGAS scores for BM25 retriever...\n",
            "   Processing question 1/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f489c11e7b7043dabb060f01d9170c61",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5aee973e4271426fbbbace6e7eb711fb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1056aa997e045b6be871685bc7e4d72",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d07b0758f924fa089f574a107fa7fca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 2/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "30ad83a5c8974fc698c1d264a3e774aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c208157736b436ab710b3fb01c30245",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "abd8216123d648a7a9f2ef9563a8f285",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f41a26e7ba75457e8d4dcb61cbe979f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 3/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4a67f91b22a482eb12c9d7ad727aa70",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "26d668a457674a6a878f6b4c3de770f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9223adbcce7241a7a29648d10db242c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0eab22bf2ca844e1b020a105c15957d1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 4/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c0758f959c341339576a5355ba808b1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f56e112369e2418ab0e067e18b71eb4a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "266067739e7c4cebac4240ae88a64b9d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "423ff5915d5f450f9e64e1ae870dc69a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 5/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "69647d2a3fbe4b8faea8b0a92944437a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73d87010949c4aa3808912d3892116e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "afa7f2c2a9814e2db75dcf94f73b73e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "857e26723bbd4668b9f1693c3bdb7eaf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 6/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b81d998dd3a943348e1c9c48df88bfa1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ded7ee40d00849649b30ae6bf65b417c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "930a22220afc4d9aa916ab18ebaf4c72",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c030437b75824156b1050195905740aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 7/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac2af77a9f8841b695c2201efbc8f0e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b2e43577e40450d8cad59b2c4f599ba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "45062bf2a9a14cd58515c91e798926e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2bc528c82fb24e279b258cefbabe4864",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 8/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3eb12ea32d004168aa417d82d78a508c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31b64cbd28ae483fa1f43836683f47fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "12bb96a7f64f4a13aa251ad1b858388f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bae11ec2809340fe86ab9f824e6b243c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 9/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "345b4443b90b48efa44d04a796b07a42",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e219cf8b4664cfab1e0f4fba8659f1f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8864c9a0ebf4e40a71a646c76bb1699",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5743ab8fbb1c492a98eca61f73674634",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 10/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1899b9d49ed14fda8f6360f3478e34ce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b6a906333f343acbbb81ea8cf4f1009",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9fffee8ae08c4ede981e09fb1005f731",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bddf0cb97db349e1af262cd3371b19c8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 11/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eec34eb7e8b249bfbaae489797cf377d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "edbdd342a1d04e2babfb8203a3fc87ca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ad25a8d553246ca9690427c7e2ef834",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e2069ab2ff0438582417a3140490daa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 12/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5845716a5ca419caa2aedc1f5347885",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aec8a425d8c74113bc76dc995750f273",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7229b8957d2847c1827d67e5c8331317",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "181299bf928d420781f3dba77c618e6d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… BM25 average scores: {'faithfulness': 0.876388888888889, 'answer_relevancy': 0.5621569131638228, 'context_precision': 0.4999999999625, 'context_recall': 0.4166666666666667}\n",
            "\n",
            "ğŸ” Pre-computing RAGAS scores for Multi-Query retriever...\n",
            "   Processing question 1/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bed17d0c166a44f1a60cd22a295664cf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ca7d5dccd964f9aa84c33be32613d9b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e6d308cbb9f461abde38b659afb2198",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff54e0ebe2e149ad81d916ebc0d179f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 2/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a4c1366ca9c46e98de1f176c2a9b3f1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "883640a9b71c4335a10a0a5d7131ca4c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "407573c8f2eb42318582831ba2fb1a3c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8771857fc61645cf9300b41a3aa137da",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 3/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c10a1d63ca84b89a57b2dd522bf07b4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f7b3356af1b04a8fadd14ef217b9e2f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "71415189b540486b8b6b7362081fcb10",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18b1aa1cc697400fb70ae74a76b7766b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 4/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6483c5b12e864757a40e0ef26224b548",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87f4367bdcb94d81aa145c04c1fa5bf9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c480c748c2a743e8b5d1c919a34217e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8bb9c55e547c4515a986a84b4488f8a5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 5/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ef9ac2792fd401b8f0b78129cd447e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb0fc38ecfef422ea742a9ea03ffed09",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd54cd9632cf4510b4a3599952b2bd5e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "577a1d5f800447848e14ab4149273a58",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 6/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5bf60270ca734c389af7ef0ec313f5b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "578c7d21430c46998ddd9b83b1dcadaa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6a5bd8e886d4a02936a27434fcf1150",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b2d721248c684e369f043d7a71272c6e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 7/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "029ff15376584d7f8b5d18e87ac629bf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b52f5c61fe234a459cfcb900592a174f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a83147ab9c64849bb6ee7bca95939c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2bda1cd78e3d4fb3a29471617273a76a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 8/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2e99e6063da428da644e7f921bd3ca5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d9927d3fab54eaf8a39383d0528d414",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7171e4de143b452aacfeae1b7683628a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a40907cbc8a04841992888ef4a5a85c5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 9/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a9c5ce38597e4c3db949e0b0edfd2042",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea2bffe720334f5394a512ea6fbbc677",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a1ef4a30f35427dbe85b14a359f9f18",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da5e68ed091d4540844412249863092e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 10/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39d031b730cd43069a304d294b36f297",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a17b99a6ae8a4c6fa05ff689b30eaea4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2bc1bac87af14653870bb1d1ce06d336",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd477ebe55ef4017b1eba1f3f916e165",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 11/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21cb7d776dff46f088cbd7f086f82f0a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21017c06eb8a4e13ae3e7c0816cde186",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21bba0da26e743d6b22f9f4c3327445e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a26927c4a5549a7b9cdbce1e1dc0ad3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 12/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa70d465d69c4f4bb66130cc1be8baec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a4a33d6319e4b7ababfe21a3fdbd206",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "662f248d12b44b4faed03da61eb67324",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c61cf1be147428ca57de6c5c57d1c9e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… Multi-Query average scores: {'faithfulness': 0.9041666666666667, 'answer_relevancy': 0.6479321683277005, 'context_precision': 0.5833333332833334, 'context_recall': 0.47222222222222227}\n",
            "\n",
            "ğŸ” Pre-computing RAGAS scores for Parent-Document retriever...\n",
            "   Processing question 1/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74bcbddcb3b947f99b0d1e7f51059b2d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ddeefff69c545faaf5cd317619b8263",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d059aa8d946742e595f47383113d6638",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ddcb2f7dab694a00aecd5bbbd7a004af",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 2/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0bfd8da3521e434bac5576cfa153ef0f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cabaff7c1cee4939957328f484743b17",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82f684117cbb4beb886d15e566a6e065",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f42de80384f149d4b3468c21af508095",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 3/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a374b805ba24292859adebf8b6732a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4314574870aa4cb6b45dc5daeca5e2ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b95cb6e49914c8292e820653c85006e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e644c6a1020e4b45abe4a12515df75c8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 4/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "86a95f8069bf45c6ae1d227d3d50e951",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "32fc3323270a47b0b589f5767a9a466b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e54d38aeed594bc98844fe37f6fd214d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4cb380baea5a437f9350aa1b11549604",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 5/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f20c850597d4d1ca4844a5d9f8b5bef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "207d461e220345609c5a5cc64979f022",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "394e81b39e5c4f73abe3394c2694062a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35fdef3c60eb4f9083d813f3ad4a9fd7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 6/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60fcdf3d88184e1082e6327d536e1a73",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca88142e01f44b3789634a1e342252f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae684d01527e4a3490dc065227e7f5e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77047cb38feb4cd2a117de96d288c6e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 7/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1bca9105aa0e4a20be9c373f55ed9c15",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f38d07bce51f4244b1d2ee35a7e15a6d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e33f92c7b2d4678bd90dc6af4646d86",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "734b1b6bf2744202b49f925716127924",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 8/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c4ff682198c460488668ad964f957aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff18806fe5a146b881004b5a3775e157",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36546fd7072141a38c879fd79b8c199f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "10ba1105b2d74781880a93846d3c61e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 9/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97cc3970487f4665b691ea5c63da0fa7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d20dc5eb8be24bb98449ebd8bf881127",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dbf4d1760e4f4f7580b51a977fcd046f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9bab84ac9c864ad4a1a7e0298fc38582",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 10/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "25e382a3c79f4fc0a357c7d312881ed2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b53338848d4f4132a64464a4b344758e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bcca7950b0d84ecf875eb82faa40d756",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "641769b7bbec4016b9771c4d6f7dae4e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 11/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a1d5257023840bf9f63740057404016",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7806de316bd046099460a41ee003fbc6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9cb25fe905a24dd18431bc3aa980c979",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "557d93a6ab6042bd97f1cffcfc8a1f83",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 12/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b818a07d47cc43ffaae8e67035524aa4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f753bce8b2ae4d9280fe1360ad28f242",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec74fae5beec4725b5fd3995fae8c424",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc052a487ae8406ab01be25d0cd0ead8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… Parent-Document average scores: {'faithfulness': 0.8954156954156954, 'answer_relevancy': 0.7214588575192243, 'context_precision': 0.6666666666083333, 'context_recall': 0.548611111111111}\n",
            "\n",
            "ğŸ” Pre-computing RAGAS scores for Contextual-Compression retriever...\n",
            "   Processing question 1/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aab8491de0fe4fa5b2032f83ff72a0e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42c803668c714fb89f89ebff48ca56f1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6713dfcf10804d9bb9486c10a878d2dc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d64bba0e5efe4bf4acf703cbc0449738",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 2/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93017cf550c34b14b9c102ff1782460e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a9141e057734e6d83c177525791bcf2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0fdfe1a1e59b46b8b6b15c524292104b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb4befccadde4d8894950e6824e64461",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 3/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48c7b1744b524819a7f1347127f817ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40c4ecc459a44191be332d240186d8fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8bb72790265d41c9abf1d44297d12da2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5401f7c891e944acb9bd6adb5ff24dd1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 4/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b68546ac0664472be8f989dc2c8acf1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b46c3116ef24205ba6f1c479040d03b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15bce8cff2d64b3ca7fbf05890056782",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "91a445e708954af18f874f712e6ffca8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 5/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d45cdc818a841d4af9414466676b13f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55e0ac75131540f0ad2f75e27a30375b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8d85df41f0741c6a96fca0bfc6f4904",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fde5dcd0833a4a51a24dddd331d9ce06",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 6/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f606965539b74b85a67a130f1d9d71e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58ff1d633cc84ea787612ee36b7bcaf0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1bc06382da0e4650925f3dbe27189977",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38aaba3ce2e44531b8e8fc360e8e9b76",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 7/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9aca1d4985054702bf1f6dd3b1069e9f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5765302f3e1c4d82a329a92e288113c5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "591552f996594e5b9245924fb2d964ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b64493ed9a1a4d74bfc37240aea4aa9a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 8/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c744b5fab8324946aff6ee1401840fc6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fed9e75a6d6a41c5bb4bbf44f0ee5aa5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "400c49b65c8a45928be7bad0ec92839d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b47f546e6e54b8b914559617319a309",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 9/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "356fa5e994c74bfda7bb0a850a34e9f1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ba69e1ce01e4234bdecf4a86aff3011",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb60e421044f4e0184a1c92b0ebf1566",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a17d79dc611434bb07a091986242bdb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 10/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f28c110a83e5431289ae13457ec6b4e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3f8897f19494e3493c34c9c8a6a8c3d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b63dd467ef1e41109b6a8afd8eadcb27",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7692a24f592c4dc3be54784bd529a456",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 11/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f28cb2bef2e348ec97a026ada18ccfa8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a353822b7b048bb877147c16e5ba705",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "334d07b449b44ecf955a94d3f3322441",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3962b5aafba849eea269dd6ee65ca900",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 12/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c9bda4575706419895e9adc97e20fcf8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "53adc3c88e6741319f334a2669060751",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05df0fd1d8454b2a83dc2d82d384c33f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "debbf270813b409eb16bad5945e9f4d4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… Contextual-Compression average scores: {'faithfulness': 0.8898148148148147, 'answer_relevancy': 0.7228061368183281, 'context_precision': 0.7499999999375001, 'context_recall': 0.576388888888889}\n",
            "\n",
            "ğŸ” Pre-computing RAGAS scores for Ensemble retriever...\n",
            "   Processing question 1/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "227d4331e1124c3494363443d1f84492",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1d2db44e8ae4c9093ac64bc2b9f2697",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99f3fb8300d44a4099a5ede279de58a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5180f3c4e2c74104b6d2f478a4202826",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 2/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55ecf2d1c93d4de495bfa822ec8405dd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84a0ae5975b145bba13bfdc115963861",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1de8af2952f9413eaf6f8bbc08037b5f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac6af652c82845859f0e48bf2908efff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 3/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0bdde0f4b55a45d5872352cb11dce334",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47ec952b70084dac8813b1fcfbab7e93",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1085346efda04f2584cd8efe90d35e9b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb1e1ef5782945ecb8cacb9d9951ad38",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 4/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a29a7ae29669417191521b3f6e9fe9a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4215b441f214ddf92788415176a05d1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d4166f66e004b2a82bf30d92569d4c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db2fa5288f4044689fc750998360ddb2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 5/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0458d31cb1c04e819f5f9813dbe31edc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7f72a3de52145c6b258bb3ba95d68fd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "523d1b822bbd430bb8fc12eb5737b02a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "287bfc37dec04973a681b6d29f51e33d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 6/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae44a2dbab4c4970b6ae9950d59df0b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7da4a04d12d24ac8aef8a6c513ab3d5f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4b9ae078b89400f938879f095445890",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d47e3f7f25a466e99aeb9e0a58c7ef9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 7/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d5937a7a6bca4a98adc932f38dcccc8f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c78c24c176684a67a2b1ecb0791a75f1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "744c969b9ac64d62a2a855291beea3e7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c9e64f6b23754ec28ca00868d4cfb948",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 8/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c935852ce694e92adebbfd207ce451d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b613c43113554b6487dbb3bf9cd9174a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "33c07945ada84d96aa694a644b5047e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19d780dbdafa455fa27d29ee518f5d65",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 9/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc0d726348e8462491834d264fc42561",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2996d380872048c18f30d99eb7fd8542",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b05b6eb966324e8dbf20ecb898ce4ffb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2db4f937b634353a90fd2748922cc47",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 10/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea539a6025e442c89d4475f3c5602c4f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47a567f40ea849a4bae94a7cb72bd885",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "651e7418aa24496aa1577a4f06abad44",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c9b1410f79054c18b0bbe8cb1dd10322",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 11/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f299f3de52e478794fc6e83f15a4ca5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "429bd3d7380249b4ae133ecd592eab81",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60aaff68f64a47b38d996d52661db7bf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "446eff018fc944f29c3953ba5749131a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Processing question 12/12...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aae559be15634a9197cdc70971af0f1c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "83ba8fa08d4b44d4a91fea3a45636511",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c945ef700bb4d6e8be73dcf9f02aa09",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "074ff96db39b4ac1856528ed99596883",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… Ensemble average scores: {'faithfulness': 0.7811507936507937, 'answer_relevancy': 0.7235935305423552, 'context_precision': 0.5833333332833334, 'context_recall': 0.5416666666666666}\n",
            "\n",
            "ğŸ“Š Step 2: Creating LangSmith evaluators with pre-computed scores...\n",
            "âœ… Pre-computed evaluators created\n",
            "\n",
            "ğŸ“Š Step 3: Running LangSmith evaluation with pre-computed RAGAS scores...\n",
            "\n",
            "ğŸ” Running LangSmith evaluation for Naive retriever (with pre-computed RAGAS)...\n",
            "View the evaluation results for experiment: 'ragas_precomputed_naive-f8b4f1e5' at:\n",
            "https://smith.langchain.com/o/a8b64252-5f0f-4f35-a048-c004586e098a/datasets/571b3b25-acd2-44c8-8012-6015f838d6c9/compare?selectedSessions=df1d9682-d5cc-4aca-af79-f2d71f14512c\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54123c82d9d24bc49df69dc318f8b651",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Naive LangSmith evaluation completed (with pre-computed RAGAS scores)\n",
            "â±ï¸ Pausing before next retriever...\n",
            "\n",
            "ğŸ” Running LangSmith evaluation for BM25 retriever (with pre-computed RAGAS)...\n",
            "View the evaluation results for experiment: 'ragas_precomputed_bm25-c3c9c984' at:\n",
            "https://smith.langchain.com/o/a8b64252-5f0f-4f35-a048-c004586e098a/datasets/571b3b25-acd2-44c8-8012-6015f838d6c9/compare?selectedSessions=b132156c-9891-4098-bfda-bc1ed4f305b8\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "78da96ac43374e22b577b172bc141ca3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… BM25 LangSmith evaluation completed (with pre-computed RAGAS scores)\n",
            "â±ï¸ Pausing before next retriever...\n",
            "\n",
            "ğŸ” Running LangSmith evaluation for Multi-Query retriever (with pre-computed RAGAS)...\n",
            "View the evaluation results for experiment: 'ragas_precomputed_multi_query-98e4f4c3' at:\n",
            "https://smith.langchain.com/o/a8b64252-5f0f-4f35-a048-c004586e098a/datasets/571b3b25-acd2-44c8-8012-6015f838d6c9/compare?selectedSessions=b9446cb8-e658-47a7-815b-5fe331a210ea\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b21a4710e7a3429c8606586ee6950c9c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Multi-Query LangSmith evaluation completed (with pre-computed RAGAS scores)\n",
            "â±ï¸ Pausing before next retriever...\n",
            "\n",
            "ğŸ” Running LangSmith evaluation for Parent-Document retriever (with pre-computed RAGAS)...\n",
            "View the evaluation results for experiment: 'ragas_precomputed_parent_document-482d830d' at:\n",
            "https://smith.langchain.com/o/a8b64252-5f0f-4f35-a048-c004586e098a/datasets/571b3b25-acd2-44c8-8012-6015f838d6c9/compare?selectedSessions=d3bce4c0-15b3-4e38-b9da-77967a3fbd88\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95212cb7ec7f43028725a05cef7f028d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Parent-Document LangSmith evaluation completed (with pre-computed RAGAS scores)\n",
            "â±ï¸ Pausing before next retriever...\n",
            "\n",
            "ğŸ” Running LangSmith evaluation for Contextual-Compression retriever (with pre-computed RAGAS)...\n",
            "View the evaluation results for experiment: 'ragas_precomputed_contextual_compression-8e076536' at:\n",
            "https://smith.langchain.com/o/a8b64252-5f0f-4f35-a048-c004586e098a/datasets/571b3b25-acd2-44c8-8012-6015f838d6c9/compare?selectedSessions=0650d6a0-1afc-4095-a7bf-78226c205bda\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "304d2af4f50e4543969a94b8eff64808",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Contextual-Compression LangSmith evaluation completed (with pre-computed RAGAS scores)\n",
            "â±ï¸ Pausing before next retriever...\n",
            "\n",
            "ğŸ” Running LangSmith evaluation for Ensemble retriever (with pre-computed RAGAS)...\n",
            "View the evaluation results for experiment: 'ragas_precomputed_ensemble-6cf337da' at:\n",
            "https://smith.langchain.com/o/a8b64252-5f0f-4f35-a048-c004586e098a/datasets/571b3b25-acd2-44c8-8012-6015f838d6c9/compare?selectedSessions=57988428-7430-4a47-ae8b-6bfb63cd33fa\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d808721adcf416fa1b4afa54ce0dfeb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Ensemble LangSmith evaluation completed (with pre-computed RAGAS scores)\n",
            "â±ï¸ Pausing before next retriever...\n",
            "\n",
            "ğŸ“Š SUMMARY: Pre-computed RAGAS Scores by Retriever\n",
            "================================================================================\n",
            "                        faithfulness  answer_relevancy  context_precision  \\\n",
            "Naive                          0.909             0.654              0.625   \n",
            "BM25                           0.876             0.562              0.500   \n",
            "Multi-Query                    0.904             0.648              0.583   \n",
            "Parent-Document                0.895             0.721              0.667   \n",
            "Contextual-Compression         0.890             0.723              0.750   \n",
            "Ensemble                       0.781             0.724              0.583   \n",
            "\n",
            "                        context_recall  \n",
            "Naive                            0.542  \n",
            "BM25                             0.417  \n",
            "Multi-Query                      0.472  \n",
            "Parent-Document                  0.549  \n",
            "Contextual-Compression           0.576  \n",
            "Ensemble                         0.542  \n",
            "\n",
            "ğŸ¯ All evaluations completed!\n",
            "âœ… WORKAROUND: RAGAS tracing conflicts resolved by pre-computing scores\n",
            "ğŸ“Š Check LangSmith dashboard for detailed comparisons!\n",
            "ğŸ”¬ Each retriever evaluated with pre-computed RAGAS metrics\n",
            "ğŸŒ LangSmith Project: Movie-Reviews-Enhanced-RAG-d7df46c9\n",
            "ğŸ“‹ Dataset: movie-reviews-retriever-eval4-d7df46c9\n",
            "\n",
            "ğŸ”§ RAGAS-LangSmith Integration Complete (WORKAROUND VERSION)!\n",
            "ğŸ”¬ Pre-computed approach avoids tracing conflicts completely\n",
            "ğŸ“Š Scientific retriever comparison available in LangSmith dashboard\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# ğŸ”§ RAGAS Metric Evaluation - WORKAROUND (Pre-compute scores outside LangSmith)\n",
        "\n",
        "if USE_LANGSMITH:\n",
        "    print(\"ğŸ”§ RAGAS WORKAROUND - Pre-computing scores outside LangSmith context...\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    try:\n",
        "        from ragas import evaluate as ragas_evaluate, EvaluationDataset\n",
        "        from ragas.metrics import (\n",
        "            answer_relevancy,\n",
        "            faithfulness,\n",
        "            context_precision,\n",
        "            context_recall\n",
        "        )\n",
        "        from langsmith.evaluation import evaluate\n",
        "        from langsmith.schemas import Run, Example\n",
        "        import os\n",
        "        import pandas as pd\n",
        "        \n",
        "        # Disable RAGAS tracking\n",
        "        os.environ['RAGAS_DO_NOT_TRACK'] = 'true'\n",
        "        \n",
        "        print(\"âœ… RAGAS and LangSmith imports successful\")\n",
        "        print(\"ğŸ”§ WORKAROUND: Pre-computing RAGAS scores outside LangSmith context\")\n",
        "        print(\"ğŸ’¡ Issue: RAGAS tracing conflicts when running inside LangSmith evaluators\")\n",
        "        \n",
        "        # Step 1: Pre-compute RAGAS scores for all questions with each retriever\n",
        "        print(f\"\\nğŸ“Š Step 1: Pre-computing RAGAS scores for all dataset questions...\")\n",
        "        \n",
        "        # Get all questions from the dataset\n",
        "        if 'synthetic_df' in locals() and len(synthetic_df) > 0:\n",
        "            questions = synthetic_df['user_input'].tolist()\n",
        "            references = synthetic_df['reference'].tolist()\n",
        "            print(f\"   Found {len(questions)} questions in synthetic dataset\")\n",
        "        else:\n",
        "            print(\"âŒ No synthetic_df found - run RAGAS dataset generation first\")\n",
        "            questions = []\n",
        "            references = []\n",
        "        \n",
        "        # Define retrievers to evaluate\n",
        "        retrievers_for_ragas = [\n",
        "            (naive_retriever, \"Naive\"),\n",
        "            (bm25_retriever, \"BM25\"),\n",
        "            (multi_query_retriever, \"Multi-Query\"),\n",
        "            (parent_document_retriever, \"Parent-Document\"),\n",
        "            (compression_retriever, \"Contextual-Compression\"),\n",
        "            (ensemble_retriever, \"Ensemble\")\n",
        "        ]\n",
        "        \n",
        "        # Store pre-computed scores\n",
        "        precomputed_scores = {}\n",
        "        \n",
        "        # Pre-compute RAGAS scores for each retriever\n",
        "        for retriever, retriever_name in retrievers_for_ragas:\n",
        "            print(f\"\\nğŸ” Pre-computing RAGAS scores for {retriever_name} retriever...\")\n",
        "            \n",
        "            retriever_scores = {\n",
        "                'faithfulness': [],\n",
        "                'answer_relevancy': [],\n",
        "                'context_precision': [],\n",
        "                'context_recall': []\n",
        "            }\n",
        "            \n",
        "            # Process each question\n",
        "            for i, (question, reference) in enumerate(zip(questions, references)):\n",
        "                print(f\"   Processing question {i+1}/{len(questions)}...\")\n",
        "                \n",
        "                try:\n",
        "                    # Get contexts using current retriever\n",
        "                    retrieved_docs = retriever.invoke(question)\n",
        "                    contexts = [doc.page_content for doc in retrieved_docs[:2]]\n",
        "                    \n",
        "                    # Generate response using RAG\n",
        "                    context_str = \"\\n\\n\".join(contexts)\n",
        "                    rag_prompt = f\"\"\"Given the movie review context, answer the question based only on the context.\n",
        "\n",
        "Context: {context_str}\n",
        "Question: {question}\"\"\"\n",
        "                    \n",
        "                    response = chat_model.invoke(rag_prompt).content\n",
        "                    \n",
        "                    # Create RAGAS evaluation data\n",
        "                    eval_data = [{\n",
        "                        'user_input': question,\n",
        "                        'response': response,\n",
        "                        'retrieved_contexts': contexts,\n",
        "                        'reference': reference\n",
        "                    }]\n",
        "                    \n",
        "                    # Run RAGAS evaluation OUTSIDE LangSmith context\n",
        "                    ragas_dataset = EvaluationDataset.from_list(eval_data)\n",
        "                    \n",
        "                    # Evaluate each metric separately to isolate any issues\n",
        "                    metrics_to_eval = [\n",
        "                        (faithfulness, 'faithfulness'),\n",
        "                        (answer_relevancy, 'answer_relevancy'),\n",
        "                        (context_precision, 'context_precision'),\n",
        "                        (context_recall, 'context_recall')\n",
        "                    ]\n",
        "                    \n",
        "                    for metric, metric_name in metrics_to_eval:\n",
        "                        try:\n",
        "                            result = ragas_evaluate(\n",
        "                                dataset=ragas_dataset,\n",
        "                                metrics=[metric],\n",
        "                                llm=chat_model,\n",
        "                                embeddings=embedding_model\n",
        "                            )\n",
        "                            \n",
        "                            # Extract score\n",
        "                            result_df = result.to_pandas()\n",
        "                            if metric_name in result_df.columns:\n",
        "                                score = float(result_df[metric_name].iloc[0])\n",
        "                            else:\n",
        "                                score = 0.0\n",
        "                            \n",
        "                            retriever_scores[metric_name].append(score)\n",
        "                            \n",
        "                        except Exception as metric_error:\n",
        "                            print(f\"     âš ï¸ Error evaluating {metric_name}: {metric_error}\")\n",
        "                            retriever_scores[metric_name].append(0.0)\n",
        "                    \n",
        "                except Exception as question_error:\n",
        "                    print(f\"     âŒ Error processing question {i+1}: {question_error}\")\n",
        "                    # Add 0.0 for all metrics if question fails\n",
        "                    for metric_name in retriever_scores:\n",
        "                        retriever_scores[metric_name].append(0.0)\n",
        "            \n",
        "            # Store average scores for this retriever\n",
        "            avg_scores = {}\n",
        "            for metric_name, scores in retriever_scores.items():\n",
        "                avg_scores[metric_name] = sum(scores) / len(scores) if scores else 0.0\n",
        "            \n",
        "            precomputed_scores[retriever_name] = avg_scores\n",
        "            print(f\"   âœ… {retriever_name} average scores: {avg_scores}\")\n",
        "        \n",
        "        # Step 2: Create simple LangSmith evaluators that return pre-computed scores\n",
        "        print(f\"\\nğŸ“Š Step 2: Creating LangSmith evaluators with pre-computed scores...\")\n",
        "\n",
        "        def make_metric_evaluator(metric_key: str, retriever_name: str):\n",
        "            \"\"\"Return a LangSmith evaluator that always looks up the\n",
        "            already-computed `metric_key` for `retriever_name`.\"\"\"\n",
        "            def _evaluator(run: Run, example: Example) -> dict:\n",
        "                return {\n",
        "                    \"key\": metric_key,\n",
        "                    \"score\": precomputed_scores[retriever_name][metric_key]\n",
        "                }\n",
        "            return _evaluator\n",
        "\n",
        "        \n",
        "        def create_precomputed_evaluator(metric_name):\n",
        "            \"\"\"Create evaluator that returns pre-computed RAGAS scores\"\"\"\n",
        "            def precomputed_evaluator(run: Run, example: Example) -> dict:\n",
        "                # Determine which retriever is being used (from metadata or experiment name)\n",
        "                current_retriever_name = \"Naive\"  # Default fallback\n",
        "                \n",
        "                # Try to get retriever name from run metadata\n",
        "                if hasattr(run, 'extra') and run.extra:\n",
        "                    current_retriever_name = run.extra.get('retriever_type', 'Naive')\n",
        "                \n",
        "                # Get pre-computed score for this retriever and metric\n",
        "                if current_retriever_name in precomputed_scores:\n",
        "                    score = precomputed_scores[current_retriever_name].get(metric_name.lower().replace(' ', '_'), 0.0)\n",
        "                else:\n",
        "                    score = 0.0\n",
        "                \n",
        "                return {\n",
        "                    \"key\": metric_name.lower().replace(' ', '_'),\n",
        "                    \"score\": score\n",
        "                }\n",
        "            \n",
        "            return precomputed_evaluator\n",
        "        \n",
        "        # Create pre-computed evaluators\n",
        "        faithfulness_evaluator = create_precomputed_evaluator(\"Faithfulness\")\n",
        "        answer_relevancy_evaluator = create_precomputed_evaluator(\"Answer_Relevancy\")\n",
        "        context_precision_evaluator = create_precomputed_evaluator(\"Context_Precision\")\n",
        "        context_recall_evaluator = create_precomputed_evaluator(\"Context_Recall\")\n",
        "        \n",
        "        print(f\"âœ… Pre-computed evaluators created\")\n",
        "        \n",
        "        # Step 3: Run LangSmith evaluation with pre-computed scores\n",
        "        print(f\"\\nğŸ“Š Step 3: Running LangSmith evaluation with pre-computed RAGAS scores...\")\n",
        "        \n",
        "        # Global variable to track current retriever\n",
        "        current_retriever_for_ragas = None\n",
        "        \n",
        "        # Evaluate each retriever with pre-computed RAGAS scores\n",
        "        for retriever, name in retrievers_for_ragas:\n",
        "            print(f\"\\nğŸ” Running LangSmith evaluation for {name} retriever (with pre-computed RAGAS)...\")\n",
        "            \n",
        "            try:\n",
        "                # Set current retriever\n",
        "                current_retriever_for_ragas = retriever\n",
        "                \n",
        "                # Create RAG wrapper\n",
        "                def precomputed_rag_wrapper(inputs):\n",
        "                    \"\"\"Simple RAG wrapper for use with pre-computed scores\"\"\"\n",
        "                    question = inputs[\"question\"]\n",
        "                    \n",
        "                    try:\n",
        "                        retrieved_docs = current_retriever_for_ragas.invoke(question)\n",
        "                        contexts = [doc.page_content for doc in retrieved_docs[:2]]\n",
        "                        context_str = \"\\n\\n\".join(contexts)\n",
        "                        \n",
        "                        rag_prompt = f\"\"\"Given the movie review context, answer the question based only on the context.\n",
        "\n",
        "Context: {context_str}\n",
        "Question: {question}\"\"\"\n",
        "                        \n",
        "                        response = chat_model.invoke(rag_prompt).content\n",
        "                        return {\"output\": response}\n",
        "                        \n",
        "                    except Exception as e:\n",
        "                        return {\"output\": f\"RAG error: {str(e)}\"}\n",
        "                \n",
        "                # Run LangSmith evaluation with pre-computed RAGAS metrics\n",
        "                experiment_results = evaluate(\n",
        "                    precomputed_rag_wrapper,\n",
        "                    data=LANGSMITH_DATASET_NAME,\n",
        "                    evaluators=[\n",
        "                        faithfulness_evaluator,\n",
        "                        answer_relevancy_evaluator,\n",
        "                        context_precision_evaluator,\n",
        "                        context_recall_evaluator\n",
        "                    ],\n",
        "                    metadata={\n",
        "                        \"retriever_type\": name,\n",
        "                        \"evaluation_run\": \"ragas_metrics_precomputed\",\n",
        "                        \"evaluators\": \"faithfulness_answer_relevancy_context_precision_context_recall\",\n",
        "                        \"domain\": \"movie_reviews\",\n",
        "                        \"evaluation_mode\": \"ragas_precomputed_scores\",\n",
        "                        \"framework\": \"ragas_langsmith_workaround\"\n",
        "                    },\n",
        "                    experiment_prefix=f\"ragas_precomputed_{name.lower().replace(' ', '_').replace('-', '_')}\"\n",
        "                )\n",
        "                \n",
        "                print(f\"âœ… {name} LangSmith evaluation completed (with pre-computed RAGAS scores)\")\n",
        "                \n",
        "                # Rate limiting delay\n",
        "                print(f\"â±ï¸ Pausing before next retriever...\")\n",
        "                time.sleep(3)\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"âŒ {name} evaluation failed: {e}\")\n",
        "                continue\n",
        "        \n",
        "        # Display summary of pre-computed scores\n",
        "        print(f\"\\nğŸ“Š SUMMARY: Pre-computed RAGAS Scores by Retriever\")\n",
        "        print(\"=\" * 80)\n",
        "        summary_df = pd.DataFrame(precomputed_scores).T\n",
        "        print(summary_df.round(3))\n",
        "        \n",
        "        print(f\"\\nğŸ¯ All evaluations completed!\")\n",
        "        print(f\"âœ… WORKAROUND: RAGAS tracing conflicts resolved by pre-computing scores\")\n",
        "        print(f\"ğŸ“Š Check LangSmith dashboard for detailed comparisons!\")\n",
        "        print(f\"ğŸ”¬ Each retriever evaluated with pre-computed RAGAS metrics\")\n",
        "        print(f\"ğŸŒ LangSmith Project: {project_name}\")\n",
        "        print(f\"ğŸ“‹ Dataset: {LANGSMITH_DATASET_NAME}\")\n",
        "        \n",
        "        # Clean up\n",
        "        current_retriever_for_ragas = None\n",
        "        if 'RAGAS_DO_NOT_TRACK' in os.environ:\n",
        "            del os.environ['RAGAS_DO_NOT_TRACK']\n",
        "        \n",
        "    except ImportError as e:\n",
        "        print(f\"âŒ RAGAS or LangSmith import error: {e}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Pre-computed RAGAS evaluation failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "else:\n",
        "    print(\"âš ï¸ Skipping RAGAS evaluation (LangSmith not configured)\")\n",
        "\n",
        "print(f\"\\nğŸ”§ RAGAS-LangSmith Integration Complete (WORKAROUND VERSION)!\")\n",
        "print(\"ğŸ”¬ Pre-computed approach avoids tracing conflicts completely\")\n",
        "print(\"ğŸ“Š Scientific retriever comparison available in LangSmith dashboard\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”§ RAGAS WORKAROUND â€“ Pre-computing scores outside LangSmith contextâ€¦\n",
            "================================================================================\n",
            "âœ… RAGAS and LangSmith imports successful\n",
            "ğŸ“Š Found 12 questions in synthetic dataset\n",
            "\n",
            "ğŸ” Pre-computing scores for Â«NaiveÂ» retriever â€¦\n",
            "   â€¢ Question 1/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4cec9e5810734e88858d4f2c1013bfbc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8007586b23cc48af93173d970497f80d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85edd7f522d84cb79e050cd626fb4f12",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d877735033f4dddb85d22d18fb22f32",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 2/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9059c6f024a64adfb623f994660d0adf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4428ed1409654ce484b9542baf578e4e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8aebd919d57e443fa9f114b49b3b759d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62340ec77ee84305a169ac08500369ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 3/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "86968ae8c9db4b94b6a125cdd9e26c73",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a0f592930f243babd899b8c59e89d68",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01a1727783da4b71a62e4018eac89985",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f872f08e249b4a78b2bd8bd552994e6a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 4/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0e69691b59c4aaa890b59579a6a8ffe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d1db876a2b94fb599f9b713dfcb4414",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e8c2b666d5745dbab7b32e6967dcb01",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93a1766d9f0a402fbc778cb0fba42af3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 5/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e8e0904e10e34307860871a3fdc88e8d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "00941791a01645a9ad44a80755413647",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2f54bc5be224138981509ecb33a67e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3abc46d3142e433f922b1adfffc64467",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 6/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7bef96d9c4604aafb3ad9437df6c5ef3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2269acec76a48a18fdeaba527720889",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac699891b2274dae8cea14985eb947a8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44b90a75065c44489557ca69500f9303",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 7/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d5188d7c7d54eae986d78386c53db3c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d218cb6e56e476384eb998a312ca044",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cfcb222fcd704d5494d06dd7ba483b8b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "192278507ef54dcaaebef1912999face",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 8/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84e235f6b12944d38992935f095b0b65",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cfa9a500cbae4a14b63c684accbdc87d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b483c776bc441b4babc16ed4741d4df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fcd0b87b9e134c2e973c5499093d0964",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 9/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "450e88ab707344d79ee10486f37fc629",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb75a84e9aef4adba8c2417294486ead",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3635b11f1116453283c42a8a43ea605f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59f6bf76612e43d8a519ece4b005d566",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 10/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b50b080c9629493fad1f014c5cf4df42",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c9e0dc707a14ae286870115e8bd13a5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cdde81bc7d2c498d8a3d220eb689d3be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58ff7775870446cfb6b1560f72c6e3bd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 11/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea3d88d5ffbb488dbf874aa6b0b1baa6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73ba00db1626433288aafa86b09c00ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3748892bb7e84535a6ab6de621f030af",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b02fcacbd3964e91886e3870d125a845",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 12/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a87d377e9aa44a9ba38f11a532049ded",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b81ce92563e4db18398b8b327b5ba26",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ccb598e3b5345b288aedc532fb79c84",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d5904598ef944949aac9fa581ba647a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… Avg scores for Â«NaiveÂ»: {'faithfulness': 0.7786172161172161, 'answer_relevancy': 0.7946670977353238, 'context_precision': 0.8333333332541667, 'context_recall': 0.8166666666666668}\n",
            "\n",
            "ğŸ” Pre-computing scores for Â«BM25Â» retriever â€¦\n",
            "   â€¢ Question 1/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ab14ef4050140918432aa173c037e75",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7d7b78b581d41afb9c3ce5891fe6971",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a8b8eb7a8a746b58cd088c65eb0fbd8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4cf4fe45566647eb9c28e6ba16a831f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 2/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "222a16f9c456488baf82c8de212ad444",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49c90f6942a14ae7bd4eda0440a84510",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d54345c46aff4a82879297e2c96b9026",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3c65c0496d74108834dcca76acc70ce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 3/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba3aaae7142a4dc290bee8593dbd4013",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c13c103851f842c58147673eea9aae76",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf3e9def703146bd85d69efce2b805ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c9e6166616e42428a0f7d3d9bbd7356",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 4/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63c32e822b60463284b62f9fda3bb29c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed3ab5a376154d5abc9c7486c12a6a2c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85341ec02a994aa8ab6dca718cce0cd0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "acc485efa64842f9a80d8a05edd7273d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 5/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3fc4b2de7d42426199af4309ad7ef6e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9d52dce10cb4a6e895cbec499d39907",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e16263e088a4bb8a825c6dc3e51107a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e50c8855732d4bf1b6b80a1018ef8d2b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 6/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5123c93291814208b3ca9aea12d61856",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2a01fce1f484a519d8c1622da32ba0d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "71cb0873376c43e5b0758496f301f7d4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2bb4af234c8c4848a067f42981ca73d4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 7/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc50d59ba53d4c0b9f89ac40c6910d9a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "427cbcc83af94d1388b930264f924e91",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2411a4d57b7f4f6eb50190f7585aa132",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87ea40dea2e945ce9c21884e27016040",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 8/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b9c57e81e5e949fd9bf40c793045c78f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08b5f93e5704435283c1d951ac1f0bbe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b222b1f2bc6e4778ac9a3ae20354aab5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f06ab02488b940d59b713697bfdaf9a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 9/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fefae8a4396f4089aca7849fa4ec37a7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b629fa6096384c418add1b21f26d8290",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0687c86aa36149ff9d86a8f9b10c8c1b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b8ac31f6571847a2a7ec2f9ee5f1332f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 10/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "86629aa397fd49e09bd30149edeb245a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6cc94aaf914e45d9bfaef09f6d92dbbe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "53640b268f304ea696593d5dcfb95389",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef0e4e398945445e9b179e611d99494d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 11/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a2ce795f7ec42088d313a3d394cae82",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc963903c9eb4575adf3b4676c68567f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "46a0633441704f61a9e3553ca0079708",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6bfd8ea5a544aae8c7fa39f1e99862f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 12/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb1a73dbef624bae83b8b0ffb2319b92",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d71c7c1c2f0346e3bf87ff080db4268f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b01741e458fc4c9a87114deacb42e455",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4f9184f279e4425913c53c644b3ee51",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… Avg scores for Â«BM25Â»: {'faithfulness': 0.8208573833573833, 'answer_relevancy': 0.484477993961654, 'context_precision': 0.7083333332624999, 'context_recall': 0.6944444444444445}\n",
            "\n",
            "ğŸ” Pre-computing scores for Â«Multi-QueryÂ» retriever â€¦\n",
            "   â€¢ Question 1/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6df431665ef4dd08401904b897f3ef8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec80e8929e8249ee8a37950af611438b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a89ff2c52d1f4947bdf721de4c172ef4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4ac113848694b22931b13be6f2cafec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 2/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a13b87c0f8704c3e8ba14f79c39a035d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39b01ac2ff26441bb777be5eb86e9593",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84e45fdde4604d5c9583f24624a06af4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception raised in Job[0]: TimeoutError()\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7afc46da72d44509e8dd07c858723e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 3/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f85130f22764c3482c43ed99e248efc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f7b68b02d014958bf82093e4e92f9eb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c8428e3aaf94c6fa65da2333f09448a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "967a7047f045486ca734d94a8826dd5d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 4/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e21d22f3c664436a9ef699d5af7f4976",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5dd353cbb5a42feba8528fbe95786a2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "616a2d013fe44bea8214b41006892bfc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65f588a9f7c241a7be825b0a2ad50ecc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 5/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7536b1c53f134406b0bf04c1bf853481",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17b042bf584a4dd49c7d75203a1d2edf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dbe9893caae14ed4afdb4c24b315029f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c3b5cffcc8f4a7e94dcc8685d10a7d6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 6/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c756ec170834473bbb2e4f855c43ac4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5203a764ecf54aa986ca67bd70aa0d2a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e35a9888d16f4276a3359aba5d96dfc7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90addefde1db450c9714d46e55809bc1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 7/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad38dcbf2b16417dac49925c7dcf8d7f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b58ba8a4ba3847a18ac869ead360d871",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "28a60c92f04a40a3b4ee874337022d92",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3000a4ac98b3457d862c168f858c06f9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 8/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e160d927ba9d4fe99a573b7e6786fa0e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31fd21bc016c48d5aa2fa297c9f1314d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fdf856dd79c7434d9dfa3db703bd52f6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8dc2e04ffdae4bb9a95ced411f9bf4b8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 9/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "287df202e60c487f8ab060633a20ae65",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d8773717d884411afc62cb702a5e429",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c22c0219982344c68609a908ffb083a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8532c939db4340718a7bf8d95253b342",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 10/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0439ef180555432580cbb0c93da8065b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee3b030c87354f63a76ee1a762c39e87",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09997294b5bf4522889f73310a27667a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c397286c79bb4aee84fb87a1787a8edb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 11/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "33053dc7bf4b4b9980c72d50830045ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f5a8d46f48f4f19aaf54bedd4a9a5ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed32e1d41cde46a298326425bc156144",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "800670030a8b4d979c7db54ecd616681",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 12/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5782befbd04040e88c65469c29b5ec1d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "06dbcb0d338042a8a82d2c12f5b57af0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e163acd0a71c4e788e4d619ffd088146",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f43ad6585e846c9b4fee2f0d0a05f5c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… Avg scores for Â«Multi-QueryÂ»: {'faithfulness': 0.8390151515151515, 'answer_relevancy': 0.7226773462384805, 'context_precision': nan, 'context_recall': 0.8333333333333334}\n",
            "\n",
            "ğŸ” Pre-computing scores for Â«Parent-DocumentÂ» retriever â€¦\n",
            "   â€¢ Question 1/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9941d95131704654bc0c4b0171ac925c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "04df90d2d6a54187b5f41095f8ee167e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "417f738067e84b6cbdbbec16ae654f56",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f8e8da9ca9540ed900709fc43b3aef7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 2/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "61fee1ab47bc48179dea10ae470a2d6d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31f888bc3ccf4d01a969805e0ef3c305",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21396f69b7bd473ebccc037f59fecc16",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54698949f2774bfdb0ab2a5f48eb44a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 3/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6cea202c14164471950b89bb273fab3c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d2836c5c6db485db85a70cca3eb5fb6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d3f76e343e2445a92599c6651259053",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9cb5a81939b43799213d8182beccdd1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 4/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5b713c610bb4b21ba313582563dadad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "880f689cec7f4420abc0d7b2e6b75278",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "625420c2613f47e99ddcd5e6d17f44ed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6d8e133d0af408691cae190def531b3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 5/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ddb8d651200453297dd9774adb9b5e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c01cad2b89c443239946f6d7feb9806c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2fa1c2d0bf604b2eb68f29bc68f8c60c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b82320cd07894efc89915830aa7ac61e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 6/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cadd3cee12094548b0f7329252c06309",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62592ff8a7a2420fa124af2dd7757463",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f7de443765e8495a84c45f81a2166f5a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "af25e6bd25114e26bb8a890bdfe0849f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 7/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "267a6800706e486c875f495022702e47",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee66a49d597e4a7abfdb13779a053936",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "45f5f6e0dad848b6ae6e2f3733863c53",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17a3227865de484fbd8155f75474949b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 8/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b76e513c1d3c482baf011621ed6f3828",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03eb181ad1ee4279a4b7b1aea385f2a2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19eb9d0d7a5d4de7b2de4b59f371e4ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6280483c1ea4eedbeb7df0aad79b7a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 9/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08593fd2a0b040788d8a1f10b7ceb931",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "264910d3fa884074aaa304e9e1bc65d8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "345bb1ad113845c98e8faac07678427b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9354904e0ec34163a2e7e2ee9056e0e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 10/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1de5e4793fe744cb9a785e950d4dc795",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ca887cfb2f347b484b1d10ef0e59a90",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7216d39df3f54c72b6d207770874feee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "125490302d0b4860ac737397150dcfc0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 11/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5fca67ae49f4d1d8031d065b4dd4f6f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a4e7157a63f48f3afd14db23c6ccbdf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dfb4c221e99a4d158e744a9040e5ff44",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b821dfa1596a4e34a96b9051faf8c14a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 12/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "056c4575047f4d61b029dab2dad11ab6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f94464380ce746a491293aeab00f334d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5fe9a72bef8439cbb105fcc999e9cb3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56d979f1257945608d3b9d9afb0b550e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… Avg scores for Â«Parent-DocumentÂ»: {'faithfulness': 0.8305555555555556, 'answer_relevancy': 0.765725307251287, 'context_precision': 0.916666666575, 'context_recall': 0.8888888888888888}\n",
            "\n",
            "ğŸ” Pre-computing scores for Â«Contextual-CompressionÂ» retriever â€¦\n",
            "   â€¢ Question 1/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63e34c26908240099b37ce1d094248d8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c2207a4c39b4c1aa0409102e0d560e4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b4166768d1d46b4b536cd1cfe64cf39",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cdcb2815a0224e5cbaf1ce4327e4e943",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 2/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "34c1e699eec64a81937e1f807476ef5c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d4150378067488aad51f3a7ac99bd1a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ed793ed93604b7ea4c0ecf68a54f3c9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82e9ff102dd84717bc8ee6acfc261f36",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 3/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f442251dd46342a992a02687c0c6c096",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f295cd891f85494097c98c5d51f5df98",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d07e943e51474e70b924ce760fa7ee94",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c133e580f3784a4f8067cf035321a087",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 4/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5bd1cdaf96c343ba887626821633ba63",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba13db2fb3f1497d91e72fda60cea9ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a283eda5fae423bb396163f22d8a0f3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "682a3fe8306549178548c778f8e41f83",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 5/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1854bf4679e648c3a6f042f1cc249c1c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6d68c1dbee94f6e8bdb6e13dd9483e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7937cb4d3534c29bf9b6af12128978f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f8571f014d86491eaf8122fe2c713eab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 6/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59f29d2facf446cb9c1a5e24b30c5038",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c0b410dcd9a47359d70df3139d06350",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e76dbb3e8101423e9a339af2efda3c35",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51173845cfef47f1b12859b96f79dfc8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 7/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43bcf8e648094d74a467fa6a79a07bef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "457432ecc32446558876fd37cfe9977b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "26b3b8c3ac58424facf031e35d17afce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a54fd096bbdc43d6a5c890c04e400eb9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 8/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b8d865326a94ba1bb80905d71e798ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7672d59ddd0a4398b2896c7bebbefa64",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3109c8c6d8f94bf0b48ca0d80a6f4e00",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d5199e71588a4ab5b0fecae722f66ae9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 9/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62a34b6b24be497bb6a04f17a6ac7412",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ffa47062cbe540baafe8e5d861933ed5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e17ded0947184e8890310dd1e76cf680",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2cf5a4dc42f44a1999f9aa3438880670",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 10/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c680ff12841843c4acf0f28fa2059f86",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "91300f657c03448fad48d1f42ebfaab1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c9e89eedb23c465d919fa0d386b820ca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a1c8b057bcf4dab9d68ce068b859a6e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 11/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0783e6cedb44fcf94043170c1eb7ca4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac41c2e5b9d04d88b3fa450bc8f0066a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b130b8a485ec4e909edc0614e4ef3dc9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58f19ecfa6fa4a48ab7f41fdf8f688e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 12/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6bba8f4a02e84f008d737df406d98a20",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b69db8c719824944a8f9152b9e2f2ded",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dccc9094f5d54a62947d7b2b72f39c4e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c8120e5ef9d45b4b11a50c3b8e59ec4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… Avg scores for Â«Contextual-CompressionÂ»: {'faithfulness': 0.8301282051282052, 'answer_relevancy': 0.7892890209138014, 'context_precision': 0.7083333332624999, 'context_recall': 0.8333333333333334}\n",
            "\n",
            "ğŸ” Pre-computing scores for Â«EnsembleÂ» retriever â€¦\n",
            "   â€¢ Question 1/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d84b14498bc64853bd11f9472a6633fe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a4189ca5d0d4d9d993b08b8baa02ff9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3128f8ccf5d24ff5b983e17d48ffe7ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5eb52ba4f3f4f41808eeef256aee2d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 2/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f380cf27835c45aa9200517259a17590",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0a33a0e9b524079b070e5f223e35f4e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5170fe66bf5a4addbb5b86e04b3a9b02",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2715494cca954f02886768d22674ddc0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 3/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa862e74066549e5870db74ee841c493",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb1d733e554c45e5adee180ebc237f03",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ddbb51ce5e5648db97e0b79f7e0abb2a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fcb7f877c7614508b1babc2d12316be2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 4/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "457517452ce545d6a6c5b6c2c1c55105",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d79f4787fabf42a69c28a64a90e0f58c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aafd4d0e91c34b4db4142232bbc742b2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "00a1b6f1d4444a37b476c2ceaedba360",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 5/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e94c80b9d84f4a869d855564fe87034d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e17c02ad7734fb3ab1c4178091f2f96",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bade26a2f4064d7297e28b9bf2634b4c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "53ecb9bf85994ef198f32af4d3f61e12",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 6/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f3c7f07e205460e9a1d3393b54d4b5a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7da93f5f9bec42218ccbab5d48145a7b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de4c10ef4ac64f44b6e2c8ae0b20125e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6db280dd7c2e483595a7c032e5a9d85c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 7/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "30932df0eb164a5cbc261467fc73771c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf1dced16fc3497e9428b53c29bd62fb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b53d0be0d0f848f6a5d6155fbed870e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97b17015e3564a13922d91179b42d06f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 8/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3fede88bf3d74e4cb37ebfa2afe93d09",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ae857d760054b2090e763f6b09dcf10",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc41e7b8475d493eacc15fe5fc57b184",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d3adb2905c14e0fbc63dce69e8cb282",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 9/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7bd4f3edc2dc4b31bfc9c597c97ae6ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0934f6a227ca40b6b0aadb84e3d43d08",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7043913ed3194850a9a7acd083cc1630",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "398c9e21717b46fab533db53aeb44f48",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 10/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e27eeafa46f48e5938dd378b748b826",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "329acd85ff334d5099eb9d9b9154d8a5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2bde20f124b642a28c90c2e140a2ad5a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eaf401650dd0459cb7b26aa7cb8b0228",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 11/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62aedb6a311b48cc892efde3e0d46256",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "120a255be3d04f23b001653c61a6303c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a17cb268fc414266b02c8f749337f7c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d14eb9483f2e4eac8fd02c8a1ed16f8a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   â€¢ Question 12/12\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c92058ce3a7b4d10b5192cf541b2ef0c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b8a163c807414277ae92fec6cc8c7a44",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f601e61f4cb4ae49d9e8660de3145e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b7ccfeedd2a4fd0a2f00aecdfcff6ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… Avg scores for Â«EnsembleÂ»: {'faithfulness': 0.8598484848484849, 'answer_relevancy': 0.7112428931916175, 'context_precision': 0.8333333332541667, 'context_recall': 0.7611111111111111}\n",
            "\n",
            "ğŸ” Running LangSmith evaluation for Â«NaiveÂ» â€¦\n",
            "View the evaluation results for experiment: 'ragas_precomputed_naive-ba48e48b' at:\n",
            "https://smith.langchain.com/o/a8b64252-5f0f-4f35-a048-c004586e098a/datasets/555a2c84-0480-4b03-8f05-7b3a60c05722/compare?selectedSessions=5e5c5b32-dc55-4f49-a0dc-357d508f84b2\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c447c5dcc1ca4b8989ade4da62a10832",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Â«NaiveÂ» evaluation complete\n",
            "\n",
            "ğŸ” Running LangSmith evaluation for Â«BM25Â» â€¦\n",
            "View the evaluation results for experiment: 'ragas_precomputed_bm25-51d75229' at:\n",
            "https://smith.langchain.com/o/a8b64252-5f0f-4f35-a048-c004586e098a/datasets/555a2c84-0480-4b03-8f05-7b3a60c05722/compare?selectedSessions=d228b687-425c-42cf-a7f8-2ecb2302c664\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5936afc7ae0e4407b24b24c232602128",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Â«BM25Â» evaluation complete\n",
            "\n",
            "ğŸ” Running LangSmith evaluation for Â«Multi-QueryÂ» â€¦\n",
            "View the evaluation results for experiment: 'ragas_precomputed_multi-query-91320fa5' at:\n",
            "https://smith.langchain.com/o/a8b64252-5f0f-4f35-a048-c004586e098a/datasets/555a2c84-0480-4b03-8f05-7b3a60c05722/compare?selectedSessions=b229517e-7c45-419a-b06a-1b8f0597cb87\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "532f453c5cc643a3b35c79bc56c83866",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Â«Multi-QueryÂ» evaluation complete\n",
            "\n",
            "ğŸ” Running LangSmith evaluation for Â«Parent-DocumentÂ» â€¦\n",
            "View the evaluation results for experiment: 'ragas_precomputed_parent-document-32100124' at:\n",
            "https://smith.langchain.com/o/a8b64252-5f0f-4f35-a048-c004586e098a/datasets/555a2c84-0480-4b03-8f05-7b3a60c05722/compare?selectedSessions=8ab986db-d4da-49e5-8879-af50928dcbf0\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6c7e24a93964e7797945981fb4ca2a8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Â«Parent-DocumentÂ» evaluation complete\n",
            "\n",
            "ğŸ” Running LangSmith evaluation for Â«Contextual-CompressionÂ» â€¦\n",
            "View the evaluation results for experiment: 'ragas_precomputed_contextual-compression-3acfb502' at:\n",
            "https://smith.langchain.com/o/a8b64252-5f0f-4f35-a048-c004586e098a/datasets/555a2c84-0480-4b03-8f05-7b3a60c05722/compare?selectedSessions=999c5006-6287-41b1-965a-b65fd39825bc\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8d7a9e869ba4011983ae6df8d960981",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Â«Contextual-CompressionÂ» evaluation complete\n",
            "\n",
            "ğŸ” Running LangSmith evaluation for Â«EnsembleÂ» â€¦\n",
            "View the evaluation results for experiment: 'ragas_precomputed_ensemble-dd89dd72' at:\n",
            "https://smith.langchain.com/o/a8b64252-5f0f-4f35-a048-c004586e098a/datasets/555a2c84-0480-4b03-8f05-7b3a60c05722/compare?selectedSessions=20c919a6-ad40-43e8-a3ae-8be2c9d32c05\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d17eb48f19a42078336d0526ce58190",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Error running target function: headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin', 'x-accel-expires': '0', 'x-debug-trace-id': '26cf5bfe2d7ff00cf0f5c06c4bde8127', 'date': 'Tue, 05 Aug 2025 16:38:18 GMT', 'content-length': '372', 'x-envoy-upstream-service-time': '2', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 429, body: {'id': '9c96dffd-cc3d-4c33-b4fa-3e4026078118', 'message': \"You are using a Trial key, which is limited to 10 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1924, in _forward\n",
            "    fn(*args, langsmith_extra=langsmith_extra)\n",
            "  File \"/var/folders/f1/cmsz4dgn2y194hgy1n_pldjc0000gn/T/ipykernel_44873/3739259170.py\", line 140, in rag_fn\n",
            "    docs   = _retriever.invoke(q)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain/retrievers/ensemble.py\", line 116, in invoke\n",
            "    result = self.rank_fusion(input, run_manager=run_manager, config=config)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain/retrievers/ensemble.py\", line 226, in rank_fusion\n",
            "    retriever.invoke(\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain_core/retrievers.py\", line 259, in invoke\n",
            "    result = self._get_relevant_documents(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain/retrievers/contextual_compression.py\", line 46, in _get_relevant_documents\n",
            "    compressed_docs = self.base_compressor.compress_documents(\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain_cohere/rerank.py\", line 151, in compress_documents\n",
            "    for res in self.rerank(documents, query):\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain_cohere/rerank.py\", line 119, in rerank\n",
            "    results = self.client.rerank(\n",
            "              ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/cohere/v2/client.py\", line 547, in rerank\n",
            "    _response = self._raw_client.rerank(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/cohere/v2/raw_client.py\", line 1067, in rerank\n",
            "    raise TooManyRequestsError(\n",
            "cohere.errors.too_many_requests_error.TooManyRequestsError: headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin', 'x-accel-expires': '0', 'x-debug-trace-id': '26cf5bfe2d7ff00cf0f5c06c4bde8127', 'date': 'Tue, 05 Aug 2025 16:38:18 GMT', 'content-length': '372', 'x-envoy-upstream-service-time': '2', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 429, body: {'id': '9c96dffd-cc3d-4c33-b4fa-3e4026078118', 'message': \"You are using a Trial key, which is limited to 10 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}\n",
            "Error running target function: headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin', 'x-accel-expires': '0', 'x-debug-trace-id': '5de0867fe3f968fe46f1c7088ab160a8', 'date': 'Tue, 05 Aug 2025 16:38:18 GMT', 'content-length': '372', 'x-envoy-upstream-service-time': '16', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 429, body: {'id': '78d6f1dc-4a16-4dfa-9926-b574993f2c64', 'message': \"You are using a Trial key, which is limited to 10 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1924, in _forward\n",
            "    fn(*args, langsmith_extra=langsmith_extra)\n",
            "  File \"/var/folders/f1/cmsz4dgn2y194hgy1n_pldjc0000gn/T/ipykernel_44873/3739259170.py\", line 140, in rag_fn\n",
            "    docs   = _retriever.invoke(q)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain/retrievers/ensemble.py\", line 116, in invoke\n",
            "    result = self.rank_fusion(input, run_manager=run_manager, config=config)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain/retrievers/ensemble.py\", line 226, in rank_fusion\n",
            "    retriever.invoke(\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain_core/retrievers.py\", line 259, in invoke\n",
            "    result = self._get_relevant_documents(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain/retrievers/contextual_compression.py\", line 46, in _get_relevant_documents\n",
            "    compressed_docs = self.base_compressor.compress_documents(\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain_cohere/rerank.py\", line 151, in compress_documents\n",
            "    for res in self.rerank(documents, query):\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain_cohere/rerank.py\", line 119, in rerank\n",
            "    results = self.client.rerank(\n",
            "              ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/cohere/v2/client.py\", line 547, in rerank\n",
            "    _response = self._raw_client.rerank(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/cohere/v2/raw_client.py\", line 1067, in rerank\n",
            "    raise TooManyRequestsError(\n",
            "cohere.errors.too_many_requests_error.TooManyRequestsError: headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin', 'x-accel-expires': '0', 'x-debug-trace-id': '5de0867fe3f968fe46f1c7088ab160a8', 'date': 'Tue, 05 Aug 2025 16:38:18 GMT', 'content-length': '372', 'x-envoy-upstream-service-time': '16', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 429, body: {'id': '78d6f1dc-4a16-4dfa-9926-b574993f2c64', 'message': \"You are using a Trial key, which is limited to 10 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}\n",
            "Error running target function: headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin', 'x-accel-expires': '0', 'x-debug-trace-id': '77562b3c875239e33743aad69d302490', 'date': 'Tue, 05 Aug 2025 16:38:19 GMT', 'content-length': '372', 'x-envoy-upstream-service-time': '17', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 429, body: {'id': 'a23251e5-6a0a-455a-8eb2-5785ecf68cc6', 'message': \"You are using a Trial key, which is limited to 10 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1924, in _forward\n",
            "    fn(*args, langsmith_extra=langsmith_extra)\n",
            "  File \"/var/folders/f1/cmsz4dgn2y194hgy1n_pldjc0000gn/T/ipykernel_44873/3739259170.py\", line 140, in rag_fn\n",
            "    docs   = _retriever.invoke(q)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain/retrievers/ensemble.py\", line 116, in invoke\n",
            "    result = self.rank_fusion(input, run_manager=run_manager, config=config)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain/retrievers/ensemble.py\", line 226, in rank_fusion\n",
            "    retriever.invoke(\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain_core/retrievers.py\", line 259, in invoke\n",
            "    result = self._get_relevant_documents(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain/retrievers/contextual_compression.py\", line 46, in _get_relevant_documents\n",
            "    compressed_docs = self.base_compressor.compress_documents(\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain_cohere/rerank.py\", line 151, in compress_documents\n",
            "    for res in self.rerank(documents, query):\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain_cohere/rerank.py\", line 119, in rerank\n",
            "    results = self.client.rerank(\n",
            "              ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/cohere/v2/client.py\", line 547, in rerank\n",
            "    _response = self._raw_client.rerank(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/cohere/v2/raw_client.py\", line 1067, in rerank\n",
            "    raise TooManyRequestsError(\n",
            "cohere.errors.too_many_requests_error.TooManyRequestsError: headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin', 'x-accel-expires': '0', 'x-debug-trace-id': '77562b3c875239e33743aad69d302490', 'date': 'Tue, 05 Aug 2025 16:38:19 GMT', 'content-length': '372', 'x-envoy-upstream-service-time': '17', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 429, body: {'id': 'a23251e5-6a0a-455a-8eb2-5785ecf68cc6', 'message': \"You are using a Trial key, which is limited to 10 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}\n",
            "Error running target function: headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin', 'x-accel-expires': '0', 'x-debug-trace-id': '5f9ad36929a368cc5152e23d13a86765', 'date': 'Tue, 05 Aug 2025 16:38:20 GMT', 'content-length': '372', 'x-envoy-upstream-service-time': '5', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 429, body: {'id': '4857d8bb-7719-494f-8d40-7b57a81450d9', 'message': \"You are using a Trial key, which is limited to 10 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1924, in _forward\n",
            "    fn(*args, langsmith_extra=langsmith_extra)\n",
            "  File \"/var/folders/f1/cmsz4dgn2y194hgy1n_pldjc0000gn/T/ipykernel_44873/3739259170.py\", line 140, in rag_fn\n",
            "    docs   = _retriever.invoke(q)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain/retrievers/ensemble.py\", line 116, in invoke\n",
            "    result = self.rank_fusion(input, run_manager=run_manager, config=config)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain/retrievers/ensemble.py\", line 226, in rank_fusion\n",
            "    retriever.invoke(\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain_core/retrievers.py\", line 259, in invoke\n",
            "    result = self._get_relevant_documents(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain/retrievers/contextual_compression.py\", line 46, in _get_relevant_documents\n",
            "    compressed_docs = self.base_compressor.compress_documents(\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain_cohere/rerank.py\", line 151, in compress_documents\n",
            "    for res in self.rerank(documents, query):\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain_cohere/rerank.py\", line 119, in rerank\n",
            "    results = self.client.rerank(\n",
            "              ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/cohere/v2/client.py\", line 547, in rerank\n",
            "    _response = self._raw_client.rerank(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/cohere/v2/raw_client.py\", line 1067, in rerank\n",
            "    raise TooManyRequestsError(\n",
            "cohere.errors.too_many_requests_error.TooManyRequestsError: headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin', 'x-accel-expires': '0', 'x-debug-trace-id': '5f9ad36929a368cc5152e23d13a86765', 'date': 'Tue, 05 Aug 2025 16:38:20 GMT', 'content-length': '372', 'x-envoy-upstream-service-time': '5', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 429, body: {'id': '4857d8bb-7719-494f-8d40-7b57a81450d9', 'message': \"You are using a Trial key, which is limited to 10 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}\n",
            "Error running target function: headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin', 'x-accel-expires': '0', 'x-debug-trace-id': '1a24116091350aade19ef444add9b183', 'date': 'Tue, 05 Aug 2025 16:38:21 GMT', 'content-length': '372', 'x-envoy-upstream-service-time': '20', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 429, body: {'id': '33b6e0fa-162d-4452-baf0-f965eb7e5d5c', 'message': \"You are using a Trial key, which is limited to 10 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1924, in _forward\n",
            "    fn(*args, langsmith_extra=langsmith_extra)\n",
            "  File \"/var/folders/f1/cmsz4dgn2y194hgy1n_pldjc0000gn/T/ipykernel_44873/3739259170.py\", line 140, in rag_fn\n",
            "    docs   = _retriever.invoke(q)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain/retrievers/ensemble.py\", line 116, in invoke\n",
            "    result = self.rank_fusion(input, run_manager=run_manager, config=config)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain/retrievers/ensemble.py\", line 226, in rank_fusion\n",
            "    retriever.invoke(\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain_core/retrievers.py\", line 259, in invoke\n",
            "    result = self._get_relevant_documents(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain/retrievers/contextual_compression.py\", line 46, in _get_relevant_documents\n",
            "    compressed_docs = self.base_compressor.compress_documents(\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain_cohere/rerank.py\", line 151, in compress_documents\n",
            "    for res in self.rerank(documents, query):\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain_cohere/rerank.py\", line 119, in rerank\n",
            "    results = self.client.rerank(\n",
            "              ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/cohere/v2/client.py\", line 547, in rerank\n",
            "    _response = self._raw_client.rerank(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/cohere/v2/raw_client.py\", line 1067, in rerank\n",
            "    raise TooManyRequestsError(\n",
            "cohere.errors.too_many_requests_error.TooManyRequestsError: headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin', 'x-accel-expires': '0', 'x-debug-trace-id': '1a24116091350aade19ef444add9b183', 'date': 'Tue, 05 Aug 2025 16:38:21 GMT', 'content-length': '372', 'x-envoy-upstream-service-time': '20', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 429, body: {'id': '33b6e0fa-162d-4452-baf0-f965eb7e5d5c', 'message': \"You are using a Trial key, which is limited to 10 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}\n",
            "Error running target function: headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin', 'x-accel-expires': '0', 'x-debug-trace-id': '43f995e9ef6590ab2e5cb935f7a53138', 'date': 'Tue, 05 Aug 2025 16:38:21 GMT', 'content-length': '372', 'x-envoy-upstream-service-time': '6', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 429, body: {'id': 'fe4f0524-fb87-47c5-963a-df44335e080f', 'message': \"You are using a Trial key, which is limited to 10 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1924, in _forward\n",
            "    fn(*args, langsmith_extra=langsmith_extra)\n",
            "  File \"/var/folders/f1/cmsz4dgn2y194hgy1n_pldjc0000gn/T/ipykernel_44873/3739259170.py\", line 140, in rag_fn\n",
            "    docs   = _retriever.invoke(q)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain/retrievers/ensemble.py\", line 116, in invoke\n",
            "    result = self.rank_fusion(input, run_manager=run_manager, config=config)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain/retrievers/ensemble.py\", line 226, in rank_fusion\n",
            "    retriever.invoke(\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain_core/retrievers.py\", line 259, in invoke\n",
            "    result = self._get_relevant_documents(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain/retrievers/contextual_compression.py\", line 46, in _get_relevant_documents\n",
            "    compressed_docs = self.base_compressor.compress_documents(\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain_cohere/rerank.py\", line 151, in compress_documents\n",
            "    for res in self.rerank(documents, query):\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain_cohere/rerank.py\", line 119, in rerank\n",
            "    results = self.client.rerank(\n",
            "              ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/cohere/v2/client.py\", line 547, in rerank\n",
            "    _response = self._raw_client.rerank(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/cohere/v2/raw_client.py\", line 1067, in rerank\n",
            "    raise TooManyRequestsError(\n",
            "cohere.errors.too_many_requests_error.TooManyRequestsError: headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin', 'x-accel-expires': '0', 'x-debug-trace-id': '43f995e9ef6590ab2e5cb935f7a53138', 'date': 'Tue, 05 Aug 2025 16:38:21 GMT', 'content-length': '372', 'x-envoy-upstream-service-time': '6', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 429, body: {'id': 'fe4f0524-fb87-47c5-963a-df44335e080f', 'message': \"You are using a Trial key, which is limited to 10 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}\n",
            "Error running target function: headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin', 'x-accel-expires': '0', 'x-debug-trace-id': '408d1c34afc59b5f9a5b5bda6305e391', 'date': 'Tue, 05 Aug 2025 16:38:22 GMT', 'content-length': '372', 'x-envoy-upstream-service-time': '2', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 429, body: {'id': 'c515c514-5cb7-41aa-b39c-1c902c61a14f', 'message': \"You are using a Trial key, which is limited to 10 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1924, in _forward\n",
            "    fn(*args, langsmith_extra=langsmith_extra)\n",
            "  File \"/var/folders/f1/cmsz4dgn2y194hgy1n_pldjc0000gn/T/ipykernel_44873/3739259170.py\", line 140, in rag_fn\n",
            "    docs   = _retriever.invoke(q)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain/retrievers/ensemble.py\", line 116, in invoke\n",
            "    result = self.rank_fusion(input, run_manager=run_manager, config=config)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain/retrievers/ensemble.py\", line 226, in rank_fusion\n",
            "    retriever.invoke(\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain_core/retrievers.py\", line 259, in invoke\n",
            "    result = self._get_relevant_documents(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain/retrievers/contextual_compression.py\", line 46, in _get_relevant_documents\n",
            "    compressed_docs = self.base_compressor.compress_documents(\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain_cohere/rerank.py\", line 151, in compress_documents\n",
            "    for res in self.rerank(documents, query):\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain_cohere/rerank.py\", line 119, in rerank\n",
            "    results = self.client.rerank(\n",
            "              ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/cohere/v2/client.py\", line 547, in rerank\n",
            "    _response = self._raw_client.rerank(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/cohere/v2/raw_client.py\", line 1067, in rerank\n",
            "    raise TooManyRequestsError(\n",
            "cohere.errors.too_many_requests_error.TooManyRequestsError: headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin', 'x-accel-expires': '0', 'x-debug-trace-id': '408d1c34afc59b5f9a5b5bda6305e391', 'date': 'Tue, 05 Aug 2025 16:38:22 GMT', 'content-length': '372', 'x-envoy-upstream-service-time': '2', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 429, body: {'id': 'c515c514-5cb7-41aa-b39c-1c902c61a14f', 'message': \"You are using a Trial key, which is limited to 10 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}\n",
            "Error running target function: headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin', 'x-accel-expires': '0', 'x-debug-trace-id': '6c3b5d9a9ff2b9d23ea9e27cf7b7975e', 'date': 'Tue, 05 Aug 2025 16:38:23 GMT', 'content-length': '372', 'x-envoy-upstream-service-time': '14', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 429, body: {'id': '3a7a1d4b-e191-43f2-a35c-0dbb5aca5b20', 'message': \"You are using a Trial key, which is limited to 10 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1924, in _forward\n",
            "    fn(*args, langsmith_extra=langsmith_extra)\n",
            "  File \"/var/folders/f1/cmsz4dgn2y194hgy1n_pldjc0000gn/T/ipykernel_44873/3739259170.py\", line 140, in rag_fn\n",
            "    docs   = _retriever.invoke(q)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain/retrievers/ensemble.py\", line 116, in invoke\n",
            "    result = self.rank_fusion(input, run_manager=run_manager, config=config)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain/retrievers/ensemble.py\", line 226, in rank_fusion\n",
            "    retriever.invoke(\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain_core/retrievers.py\", line 259, in invoke\n",
            "    result = self._get_relevant_documents(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain/retrievers/contextual_compression.py\", line 46, in _get_relevant_documents\n",
            "    compressed_docs = self.base_compressor.compress_documents(\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain_cohere/rerank.py\", line 151, in compress_documents\n",
            "    for res in self.rerank(documents, query):\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain_cohere/rerank.py\", line 119, in rerank\n",
            "    results = self.client.rerank(\n",
            "              ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/cohere/v2/client.py\", line 547, in rerank\n",
            "    _response = self._raw_client.rerank(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/cohere/v2/raw_client.py\", line 1067, in rerank\n",
            "    raise TooManyRequestsError(\n",
            "cohere.errors.too_many_requests_error.TooManyRequestsError: headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin', 'x-accel-expires': '0', 'x-debug-trace-id': '6c3b5d9a9ff2b9d23ea9e27cf7b7975e', 'date': 'Tue, 05 Aug 2025 16:38:23 GMT', 'content-length': '372', 'x-envoy-upstream-service-time': '14', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 429, body: {'id': '3a7a1d4b-e191-43f2-a35c-0dbb5aca5b20', 'message': \"You are using a Trial key, which is limited to 10 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}\n",
            "Error running target function: headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin', 'x-accel-expires': '0', 'x-debug-trace-id': '7f8851d580de6d8614172855c43efabb', 'date': 'Tue, 05 Aug 2025 16:38:23 GMT', 'content-length': '372', 'x-envoy-upstream-service-time': '7', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 429, body: {'id': '9c13249a-1d6e-4613-a00c-6a0d8084afda', 'message': \"You are using a Trial key, which is limited to 10 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1924, in _forward\n",
            "    fn(*args, langsmith_extra=langsmith_extra)\n",
            "  File \"/var/folders/f1/cmsz4dgn2y194hgy1n_pldjc0000gn/T/ipykernel_44873/3739259170.py\", line 140, in rag_fn\n",
            "    docs   = _retriever.invoke(q)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain/retrievers/ensemble.py\", line 116, in invoke\n",
            "    result = self.rank_fusion(input, run_manager=run_manager, config=config)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain/retrievers/ensemble.py\", line 226, in rank_fusion\n",
            "    retriever.invoke(\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain_core/retrievers.py\", line 259, in invoke\n",
            "    result = self._get_relevant_documents(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain/retrievers/contextual_compression.py\", line 46, in _get_relevant_documents\n",
            "    compressed_docs = self.base_compressor.compress_documents(\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain_cohere/rerank.py\", line 151, in compress_documents\n",
            "    for res in self.rerank(documents, query):\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain_cohere/rerank.py\", line 119, in rerank\n",
            "    results = self.client.rerank(\n",
            "              ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/cohere/v2/client.py\", line 547, in rerank\n",
            "    _response = self._raw_client.rerank(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/cohere/v2/raw_client.py\", line 1067, in rerank\n",
            "    raise TooManyRequestsError(\n",
            "cohere.errors.too_many_requests_error.TooManyRequestsError: headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin', 'x-accel-expires': '0', 'x-debug-trace-id': '7f8851d580de6d8614172855c43efabb', 'date': 'Tue, 05 Aug 2025 16:38:23 GMT', 'content-length': '372', 'x-envoy-upstream-service-time': '7', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 429, body: {'id': '9c13249a-1d6e-4613-a00c-6a0d8084afda', 'message': \"You are using a Trial key, which is limited to 10 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}\n",
            "Error running target function: headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin', 'x-accel-expires': '0', 'x-debug-trace-id': '1d15e5e48975040d1e44df746b6ccedb', 'date': 'Tue, 05 Aug 2025 16:38:24 GMT', 'content-length': '372', 'x-envoy-upstream-service-time': '16', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 429, body: {'id': 'd5527177-a2f8-4246-8aa2-b6f84382c8a4', 'message': \"You are using a Trial key, which is limited to 10 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langsmith/evaluation/_runner.py\", line 1924, in _forward\n",
            "    fn(*args, langsmith_extra=langsmith_extra)\n",
            "  File \"/var/folders/f1/cmsz4dgn2y194hgy1n_pldjc0000gn/T/ipykernel_44873/3739259170.py\", line 140, in rag_fn\n",
            "    docs   = _retriever.invoke(q)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain/retrievers/ensemble.py\", line 116, in invoke\n",
            "    result = self.rank_fusion(input, run_manager=run_manager, config=config)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain/retrievers/ensemble.py\", line 226, in rank_fusion\n",
            "    retriever.invoke(\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain_core/retrievers.py\", line 259, in invoke\n",
            "    result = self._get_relevant_documents(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain/retrievers/contextual_compression.py\", line 46, in _get_relevant_documents\n",
            "    compressed_docs = self.base_compressor.compress_documents(\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain_cohere/rerank.py\", line 151, in compress_documents\n",
            "    for res in self.rerank(documents, query):\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/langchain_cohere/rerank.py\", line 119, in rerank\n",
            "    results = self.client.rerank(\n",
            "              ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/cohere/v2/client.py\", line 547, in rerank\n",
            "    _response = self._raw_client.rerank(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/eugeneklyashtorny/projects/AIE7/100_Certification_challenge/.venv/lib/python3.12/site-packages/cohere/v2/raw_client.py\", line 1067, in rerank\n",
            "    raise TooManyRequestsError(\n",
            "cohere.errors.too_many_requests_error.TooManyRequestsError: headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin', 'x-accel-expires': '0', 'x-debug-trace-id': '1d15e5e48975040d1e44df746b6ccedb', 'date': 'Tue, 05 Aug 2025 16:38:24 GMT', 'content-length': '372', 'x-envoy-upstream-service-time': '16', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 429, body: {'id': 'd5527177-a2f8-4246-8aa2-b6f84382c8a4', 'message': \"You are using a Trial key, which is limited to 10 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Â«EnsembleÂ» evaluation complete\n",
            "\n",
            "ğŸ“„ Local RAGAS score summary:\n",
            "                retriever  faithfulness  answer_relevancy  context_precision  \\\n",
            "0                   Naive         0.779             0.795              0.833   \n",
            "1                    BM25         0.821             0.484              0.708   \n",
            "2             Multi-Query         0.839             0.723                NaN   \n",
            "3         Parent-Document         0.831             0.766              0.917   \n",
            "4  Contextual-Compression         0.830             0.789              0.708   \n",
            "5                Ensemble         0.860             0.711              0.833   \n",
            "\n",
            "   context_recall  \n",
            "0           0.817  \n",
            "1           0.694  \n",
            "2           0.833  \n",
            "3           0.889  \n",
            "4           0.833  \n",
            "5           0.761  \n",
            "ğŸ’¾ Scores saved â†’ precomputed_ragas_scores.csv\n",
            "\n",
            "ğŸ”§ RAGAS-LangSmith integration finished (WORKAROUND version)\n"
          ]
        }
      ],
      "source": [
        "# ===============================================================\n",
        "# ğŸ”§ RAGAS Metric Evaluation â€“ WORKAROUND (Pre-compute scores\n",
        "#    outside LangSmith, then upload the correct values 1-to-1)\n",
        "# ===============================================================\n",
        "\n",
        "if USE_LANGSMITH:\n",
        "    print(\"ğŸ”§ RAGAS WORKAROUND â€“ Pre-computing scores outside LangSmith contextâ€¦\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # -----------------------------------------------------------\n",
        "    # Imports & setup\n",
        "    # -----------------------------------------------------------\n",
        "    import os, time, pandas as pd\n",
        "    from ragas import evaluate as ragas_evaluate, EvaluationDataset\n",
        "    from ragas.metrics import (\n",
        "        faithfulness,\n",
        "        answer_relevancy,\n",
        "        context_precision,\n",
        "        context_recall,\n",
        "    )\n",
        "    from langsmith.evaluation import evaluate\n",
        "    from langsmith.schemas import Run, Example\n",
        "\n",
        "    # Disable RAGAS anonymous telemetry (optional)\n",
        "    os.environ[\"RAGAS_DO_NOT_TRACK\"] = \"true\"\n",
        "\n",
        "    print(\"âœ… RAGAS and LangSmith imports successful\")\n",
        "\n",
        "    # -----------------------------------------------------------\n",
        "    # Step 1 â–¸ Pre-compute RAGAS scores for every retriever\n",
        "    # -----------------------------------------------------------\n",
        "    if \"synthetic_df\" in locals() and len(synthetic_df) > 0:\n",
        "        questions   = synthetic_df[\"user_input\"].tolist()\n",
        "        references  = synthetic_df[\"reference\"].tolist()\n",
        "        print(f\"ğŸ“Š Found {len(questions)} questions in synthetic dataset\")\n",
        "    else:\n",
        "        raise RuntimeError(\"âŒ No synthetic_df found â€“ run RAGAS dataset generation first\")\n",
        "\n",
        "    retrievers_for_ragas = [\n",
        "        (naive_retriever,          \"Naive\"),\n",
        "        (bm25_retriever,           \"BM25\"),\n",
        "        (multi_query_retriever,    \"Multi-Query\"),\n",
        "        (parent_document_retriever,\"Parent-Document\"),\n",
        "        (compression_retriever,    \"Contextual-Compression\"),\n",
        "        (ensemble_retriever,       \"Ensemble\"),\n",
        "    ]\n",
        "\n",
        "    precomputed_scores: dict[str, dict[str, float]] = {}\n",
        "\n",
        "    for retriever, retriever_name in retrievers_for_ragas:\n",
        "        print(f\"\\nğŸ” Pre-computing scores for Â«{retriever_name}Â» retriever â€¦\")\n",
        "\n",
        "        metrics_buf = {\n",
        "            \"faithfulness\":       [],\n",
        "            \"answer_relevancy\":   [],\n",
        "            \"context_precision\":  [],\n",
        "            \"context_recall\":     [],\n",
        "        }\n",
        "\n",
        "        for i, (q, ref) in enumerate(zip(questions, references), start=1):\n",
        "            print(f\"   â€¢ Question {i}/{len(questions)}\")\n",
        "\n",
        "            try:\n",
        "                # Retrieve context\n",
        "                docs      = retriever.invoke(q)\n",
        "                contexts  = [d.page_content for d in docs[:2]]\n",
        "                ctx_str   = \"\\n\\n\".join(contexts)\n",
        "\n",
        "                # Generate answer with your chat_model\n",
        "                prompt = (\n",
        "                    \"Given the movie review context, answer the question \"\n",
        "                    \"based only on the context.\\n\\n\"\n",
        "                    f\"Context: {ctx_str}\\nQuestion: {q}\"\n",
        "                )\n",
        "                answer = chat_model.invoke(prompt).content\n",
        "\n",
        "                # Build a temporary EvaluationDataset with one row\n",
        "                data_row = {\n",
        "                    \"user_input\":          q,\n",
        "                    \"response\":            answer,\n",
        "                    \"retrieved_contexts\":  contexts,\n",
        "                    \"reference\":           ref,\n",
        "                }\n",
        "                dataset = EvaluationDataset.from_list([data_row])\n",
        "\n",
        "                # Evaluate each metric separately\n",
        "                for metric, key in [\n",
        "                    (faithfulness,      \"faithfulness\"),\n",
        "                    (answer_relevancy,  \"answer_relevancy\"),\n",
        "                    (context_precision, \"context_precision\"),\n",
        "                    (context_recall,    \"context_recall\"),\n",
        "                ]:\n",
        "                    try:\n",
        "                        res_df = ragas_evaluate(\n",
        "                            dataset=dataset,\n",
        "                            metrics=[metric],\n",
        "                            llm=chat_model,\n",
        "                            embeddings=embedding_model,\n",
        "                        ).to_pandas()\n",
        "                        score = float(res_df[key].iloc[0])\n",
        "                    except Exception as metric_err:\n",
        "                        print(f\"     âš ï¸  {key} failed: {metric_err}\")\n",
        "                        score = 0.0\n",
        "\n",
        "                    metrics_buf[key].append(score)\n",
        "\n",
        "            except Exception as q_err:\n",
        "                print(f\"     âŒ Error on question {i}: {q_err}\")\n",
        "                # Push zeros so indices align\n",
        "                for key in metrics_buf:\n",
        "                    metrics_buf[key].append(0.0)\n",
        "\n",
        "        # Average per-retriever\n",
        "        precomputed_scores[retriever_name] = {\n",
        "            k: (sum(v) / len(v) if v else 0.0) for k, v in metrics_buf.items()\n",
        "        }\n",
        "        print(f\"   âœ… Avg scores for Â«{retriever_name}Â»: {precomputed_scores[retriever_name]}\")\n",
        "\n",
        "    # -----------------------------------------------------------\n",
        "    # Step 2 â–¸ Build evaluator factories that close over retriever\n",
        "    # -----------------------------------------------------------\n",
        "    def make_metric_evaluator(metric_key: str, retriever_name: str):\n",
        "        \"\"\"Return evaluator that always serves the matching pre-computed score.\"\"\"\n",
        "        def _eval(_: Run, __: Example) -> dict:\n",
        "            return {\n",
        "                \"key\":   metric_key,\n",
        "                \"score\": precomputed_scores[retriever_name][metric_key],\n",
        "            }\n",
        "        return _eval\n",
        "\n",
        "    # -----------------------------------------------------------\n",
        "    # Step 3 â–¸ Run LangSmith evaluation with correct evaluators\n",
        "    # -----------------------------------------------------------\n",
        "    for retriever, name in retrievers_for_ragas:\n",
        "        print(f\"\\nğŸ” Running LangSmith evaluation for Â«{name}Â» â€¦\")\n",
        "\n",
        "        # 3-A  Small RAG wrapper that uses *this* retriever\n",
        "        def rag_fn(inputs, _retriever=retriever):\n",
        "            q      = inputs[\"question\"]\n",
        "            docs   = _retriever.invoke(q)\n",
        "            ctx    = \"\\n\\n\".join(d.page_content for d in docs[:2])\n",
        "            prompt = (\n",
        "                \"Given the movie review context, answer the question \"\n",
        "                \"based only on the context.\\n\\n\"\n",
        "                f\"Context: {ctx}\\nQuestion: {q}\"\n",
        "            )\n",
        "            return {\"output\": chat_model.invoke(prompt).content}\n",
        "\n",
        "        # 3-B  Evaluators for just this retriever\n",
        "        evaluator_list = [\n",
        "            make_metric_evaluator(\"faithfulness\",       name),\n",
        "            make_metric_evaluator(\"answer_relevancy\",   name),\n",
        "            make_metric_evaluator(\"context_precision\",  name),\n",
        "            make_metric_evaluator(\"context_recall\",     name),\n",
        "        ]\n",
        "\n",
        "        # 3-C  Send to LangSmith\n",
        "        try:\n",
        "            evaluate(\n",
        "                rag_fn,\n",
        "                data=LANGSMITH_DATASET_NAME,\n",
        "                evaluators=evaluator_list,\n",
        "                metadata={\n",
        "                    \"retriever_type\": name,\n",
        "                    \"evaluation_run\": \"ragas_metrics_precomputed\",\n",
        "                    \"domain\": \"movie_reviews\",\n",
        "                    \"framework\": \"ragas_langsmith_workaround\",\n",
        "                },\n",
        "                experiment_prefix=f\"ragas_precomputed_{name.lower().replace(' ', '_')}\",\n",
        "            )\n",
        "            print(f\"âœ… Â«{name}Â» evaluation complete\")\n",
        "            time.sleep(3)  # polite rate-limit\n",
        "        except Exception as exc:\n",
        "            print(f\"âŒ Â«{name}Â» evaluation failed: {exc}\")\n",
        "\n",
        "    # -----------------------------------------------------------\n",
        "    # EXTRA â–¸ Store all scores locally for later analysis\n",
        "    # -----------------------------------------------------------\n",
        "    scores_df = (\n",
        "        pd.DataFrame(precomputed_scores)  # metrics as columns\n",
        "          .T                              # rows = retrievers\n",
        "          .reset_index()\n",
        "          .rename(columns={\"index\": \"retriever\"})\n",
        "    )\n",
        "    print(\"\\nğŸ“„ Local RAGAS score summary:\")\n",
        "    print(scores_df.round(3))\n",
        "\n",
        "    # Persist to disk for future notebooks / reports\n",
        "    scores_df.to_csv(\"precomputed_ragas_scores.csv\", index=False)\n",
        "    print(\"ğŸ’¾ Scores saved â†’ precomputed_ragas_scores.csv\")\n",
        "\n",
        "    # Clean-up env var\n",
        "    os.environ.pop(\"RAGAS_DO_NOT_TRACK\", None)\n",
        "\n",
        "else:\n",
        "    print(\"âš ï¸  Skipping RAGAS evaluation (LangSmith not configured)\")\n",
        "\n",
        "print(\"\\nğŸ”§ RAGAS-LangSmith integration finished (WORKAROUND version)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Movie Reviews RAG",
      "language": "python",
      "name": "movie-reviews-rag"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
